{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sizes_stats():\n",
    "    annotations_dir = \"/home/lowik/sealion/data/sealion/TrainAnnotations/\"\n",
    "    dots_dir = \"/home/lowik/sealion/data/sealion/TrainDots/\"\n",
    "    sizes = [[] for _ in range(5)]\n",
    "    areas = [[] for _ in range(5)]\n",
    "    for filename in os.listdir(annotations_dir):\n",
    "        # Load annotation mask and dots\n",
    "        train_id, _ = os.path.splitext(filename)\n",
    "        train_id = int(train_id)\n",
    "        mask = cv2.imread(os.path.join(annotations_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        n_labels, im_labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "        with open(os.path.join(dots_dir, \"{}.pkl\".format(train_id)), \"rb\") as p:\n",
    "            dots = pickle.load(p)\n",
    "        \n",
    "        # Find the sealion type for each label.\n",
    "        blob_types = dict()\n",
    "        for i, ds in enumerate(dots):\n",
    "            for x, y in ds:\n",
    "                if mask[y, x] != 0:\n",
    "                    blob_types[im_labels[y, x]] = i\n",
    "                    \n",
    "        # Compute size of each blobs and add it to the corresponding sealion data.\n",
    "        for label in range(1, n_labels):\n",
    "            y, x = np.nonzero(im_labels == label)\n",
    "            coords = np.zeros((x.shape[0], 2), dtype=np.int32)\n",
    "            coords[:, 0] = x\n",
    "            coords[:, 1] = y\n",
    "            ((xc, yc), (w, h), a) = cv2.minAreaRect(coords)\n",
    "            if label not in blob_types:\n",
    "                print(\"{train_id} - label {label} has no type?\".format(train_id=train_id, label=label))\n",
    "                continue\n",
    "            sizes[blob_types[label]].append(max(w, h))\n",
    "            areas[blob_types[label]].append(len(x))\n",
    "            \n",
    "    return sizes, areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes, areas = get_sizes_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size 0: min=41.87986755371094, max=164.6144561767578, mean=81.30168822004988, std=22.956427884506798, median=77.74258422851562, n=37\n",
      "Size 1: min=45.04875564575195, max=142.55235290527344, mean=75.6908574785505, std=24.858394791602496, median=64.53681945800781, n=21\n",
      "Size 2: min=39.369667053222656, max=138.251953125, mean=62.66514139175415, std=19.768246623079616, median=59.07316017150879, n=40\n",
      "Size 3: min=35.0, max=102.97856140136719, mean=51.28458023071289, std=14.259899847392974, median=48.382843017578125, n=33\n",
      "Size 4: min=18.026947021484375, max=55.61539077758789, mean=29.880167219373917, std=8.777418843640895, median=28.429442405700684, n=18\n"
     ]
    }
   ],
   "source": [
    "for i, ss in enumerate(sizes):\n",
    "    mi = np.min(ss)\n",
    "    ma = np.max(ss)\n",
    "    mean = np.mean(ss)\n",
    "    std = np.std(ss)\n",
    "    median = np.median(ss)\n",
    "    print(\"Size {}: min={}, max={}, mean={}, std={}, median={}, n={}\".format(i, mi, ma, mean, std, median, len(ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area 0: min=990, max=8216, mean=2363.9189189189187, std=1348.295087165457, median=2025.0, n=37\n",
      "Area 1: min=1034, max=5659, mean=2073.8571428571427, std=1275.4377133142245, median=1510.0, n=21\n",
      "Area 2: min=519, max=4757, mean=1276.125, std=871.7512600363707, median=1030.0, n=40\n",
      "Area 3: min=485, max=2134, mean=894.2424242424242, std=378.9575038382737, median=812.0, n=33\n",
      "Area 4: min=127, max=761, mean=327.72222222222223, std=144.7756139515966, median=297.0, n=18\n"
     ]
    }
   ],
   "source": [
    "for i, ss in enumerate(areas):\n",
    "    mi = np.min(ss)\n",
    "    ma = np.max(ss)\n",
    "    mean = np.mean(ss)\n",
    "    std = np.std(ss)\n",
    "    median = np.median(ss)\n",
    "    print(\"Area {}: min={}, max={}, mean={}, std={}, median={}, n={}\".format(i, mi, ma, mean, std, median, len(ss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean area of a superpixels: 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
