{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, Flatten, Dense, Lambda, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error, mean_absolute_error, categorical_crossentropy, binary_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Reshape, BatchNormalization\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(n_channels=3):\n",
    "    # Fully convolutional, we don't specify the image size\n",
    "    inputs = Input((None, None, n_channels))\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='elu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='elu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='elu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='elu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='elu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='elu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='elu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='elu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='elu', padding='same')(conv5)\n",
    "    \n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='elu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='elu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='elu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='elu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='elu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='elu', padding='same')(conv8)\n",
    "\n",
    "    #up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
    "    #conv9 = Conv2D(32, (3, 3), activation='elu', padding='same')(up9)\n",
    "    #conv9 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv8)\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet = get_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.ones((1, 512, 512, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.predict(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = K.constant(np.random.randint(0, 3, size=(128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = K.cast(K.not_equal(t, 2), K.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast_1:0' shape=(128, 128) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  2.  2.  1.]\n",
      " [ 2.  2.  0. ...,  0.  2.  1.]\n",
      " [ 1.  1.  2. ...,  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  2.  1. ...,  1.  1.  1.]\n",
      " [ 2.  1.  1. ...,  2.  1.  1.]\n",
      " [ 1.  0.  1. ...,  2.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    print(t.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1. ...,  0.  0.  1.]\n",
      " [ 0.  0.  1. ...,  1.  0.  1.]\n",
      " [ 1.  1.  0. ...,  1.  1.  1.]\n",
      " ..., \n",
      " [ 1.  0.  1. ...,  1.  1.  1.]\n",
      " [ 0.  1.  1. ...,  0.  1.  1.]\n",
      " [ 1.  1.  1. ...,  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    print(m.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 1.  1.  0. ...,  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  1. ...,  1.  1.  1.]\n",
      " [ 0.  1.  1. ...,  0.  1.  1.]\n",
      " [ 1.  0.  1. ...,  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    print((t * m).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'logistic_loss_12:0' shape=(12, 128, 128) dtype=float32>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.binary_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_crossentropy_ignore(y_true, y_pred):\n",
    "    ign_label = 2\n",
    "    mask = K.cast(K.not_equal(y_true, ign_label), K.floatx())\n",
    "    loss_per_pixel = K.binary_crossentropy(y_true, y_pred)\n",
    "    loss_not_ign = loss_per_pixel * mask\n",
    "    used_pixels = K.sum(mask)\n",
    "    loss_sum = K.sum(loss_not_ign)\n",
    "    return loss_sum/used_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = K.constant(np.random.randint(0, 3, size=(12, 128, 128)))\n",
    "y_pred = K.constant(np.random.randint(0, 3, size=(12, 128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = binary_crossentropy_ignore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_14:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.07217\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    print(loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_loc(shape, x, y, target_size=(224, 224), n_blocks=(4,4), overlap=(448,448)):\n",
    "    h, w = shape\n",
    "    w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "    h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "    for by in range(n_blocks[0]):\n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        for bx in range(n_blocks[1]):\n",
    "            x_start = bx * (w_block - overlap[1])\n",
    "            x_end = x_start + w_block + 1\n",
    "            \n",
    "            if x_start <= x < x_end and y_start <= y < y_end and\\\n",
    "            x_start <= x + target_size[1] - 1 < x_end and y_start <= y + target_size[0] - 1 < y_end:\n",
    "                return bx + by * n_blocks[0], x - x_start, y - y_start\n",
    "    raise NonValidPatch(\"Can't find block...??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StreamStats(object):\n",
    "    \"\"\" See https://www.johndcook.com/blog/standard_deviation/\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.M = None\n",
    "        self.S = None\n",
    "        self.k = 0\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "        \n",
    "    def update(self, x):\n",
    "        self.k += 1\n",
    "        if self.k == 1:\n",
    "            self.M = x\n",
    "            self.S = 0\n",
    "            self.min = x\n",
    "            self.max = x\n",
    "        else:\n",
    "            prevM = self.M\n",
    "            prevS = self.S\n",
    "            self.M = prevM + (x - prevM)/self.k\n",
    "            self.S = prevS + (x - prevM) * (x - self.M)\n",
    "            self.min = np.minimum(x, self.min)\n",
    "            self.max = np.maximum(x, self.max)\n",
    "            \n",
    "    def mean(self):\n",
    "        return self.M\n",
    "        \n",
    "    def variance(self):\n",
    "        if self.k - 1 > 0:\n",
    "            return self.S / (self.k - 1)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def std(self):\n",
    "        return np.sqrt(self.variance())\n",
    "    \n",
    "    def minimum(self):\n",
    "        return self.min\n",
    "    \n",
    "    def maximum(self):\n",
    "        return self.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 class_weights = None,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(224, 224),\n",
    "                 batch_size=8, shuffle=True, seed=42,\n",
    "                 debug_dir=None):\n",
    "        \n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        \n",
    "        # Normalize to use class_weights as a probability distribution.\n",
    "        if class_weights:\n",
    "            self.class_weights = np.asarray(class_weights)/np.sum(class_weights)\n",
    "        else:\n",
    "            self.class_weights = np.ones((self.n_sealion_types+1))/(self.n_sealion_types + 1)\n",
    "        \n",
    "        self.normalize = True\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size, shuffle, seed)\n",
    "        \n",
    "    def load_stats(self, uuid):\n",
    "        self.x_scale = np.load(os.path.join(self.root_dir, \"x_scale_{}.npy\".format(uuid)))\n",
    "        self.x_offset = np.load(os.path.join(self.root_dir, \"x_offset_{}.npy\".format(uuid)))\n",
    "        \n",
    "    def compute_class_distribution(self, n_batches):\n",
    "        total = 0\n",
    "        count_per_classes = defaultdict(int)\n",
    "        for b in range(n_batches):\n",
    "            _, by = self.next()\n",
    "            by = np.argmax(by, axis=-1)\n",
    "            ids, counts = np.unique(by, return_counts=True)\n",
    "            for i in range(ids.shape[0]):\n",
    "                count_per_classes[ids[i]] += counts[i]\n",
    "                total += counts[i]\n",
    "            \n",
    "        class_counts = []\n",
    "        for i in range(self.n_sealion_types + 1):\n",
    "            class_counts.append(count_per_classes[i])\n",
    "        return class_counts\n",
    "            \n",
    "    def compute_stats(self, n_batches=100):\n",
    "        self.normalize = False\n",
    "        uuid = uuid4().hex\n",
    "        input_stats = StreamStats()\n",
    "        log_output_stats = StreamStats()\n",
    "        scaled_output_stats = StreamStats()\n",
    "        \n",
    "        for b in range(n_batches):\n",
    "            bx, _ = self.next()\n",
    "            for b in range(bx.shape[0]):\n",
    "                x = bx[b,...]\n",
    "                x_mean_bgr = np.mean(np.mean(x, axis=0), axis=0)\n",
    "                input_stats.update(x_mean_bgr)\n",
    "                    \n",
    "        self.x_scale = 1/(input_stats.std())\n",
    "        self.x_offset = -input_stats.mean()/input_stats.std()\n",
    "        np.save(os.path.join(self.root_dir, \"x_scale_{}.npy\".format(uuid)), self.x_scale)\n",
    "        np.save(os.path.join(self.root_dir, \"x_offset_{}.npy\".format(uuid)), self.x_offset)\n",
    "        \n",
    "        self.normalize = True\n",
    "        return uuid\n",
    "\n",
    "    def normalize_input(self, x):\n",
    "        if not self.normalize: return x\n",
    "        \n",
    "        return x * self.x_scale + self.x_offset\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        return(x_normed - self.x_offset)/self.x_scale\n",
    "    \n",
    "    def random_flip(self, x, y):\n",
    "        flips = np.random.randint(0, 2, (3,))\n",
    "        if flips[0]:\n",
    "            x = np.rot90(x)\n",
    "            y = np.rot90(y)\n",
    "        if flips[1]:\n",
    "            x = np.flipud(x)\n",
    "            y = np.flipud(y)\n",
    "        if flips[2]:\n",
    "            x = np.fliplr(x)\n",
    "            y = np.fliplr(y)\n",
    "        return x, y\n",
    "\n",
    "    def sample(self, shape, dots, image_id):\n",
    "        # if more than 30% of the patch is masked, reject it\n",
    "        threshold_masked = 0.3 \n",
    "        \n",
    "        # Set probability to 0 if some sealion type is not in the block\n",
    "        current_weigths = self.class_weights.copy()\n",
    "        for i in range(self.n_sealion_types):\n",
    "            if not dots[i]:\n",
    "                current_weigths[i] = 0\n",
    "        current_weigths /= np.sum(current_weigths)\n",
    "\n",
    "        while 1:\n",
    "            # Choose an output class randomly\n",
    "            output_class = np.random.choice(self.n_sealion_types + 1, size=(1, ), p=current_weigths)[0]\n",
    "\n",
    "            try:\n",
    "                # Sample a location, either for background or for a sealion.\n",
    "                if output_class == self.n_sealion_types:\n",
    "                    x, y = self.sample_bg(shape, image_id)\n",
    "                else:\n",
    "                    x, y = self.sample_dot(shape, dots[output_class], image_id)\n",
    "            \n",
    "                # Get the corresponding image block, and (x, y) in this block\n",
    "                bid, x, y = get_block_loc(shape, x, y)\n",
    "            except NonValidPatch:\n",
    "                continue\n",
    "                \n",
    "            uid = \"{iid}_{bid}\".format(iid=image_id, bid=bid)\n",
    "            img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "            img_patch = img[y:y+self.target_size[0], x:x+self.target_size[1],:]\n",
    "            masked_pixels = np.count_nonzero(img_patch == 0)\n",
    "            total_pixels = img_patch.shape[0] * img_patch.shape[1]\n",
    "            if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                continue\n",
    "            if masked_pixels/total_pixels < threshold_masked:\n",
    "                smap = np.load(os.path.join(self.root_dir, \"TrainSegmentation\", uid + \".npz\"))['smap']\n",
    "                smap_patch = smap[y:y+self.target_size[0], x:x+self.target_size[1]]\n",
    "                return self.random_flip(img_patch, smap_patch)\n",
    "        \n",
    "    def sample_bg(self, shape, image_id):\n",
    "        x = np.random.randint(0, shape[1] - self.target_size[1], size=(1,))[0]\n",
    "        y = np.random.randint(0, shape[0] - self.target_size[0], size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def sample_dot(self, shape, dots, image_id):\n",
    "        half_size = 40\n",
    "        \n",
    "        randi = np.random.choice(len(dots), size=(1,))[0]\n",
    "        rand_dot = dots[randi]\n",
    "        \n",
    "        min_x = max(0, rand_dot[0] - self.target_size[1] + half_size)\n",
    "        max_x = min(shape[1] - self.target_size[1], rand_dot[0] + self.target_size[1] - half_size)\n",
    "        \n",
    "        min_y = max(0, rand_dot[1] - self.target_size[0] + half_size)\n",
    "        max_y = min(shape[0] - self.target_size[0], rand_dot[1] + self.target_size[0] - half_size)\n",
    "        \n",
    "        if min_x > max_x:\n",
    "            max_x, min_x = min_x, max_x\n",
    "        if min_y > max_y:\n",
    "            max_y, min_y = min_y, max_y \n",
    "            \n",
    "        if min_x == max_x or min_y == max_y:\n",
    "            raise NonValidPatch()\n",
    "           \n",
    "        x = np.random.randint(min_x, max_x, size=(1,))[0]\n",
    "        y = np.random.randint(min_y, max_y, size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                 \n",
    "        batch_x = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], self.n_sealion_types + 1), dtype=K.floatx())\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "                \n",
    "            x, y = self.sample(shape, dots, image_id)\n",
    "            batch_x[i,:,:,:] = x\n",
    "            batch_y[i,:,:,:] = to_categorical(y).reshape(y.shape[:2] + (self.n_sealion_types + 1, ))    \n",
    "\n",
    "        if self.debug_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "                \n",
    "        return self.normalize_input(batch_x), batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mis_matched = set()\n",
    "with open(\"../data/sealion/real_missmatched\", \"r\") as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        mis_matched.add(int(line))\n",
    "\n",
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(s[:-4]) for s in train_ids]\n",
    "\n",
    "train_ids = list(set(train_ids).difference(mis_matched))\n",
    "\n",
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(s[:-4]) for s in val_ids]\n",
    "val_ids = list(set(val_ids).difference(mis_matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = [0.34,  0.42, 0.05, 0.09, 0.11, 1/10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", train_ids, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uuid = trainPatchesGenerator.compute_stats(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uuid = 'b21a839a057b447991fc8e9cfb46cf12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPatchesGenerator.load_stats(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", val_ids, class_weights)\n",
    "valPatchesGenerator.load_stats(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes_counts = trainPatchesGenerator.compute_class_distribution(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcount = np.median(classes_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class = mcount/classes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class_clipped = np.clip(weights_per_class, 0.02, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(classes_counts * weights_per_class_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(classes_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "40140800/3500186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class_clipped *= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class_clipped = np.array([  7.44099153,   9.65796137,   2.47413777,   3.7649283 ,\n",
    "        15.        ,   0.1       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(classes_counts * np.ones((6,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(classes_counts * weights_per_class_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class_clipped = np.array([7, 9, 5, 6, 10, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w_categorical_crossentropy(y_true, y_pred):\n",
    "    y_true_r = K.reshape(y_true, (8, 224*224, 6))\n",
    "    y_pred_r = K.reshape(y_pred, (8, 224*224, 6))\n",
    "    weights = K.max(y_true_r * weights_per_class_clipped, axis=-1)\n",
    "    loss_per_pixel = K.categorical_crossentropy(y_pred_r, y_true_r)\n",
    "    return loss_per_pixel * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet = get_unet(224, 224, 3, 6, batch_norm=True)\n",
    "sgd = SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "unet.compile(optimizer=sgd, loss=w_categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/250 [========================>.....] - ETA: 573s - loss: 0.7751 - acc: 0.5752"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ad4a8b9cf74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPatchesGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalPatchesGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1876\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = unet.fit_generator(trainPatchesGenerator, 250, epochs=5, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=75, class_weight=None, max_q_size=2, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bpred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.argmax(bpred[i,...], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet.save(\"../data/unet_segmentation_ellipse_dmap_sgd_10epochs_200steps.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, batch_y in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.min(batch_ypred[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg = np.argmax(batch_ypred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique(gg, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.argmax(batch_y[i,...], axis=-1))\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.argmax(batch_ypred[i,...], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0]) > 0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 7\n",
    "print(\"GT: \", np.sum(valPatchesGenerator.denormalize_output(batch_y[i,:,:, 0])))\n",
    "print(\"Pred: \", np.sum(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_image_process(im, net, patchGenerator, patch_size=(224, 224), batch_size=8, overlap=(64, 64)):\n",
    "    h, w, c = im.shape\n",
    "    n_patches_x = int(np.ceil((w - patch_size[1])/(patch_size[1] - overlap[1]) + 1))\n",
    "    n_patches_y = int(np.ceil((h - patch_size[0])/(patch_size[0] - overlap[0]) + 1))\n",
    "    print(n_patches_x, n_patches_x)\n",
    "    \n",
    "    dmap = np.zeros((h, w, 1), dtype=np.float32)\n",
    "    dmap_count = np.zeros((h, w, 1), dtype=np.int8)\n",
    "    batch_x = np.zeros((batch_size, ) + patch_size + (c, ), dtype=np.float32)\n",
    "    batch_pos = np.zeros((batch_size, 4), dtype=np.int32)\n",
    "    \n",
    "    current_batch_size = 0\n",
    "    for py in range(n_patches_y):\n",
    "        y_start = py * (patch_size[0] - overlap[0])\n",
    "        y_start = min(h - patch_size[0], y_start)\n",
    "        y_end = y_start + patch_size[0]\n",
    "        for px in range(n_patches_x):\n",
    "            x_start = px * (patch_size[1] - overlap[1])\n",
    "            x_start = min(w - patch_size[1], x_start)\n",
    "            x_end = x_start + patch_size[1]\n",
    "            \n",
    "            # Keep filling the batch\n",
    "            batch_x[current_batch_size, :, :, :] = im[y_start:y_end, x_start:x_end, :]\n",
    "            batch_pos[current_batch_size, :] = np.array([y_start, y_end, x_start, x_end])\n",
    "            current_batch_size += 1\n",
    "            \n",
    "            if current_batch_size == batch_size or (py == n_patches_y - 1 and px == n_patches_x - 1) :\n",
    "                # time to predict\n",
    "                batch_x_normed = patchGenerator.normalize_input(batch_x)\n",
    "                batch_ylog = net.predict(batch_x_normed)\n",
    "                batch_y = patchGenerator.denormalize_output(batch_ylog)\n",
    "                # Fill the full dmap\n",
    "                for i in range(current_batch_size):\n",
    "                    y_start, y_end, x_start, x_end = tuple(batch_pos[i,:])\n",
    "                    dmap[y_start:y_end, x_start:x_end, :] += batch_y[i,:,:,:]\n",
    "                    dmap_count[y_start:y_end, x_start:x_end] += 1\n",
    "                current_batch_size = 0\n",
    "                \n",
    "    return dmap, dmap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"../data/sealion/Train/872.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap, dmap_count = full_image_process(im, unet, valPatchesGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(dmap[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_avg = dmap/dmap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(dmap_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_gt = np.load(\"../data/sealion/TrainDensity/872_0.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
