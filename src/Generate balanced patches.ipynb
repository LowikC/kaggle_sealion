{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sealion/Train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>adult_males</th>\n",
       "      <th>subadult_males</th>\n",
       "      <th>adult_females</th>\n",
       "      <th>juveniles</th>\n",
       "      <th>pups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>486</td>\n",
       "      <td>42</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  adult_males  subadult_males  adult_females  juveniles  pups\n",
       "0         0           62              12            486         42   344\n",
       "1         1            2              20              0         12     0\n",
       "2         2            2               0             38         20     0\n",
       "3         3            8               5             41          7    38\n",
       "4         4            6               9              2          0     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_types = [\"adult_males\", \n",
    "    \"subadult_males\",\n",
    "    \"adult_females\",\n",
    "    \"juveniles\",\n",
    "    \"pups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sum = df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = dict()\n",
    "total = 0\n",
    "for s in sealion_types:\n",
    "    counts[s] = df_sum[s]\n",
    "    total += 1/counts[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = dict()\n",
    "for s, c in counts.items():\n",
    "    probas[s] = (1/counts[s])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "background_proba = np.min(list(probas.values()))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult_females': 0.048142699511667254,\n",
       " 'adult_males': 0.3351506883474506,\n",
       " 'juveniles': 0.089826648353188876,\n",
       " 'pups': 0.11096914409391793,\n",
       " 'subadult_males': 0.41591081969377525}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchesIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param n_samples_per_block: Number of patches to sample on each image.\n",
    "    :param n_successive_samples: Number of samples to take on the same block when the block is loaded.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 n_samples_per_block=12,\n",
    "                 n_successive_samples=4,\n",
    "                 target_size=(224, 224),\n",
    "                 batch_size=8, shuffle=True, seed=42):\n",
    "                 \n",
    "        assert(n_samples_per_block % n_successive_samples == 0)\n",
    "        assert(batch_size % n_successive_samples == 0)\n",
    "        \n",
    "        # Read the file containing the block status, ie if a block should be used or not\n",
    "        with open(os.path.join(root_dir, \"blocks_status\"), \"r\") as jfile:\n",
    "            blocks_status = json.load(jfile)\n",
    "        \n",
    "        # Fill with only valid blocks.\n",
    "        self.image_ids = []\n",
    "        self.block_ids = []\n",
    "        for img_id in image_ids:\n",
    "            blocks = blocks_status[img_id]\n",
    "            for bid, bstatus in enumerate(blocks):\n",
    "                if bstatus:\n",
    "                    self.image_ids.append(img_id)\n",
    "                    self.block_ids.append(bid)\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.samples_per_block = n_samples_per_block\n",
    "        self.n_successive_samples = n_successive_samples\n",
    "        self.target_size = target_size\n",
    "        self.n_samples_per_epoch = len(self.image_ids) * (n_samples_per_block // n_successive_samples)\n",
    "                 \n",
    "        super(PatchesIterator, self).__init__(self.n_samples_per_epoch, batch_size, shuffle, seed)\n",
    "        \n",
    "    def __normalize_sampling__(self, smap):\n",
    "        w_edge = self.target_size[1]//2\n",
    "        h_edge = self.target_size[0]//2\n",
    "        # Set border to 0, it will avoid to deal with patches outside of the image\n",
    "        smap[:, :w_edge] = 0\n",
    "        smap[:, -w_edge:] = 0\n",
    "        smap[:h_edge,:]=0\n",
    "        smap[-h_edge:,:]=0\n",
    "        # Normalize, to use it as a probability distribution\n",
    "        return smap / np.sum(smap)\n",
    "\n",
    "    def __sample__(self, img, dmap , smap, n):\n",
    "        threshold_masked = 0.3 # if more than 30% of the patch is masked, reject it\n",
    "        h, w, _ = img.shape\n",
    "        pdistribution = self.__normalize_sampling__(smap).ravel()\n",
    "        \n",
    "        # There's a small risk that we can't find patches with enough non-masked pixels\n",
    "        # so, we try several times (but we don't want to loop indefinitely)\n",
    "        n_trys = 0\n",
    "        i = 0\n",
    "        while n_trys < 3:\n",
    "            # Sample 10 * n random locations (we sample more because we may reject some)\n",
    "            loc_indices = np.random.choice(h * w, size=(10 * n, ), replace=False, p=pdistribution)\n",
    "            xs = np.zeros((n, ) + img.shape)\n",
    "            ys = np.zeros((n, ) + dmap.shape)\n",
    "            \n",
    "            for loc_index in loc_indices:\n",
    "                x = loc_index % w\n",
    "                y = loc_index // w\n",
    "                y_start = y - self.target_size[0] // 2\n",
    "                y_end = y + self.target_size[0] // 2\n",
    "                x_start = x - self.target_size[1] // 2\n",
    "                x_end = x + self.target_size[1] // 2\n",
    "                img_patch = img[y_start:y_end, x_start:x_end, :]\n",
    "                masked_pixels = np.count_nonzero(img_patch == 0)\n",
    "                total_pixels = img_patch.shape[0] * img_patch.shape[1]\n",
    "                if masked_pixels/total_pixels < threshold_masked:\n",
    "                    xs[i, ...] = img_patch\n",
    "                    ys[i, ...] = dmap[y_start:y_end, x_start:x_end, :]\n",
    "                    i += 1\n",
    "                    if i == n:\n",
    "                        return xs, ys\n",
    "            n_trys += 1\n",
    "        raise Exception(\"ERROR: Can't find non masked patches\")\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                 \n",
    "        batch_x = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 5), dtype=K.floatx())\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            image_id = self.image_ids[j]\n",
    "            block_id = self.image_ids[j]\n",
    "            uid = \"{iid}_{bid}\".format(iid=image_id, bid=block_id)\n",
    "            img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "            dmap = np.load(os.path.join(self.root_dir, \"TrainDensity\", uid + \".npz\"))['dmap']\n",
    "            smap = np.load(os.path.join(self.root_dir, \"TrainSampling\", uid + \".npz\"))['smap']\n",
    "            \n",
    "            n = self.n_successive_samples\n",
    "            xs, ys = self.__sample__(img, dmap, smap, n)\n",
    "            batch_x[i * n: i * (n + 1),:,:,:] = xs\n",
    "            batch_y[i * n: i * (n + 1),:,:,:] = ys\n",
    "\n",
    "        return batch_x, batch_y\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patchesGenerator = PatchesIterator(\"/home/lowik/sealion/data/sealion/\", [1, 2, 3], 10, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in patchesGenerator:\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.load(\"../data/sealion/TrainSampling/3.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
