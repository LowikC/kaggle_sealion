{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sealion/Train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>adult_males</th>\n",
       "      <th>subadult_males</th>\n",
       "      <th>adult_females</th>\n",
       "      <th>juveniles</th>\n",
       "      <th>pups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>486</td>\n",
       "      <td>42</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  adult_males  subadult_males  adult_females  juveniles  pups\n",
       "0         0           62              12            486         42   344\n",
       "1         1            2              20              0         12     0\n",
       "2         2            2               0             38         20     0\n",
       "3         3            8               5             41          7    38\n",
       "4         4            6               9              2          0     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_types = [\"adult_males\", \n",
    "    \"subadult_males\",\n",
    "    \"adult_females\",\n",
    "    \"juveniles\",\n",
    "    \"pups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sum = df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = dict()\n",
    "total = 0\n",
    "for s in sealion_types:\n",
    "    counts[s] = df_sum[s]\n",
    "    total += 1/counts[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas = dict()\n",
    "for s, c in counts.items():\n",
    "    probas[s] = (1/counts[s])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "background_proba = np.min(list(probas.values()))/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult_females': 0.048142699511667254,\n",
       " 'adult_males': 0.3351506883474506,\n",
       " 'juveniles': 0.089826648353188876,\n",
       " 'pups': 0.11096914409391793,\n",
       " 'subadult_males': 0.41591081969377525}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param x_mean: Mean per channel for input normalization\n",
    "    :param x_std: Standard deviation per channel for input normalization\n",
    "    :param y_scale: Scale to apply on the output density map\n",
    "    :param output_counts: Indicate if the iterator should return only counts, otherwise density maps.\n",
    "    :param n_samples_per_block: Number of patches to sample on each image.\n",
    "    :param n_successive_samples: Number of samples to take on the same block when the block is loaded.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 5) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 x_mean, x_std, y_scale,\n",
    "                 output_counts=False,\n",
    "                 n_samples_per_block=12,\n",
    "                 n_successive_samples=4,\n",
    "                 target_size=(224, 224),\n",
    "                 batch_size=8, shuffle=True, seed=42):\n",
    "                 \n",
    "        assert(n_samples_per_block % n_successive_samples == 0)\n",
    "        assert(batch_size % n_successive_samples == 0)\n",
    "        \n",
    "        # Read the file containing the block status, ie if a block should be used or not\n",
    "        with open(os.path.join(root_dir, \"blocks_status.json\"), \"r\") as jfile:\n",
    "            blocks_status = json.load(jfile)\n",
    "        \n",
    "        # Fill with only valid blocks.\n",
    "        self.image_ids = []\n",
    "        self.block_ids = []\n",
    "        for img_id in image_ids:\n",
    "            blocks = blocks_status[str(img_id)]\n",
    "            for bid, bstatus in enumerate(blocks):\n",
    "                if bstatus:\n",
    "                    self.image_ids.append(img_id)\n",
    "                    self.block_ids.append(bid)\n",
    "        \n",
    "        self.x_mean = x_mean\n",
    "        self.x_std = x_std\n",
    "        self.y_scale = y_scale\n",
    "        self.output_counts = output_counts\n",
    "        self.root_dir = root_dir\n",
    "        self.samples_per_block = n_samples_per_block\n",
    "        self.n_successive_samples = n_successive_samples\n",
    "        self.target_size = target_size\n",
    "        self.n_blocks_per_batch = (n_samples_per_block // n_successive_samples)\n",
    "        self.n_indices = len(self.image_ids) * self.n_blocks_per_batch\n",
    "                 \n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size//self.n_successive_samples, shuffle, seed)\n",
    "        \n",
    "    def __normalize_input__(self, batch_x):\n",
    "        return (batch_x - self.x_mean) / self.x_std\n",
    "    \n",
    "    def __normalize_output__(self, batch_y):\n",
    "        return batch_y * self.y_scale\n",
    "    \n",
    "    def __normalize_sampling__(self, smap):\n",
    "        w_edge = self.target_size[1]//2\n",
    "        h_edge = self.target_size[0]//2\n",
    "        # Set border to 0, it will avoid to deal with patches outside of the image\n",
    "        smap[:, :w_edge] = 0\n",
    "        smap[:, -w_edge:] = 0\n",
    "        smap[:h_edge,:]=0\n",
    "        smap[-h_edge:,:]=0\n",
    "        # Normalize, to use it as a probability distribution\n",
    "        return smap / np.sum(smap)\n",
    "\n",
    "    def __sample__(self, img, dmap , smap, n):\n",
    "        threshold_masked = 0.3 # if more than 30% of the patch is masked, reject it\n",
    "        h, w, _ = img.shape\n",
    "        pdistribution = self.__normalize_sampling__(smap).ravel()\n",
    "        \n",
    "        # There's a small risk that we can't find patches with enough non-masked pixels\n",
    "        # so, we try several times (but we don't want to loop indefinitely)\n",
    "        n_trys = 0\n",
    "        i = 0\n",
    "        while n_trys < 3:\n",
    "            # Sample 10 * n random locations (we sample more because we may reject some)\n",
    "            loc_indices = np.random.choice(h * w, size=(10 * n, ), replace=False, p=pdistribution)\n",
    "            xs = np.zeros((n, ) + self.target_size + (3,))\n",
    "            ys = np.zeros((n, ) + self.target_size + (5,))\n",
    "            \n",
    "            for loc_index in loc_indices:\n",
    "                x = loc_index % w\n",
    "                y = loc_index // w\n",
    "                print(\"x, y: \", x, y)\n",
    "                y_start = y - self.target_size[0] // 2\n",
    "                y_end = y + self.target_size[0] // 2\n",
    "                x_start = x - self.target_size[1] // 2\n",
    "                x_end = x + self.target_size[1] // 2\n",
    "                img_patch = img[y_start:y_end, x_start:x_end, :]\n",
    "                masked_pixels = np.count_nonzero(img_patch == 0)\n",
    "                total_pixels = img_patch.shape[0] * img_patch.shape[1]\n",
    "                if masked_pixels/total_pixels < threshold_masked:\n",
    "                    xs[i, ...] = img_patch\n",
    "                    ys[i, ...] = dmap[y_start:y_end, x_start:x_end, :]\n",
    "                    i += 1\n",
    "                    if i == n:\n",
    "                        return xs, ys\n",
    "            n_trys += 1\n",
    "        raise Exception(\"ERROR: Can't find non masked patches\")\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                 \n",
    "        n = self.n_successive_samples\n",
    "        batch_x = np.zeros((current_batch_size * n, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size * n, 5)) if self.output_counts\\\n",
    "        else np.zeros((current_batch_size * n, self.target_size[0], self.target_size[1], 5), dtype=K.floatx())\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_blocks_per_batch\n",
    "            image_id = self.image_ids[index]\n",
    "            block_id = self.block_ids[index]\n",
    "            print(\"Imid, bid: \", image_id, block_id)\n",
    "            uid = \"{iid}_{bid}\".format(iid=image_id, bid=block_id)\n",
    "            img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "            dmap = np.load(os.path.join(self.root_dir, \"TrainDensity\", uid + \".npz\"))['dmap']\n",
    "            smap = np.load(os.path.join(self.root_dir, \"TrainSampling\", uid + \".npz\"))['smap']\n",
    "            \n",
    "            xs, ys = self.__sample__(img, dmap, smap, n)\n",
    "            batch_x[i * n: (i + 1) * n,:,:,:] = xs\n",
    "            if not self.output_counts: \n",
    "                batch_y[i * n: (i + 1) * n,:,:,:] = ys\n",
    "            else:\n",
    "                batch_y[i * n: (i + 1) * n,:] = np.sum(np.sum(ys, axis=1), axis=1)          \n",
    "\n",
    "        return self.__normalize_input__(batch_x), self.__normalize_output__(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bgr = np.load(\"../data/sealion/mean_bgr.npy\")\n",
    "std_bgr = np.load(\"../data/sealion/std_bgr.npy\")\n",
    "patchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", [0, 1], mean_bgr, std_bgr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_density(im, density):\n",
    "    max_density = np.max(density)\n",
    "    if max_density > 0:\n",
    "        normalized_density = density/max_density\n",
    "    else:\n",
    "        normalized_density = density\n",
    "    im_fp32 = im.astype(np.float32)\n",
    "    im_masked = im_fp32.copy()\n",
    "    im_masked[:,:,0] = (im_fp32[:,:,0] * normalized_density)\n",
    "    im_masked[:,:,1] = (im_fp32[:,:,1] * normalized_density)\n",
    "    im_masked[:,:,2] = (im_fp32[:,:,2] * normalized_density)\n",
    "    return im_masked.astype(np.uint8), (normalized_density * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imid, bid:  0 4\n",
      "x, y:  1432 964\n",
      "x, y:  935 212\n",
      "x, y:  1332 847\n",
      "x, y:  1098 457\n",
      "Imid, bid:  1 11\n",
      "x, y:  1483 936\n",
      "x, y:  1000 192\n",
      "x, y:  166 1112\n",
      "x, y:  682 960\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y in patchesGenerator:\n",
    "    for i, (x, y) in enumerate(zip(batch_x, batch_y)):\n",
    "        im, mask = show_density(x, y[:,:,2])\n",
    "        cv2.imwrite(\"../data/dmap\" + str(i) + \".png\", mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.load(\"../data/sealion/TrainSampling/3.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
