{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from math import sqrt\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id,adult_males,subadult_males,adult_females,juveniles,pups\r\n",
      "0,0,0,0,0,0\r\n",
      "1,0,0,0,0,0\r\n",
      "2,0,0,0,0,0\r\n",
      "3,0,0,0,0,0\r\n",
      "4,0,0,0,0,0\r\n",
      "5,0,0,0,0,0\r\n",
      "6,0,0,0,0,0\r\n",
      "7,0,0,0,0,0\r\n",
      "8,0,0,0,0,0\r\n"
     ]
    }
   ],
   "source": [
    "!head ../data/sealion/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18637 ../data/sealion/sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../data/sealion/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(\"../data/sealion/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_test_ids_expected = set(df_sample.test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_test_ids = set()\n",
    "for fn in os.listdir(\"../data/sealion/Test/\"):\n",
    "    if fn.endswith(\".jpg\"):\n",
    "        uid, _ = os.path.splitext(fn)\n",
    "        real_test_ids.add(int(uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test_ids == real_test_ids_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_counts(ids):\n",
    "    \"\"\" Return a dict id -> counts (5 elts list)\n",
    "    \"\"\"\n",
    "    counts = dict()\n",
    "    for iid in ids:\n",
    "        counts[iid] = [0, 0, 0, 0, 0]\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission(counts, out_fn):\n",
    "    with open(out_fn, \"w\") as ofile:\n",
    "        ofile.write(\"test_id,adult_males,subadult_males,adult_females,juveniles,pups\\n\")\n",
    "        for iid in sorted(counts.keys()):\n",
    "            str_counts = \",\".join([str(int(round(c))) for c in counts[iid]])\n",
    "            ofile.write(\"{iid},{counts}\\n\".format(iid=iid, counts=str_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(predicted_counts, groundtruth_counts):\n",
    "    N_SEALION_TYPES = 5\n",
    "    # Check if all predicted ids are also in validation ids\n",
    "    predicted_ids = set(predicted_counts.keys())\n",
    "    set_validation_ids  = set(groundtruth_counts.keys())\n",
    "    assert(predicted_ids.issubset(set_validation_ids))\n",
    "    \n",
    "    # Compute rmse for each type\n",
    "    rmses = [0 for _ in range(N_SEALION_TYPES)]\n",
    "    for iid, pred_counts in predicted_counts.items():\n",
    "        true_counts = groundtruth_counts[iid]\n",
    "        for sid in range(N_SEALION_TYPES):\n",
    "            dc = pred_counts[sid] - true_counts[sid]\n",
    "            rmses[sid] += dc * dc\n",
    "            \n",
    "    for sid in range(N_SEALION_TYPES):\n",
    "        rmses[sid] /= len(predicted_counts)\n",
    "        rmses[sid] = sqrt(rmses[sid])\n",
    "        \n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(iid) for iid in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(iid) for iid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/test.json\", \"r\") as jfile:\n",
    "    test_ids = json.load(jfile)\n",
    "test_ids = [int(iid) for iid in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_groundtruth_counts(path):\n",
    "    df = pd.read_csv(path)\n",
    "    gt_counts = dict()\n",
    "    \n",
    "    def fill_counts(x, counts):\n",
    "        counts[int(x.train_id)] = [x.adult_males, x.subadult_males, x.adult_females, x.juveniles, x.pups]\n",
    "    \n",
    "    _ = df.apply(fill_counts, axis=1, args=(gt_counts, ))\n",
    "    return gt_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_counts = get_groundtruth_counts(\"../data/sealion/my_correct_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_counts = predict_counts(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.434013750741066"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(predicted_counts, gt_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_counts_mean(ids, train_counts):\n",
    "    \"\"\" Return a dict id -> counts (5 elts list)\n",
    "    \"\"\"\n",
    "    means = [0, 0, 0, 0, 0]\n",
    "    for _, counts in train_counts.items():\n",
    "        for sid in range(5):\n",
    "            means[sid] += counts[sid]\n",
    "            \n",
    "    for sid in range(5):\n",
    "        means[sid] /= len(train_counts)\n",
    "        means[sid] = int(round(means[sid]))\n",
    "        \n",
    "    counts = dict()\n",
    "    for iid in ids:\n",
    "        counts[iid] = means\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = dict()\n",
    "for iid in train_ids:\n",
    "    train_counts[iid] = gt_counts[iid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_counts_mean = predict_counts_mean(val_ids, train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.9993039875602"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(predicted_counts_mean, gt_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(gt_counts.keys())).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 4, 39, 20, 18] 34.327967592\n",
      "[6, 4, 40, 22, 17] 30.4188003353\n",
      "[6, 4, 39, 20, 17] 35.5571450452\n",
      "[5, 4, 37, 21, 16] 35.2574232483\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for train, test in kf.split(X):\n",
    "    train_ids = list(train)\n",
    "    test_ids = list(test)\n",
    "    train_counts = dict()\n",
    "    for iid in train_ids:\n",
    "        train_counts[iid] = gt_counts[iid]\n",
    "    predicted_counts_mean = predict_counts_mean(test_ids, train_counts)\n",
    "    rmse = get_rmse(predicted_counts_mean, gt_counts)\n",
    "    rmses.append(rmse)\n",
    "    print(list(predicted_counts_mean.values())[0], rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.890334055197286"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(gt_counts, gt_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a submission with all train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_predicted_counts_mean = predict_counts_mean(real_test_ids, gt_counts)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495097083"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(datetime.timestamp(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(real_predicted_counts_mean, \"../data/submissions/1495097083_mean_prediction_all_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id,adult_males,subadult_males,adult_females,juveniles,pups\r\n",
      "0,6,4,39,21,17\r\n",
      "1,6,4,39,21,17\r\n",
      "2,6,4,39,21,17\r\n",
      "3,6,4,39,21,17\r\n",
      "4,6,4,39,21,17\r\n",
      "5,6,4,39,21,17\r\n",
      "6,6,4,39,21,17\r\n",
      "7,6,4,39,21,17\r\n",
      "8,6,4,39,21,17\r\n"
     ]
    }
   ],
   "source": [
    "!head \"../data/submissions/1495097083_mean_prediction_all_train_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18637 ../data/submissions/1495097083_mean_prediction_all_train_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"../data/submissions/1495097083_mean_prediction_all_train_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
