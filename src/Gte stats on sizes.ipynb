{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sizes_stats():\n",
    "    annotations_dir = \"/home/lowik/sealion/data/sealion/TrainAnnotations/\"\n",
    "    dots_dir = \"/home/lowik/sealion/data/sealion/TrainDots/\"\n",
    "    sizes = [[] for _ in range(5)]\n",
    "    \n",
    "    for filename in os.listdir(annotations_dir):\n",
    "        # Load annotation mask and dots\n",
    "        train_id, _ = os.path.splitext(filename)\n",
    "        train_id = int(train_id)\n",
    "        mask = cv2.imread(os.path.join(annotations_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        n_labels, im_labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "        with open(os.path.join(dots_dir, \"{}.pkl\".format(train_id)), \"rb\") as p:\n",
    "            dots = pickle.load(p)\n",
    "        \n",
    "        # Find the sealion type for each label.\n",
    "        blob_types = dict()\n",
    "        for i, ds in enumerate(dots):\n",
    "            for x, y in ds:\n",
    "                if mask[y, x] != 0:\n",
    "                    blob_types[im_labels[y, x]] = i\n",
    "                    \n",
    "        # Compute size of each blobs and add it to the corresponding sealion data.\n",
    "        for label in range(1, n_labels):\n",
    "            y, x = np.nonzero(im_labels == label)\n",
    "            coords = np.zeros((x.shape[0], 2), dtype=np.int32)\n",
    "            coords[:, 0] = x\n",
    "            coords[:, 1] = y\n",
    "            ((xc, yc), (w, h), a) = cv2.minAreaRect(coords)\n",
    "            if label not in blob_types:\n",
    "                print(\"{train_id} - label {label} has no type?\".format(train_id=train_id, label=label))\n",
    "                continue\n",
    "            sizes[blob_types[label]].append(max(w, h))\n",
    "            \n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = get_sizes_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: min=41.87986755371094, max=164.6144561767578, mean=81.30168822004988, std=22.956427884506798, n=37\n",
      "1: min=45.04875564575195, max=142.55235290527344, mean=75.6908574785505, std=24.858394791602496, n=21\n",
      "2: min=39.369667053222656, max=138.251953125, mean=62.66514139175415, std=19.768246623079616, n=40\n",
      "3: min=35.0, max=102.97856140136719, mean=51.28458023071289, std=14.259899847392974, n=33\n",
      "4: min=18.026947021484375, max=55.61539077758789, mean=29.880167219373917, std=8.777418843640895, n=18\n"
     ]
    }
   ],
   "source": [
    "for i, ss in enumerate(sizes):\n",
    "    mi = np.min(ss)\n",
    "    ma = np.max(ss)\n",
    "    mean = np.mean(ss)\n",
    "    std = np.std(ss)\n",
    "    print(\"{}: min={}, max={}, mean={}, std={}, n={}\".format(i, mi, ma, mean, std, len(ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
