{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, Flatten, Dense, Lambda\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error, mean_absolute_error, categorical_crossentropy, binary_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Reshape, BatchNormalization\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbins = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(n_channels=3, n_classes=1, batch_norm_down=False, batch_norm_up=False):\n",
    "    # Fully convolutional, we don't specify the image size\n",
    "    inputs = Input((None, None, n_channels))\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='elu', padding='same')(inputs)\n",
    "    if batch_norm_down:\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv1)\n",
    "    if batch_norm_down:\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='elu', padding='same')(pool1)\n",
    "    if batch_norm_down:\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='elu', padding='same')(conv2)\n",
    "    if batch_norm_down:\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='elu', padding='same')(pool2)\n",
    "    if batch_norm_down:\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='elu', padding='same')(conv3)\n",
    "    if batch_norm_down:\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='elu', padding='same')(pool3)\n",
    "    if batch_norm_down:\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='elu', padding='same')(conv4)\n",
    "    if batch_norm_down:\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='elu', padding='same')(pool4)\n",
    "    if batch_norm_down:\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='elu', padding='same')(conv5)\n",
    "    if batch_norm_down:\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=-1)\n",
    "    if batch_norm_up:\n",
    "        up6 = BatchNormalization()(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='elu', padding='same')(up6)\n",
    "    if batch_norm_up:\n",
    "        conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='elu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=-1)\n",
    "    if batch_norm_up:\n",
    "        up7 = BatchNormalization()(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='elu', padding='same')(up7)\n",
    "    if batch_norm_up:\n",
    "        conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='elu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=-1)\n",
    "    if batch_norm_up:\n",
    "        up8 = BatchNormalization()(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='elu', padding='same')(up8)\n",
    "    if batch_norm_up:\n",
    "        conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='elu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
    "    if batch_norm_up:\n",
    "        up9 = BatchNormalization()(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='elu', padding='same')(up9)\n",
    "    if batch_norm_up:\n",
    "        conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv9)\n",
    "    if batch_norm_up:\n",
    "        conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, (1, 1), activation='softmax')(conv9)\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_loc(shape, x, y, target_size=(224, 224), n_blocks=(4,4), overlap=(448,448)):\n",
    "    h, w = shape\n",
    "    w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "    h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "    for by in range(n_blocks[0]):\n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        for bx in range(n_blocks[1]):\n",
    "            x_start = bx * (w_block - overlap[1])\n",
    "            x_end = x_start + w_block + 1\n",
    "            \n",
    "            if x_start <= x < x_end and y_start <= y < y_end and\\\n",
    "            x_start <= x + target_size[1] - 1 < x_end and y_start <= y + target_size[0] - 1 < y_end:\n",
    "                return bx + by * n_blocks[0], x - x_start, y - y_start\n",
    "    raise Exception(\"Can't find block...??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_image(im):\n",
    "    n_channels = im.shape[2]\n",
    "    im_normed = im.copy()\n",
    "    \n",
    "    for c in range(n_channels):\n",
    "        min_channel = np.min(im[:,:,c])\n",
    "        max_channel = np.max(im[:,:,c])\n",
    "        a = 255.0/(max_channel - min_channel)\n",
    "        b = -a * min_channel\n",
    "        im_normed[:,:,c] = (a * im[:,:,c] + b).astype(np.uint8)\n",
    "        \n",
    "    return im_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StreamStats(object):\n",
    "    \"\"\" See https://www.johndcook.com/blog/standard_deviation/\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.M = None\n",
    "        self.S = None\n",
    "        self.k = 0\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "        \n",
    "    def update(self, x):\n",
    "        self.k += 1\n",
    "        if self.k == 1:\n",
    "            self.M = x\n",
    "            self.S = 0\n",
    "            self.min = x\n",
    "            self.max = x\n",
    "        else:\n",
    "            prevM = self.M\n",
    "            prevS = self.S\n",
    "            self.M = prevM + (x - prevM)/self.k\n",
    "            self.S = prevS + (x - prevM) * (x - self.M)\n",
    "            self.min = np.minimum(x, self.min)\n",
    "            self.max = np.maximum(x, self.max)\n",
    "            \n",
    "    def mean(self):\n",
    "        return self.M\n",
    "        \n",
    "    def variance(self):\n",
    "        if self.k - 1 > 0:\n",
    "            return self.S / (self.k - 1)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def std(self):\n",
    "        return np.sqrt(self.variance())\n",
    "    \n",
    "    def minimum(self):\n",
    "        return self.min\n",
    "    \n",
    "    def maximum(self):\n",
    "        return self.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantize(x, nbins, vmin, vmax):\n",
    "    \"\"\" Transorm each value x[i] into an integer xq[i] in [0, nbins-1]\n",
    "    \"\"\"\n",
    "    q = (vmax - vmin)/(nbins-1)\n",
    "    k = np.floor((x - vmin)/q)\n",
    "    return k.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dequantize(x, nbins, vmin, vmax):\n",
    "    q = (vmax - vmin)/(nbins-1)\n",
    "    return (x * q) + vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_log_space(x):\n",
    "    return np.log(x + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_log_space(x):\n",
    "    return np.exp(x) - 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids, nbins=256,\n",
    "                 x_scale=None, x_offset=None,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(224, 224),\n",
    "                 batch_size=8, shuffle=True, seed=42):\n",
    "        \n",
    "        self.image_ids = image_ids\n",
    "        self.x_scale = 1.0 if x_scale is None else x_scale\n",
    "        self.x_offset = 0.0 if x_offset is None else x_offset\n",
    "        self.nbins = nbins\n",
    "        self.root_dir = root_dir\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "        self.stats_mode = False\n",
    "                 \n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size, shuffle, seed)\n",
    "        \n",
    "    def load_stats(self):\n",
    "        self.x_scale = np.load(os.path.join(self.root_dir, \"x_scale.npy\"))\n",
    "        self.x_offset = np.load(os.path.join(self.root_dir, \"x_offset.npy\"))\n",
    "        self.y_log_min = np.load(os.path.join(self.root_dir, \"y_log_min.npy\"))\n",
    "        self.y_log_max = np.load(os.path.join(self.root_dir, \"y_log_max.npy\"))\n",
    "        \n",
    "    def compute_stats(self, n_batches=100):\n",
    "        self.stats_mode = True\n",
    "        input_stats = StreamStats()\n",
    "        log_output_stats = StreamStats()\n",
    "        scaled_output_stats = StreamStats()\n",
    "        \n",
    "        for b in range(n_batches):\n",
    "            bx, by = self.next()\n",
    "            for b in range(bx.shape[0]):\n",
    "                x = bx[b,...]\n",
    "                x_normed = normalize_image(x)\n",
    "                x_mean_bgr = np.mean(np.mean(x_normed/255, axis=0), axis=0)\n",
    "                input_stats.update(x_mean_bgr)\n",
    "            for b in range(by.shape[0]):\n",
    "                y = by[b,...]\n",
    "                ylog = to_log_space(y)\n",
    "                for vy in ylog.ravel():\n",
    "                    log_output_stats.update(vy)\n",
    "                    \n",
    "        self.x_scale = 1/(255 * input_stats.std())\n",
    "        self.x_offset = -input_stats.mean()/input_stats.std()\n",
    "        #np.save(os.path.join(self.root_dir, \"x_scale.npy\"), self.x_scale)\n",
    "        #np.save(os.path.join(self.root_dir, \"x_offset.npy\"), self.x_offset)\n",
    "        self.y_log_min = log_output_stats.minimum()\n",
    "        self.y_log_max = log_output_stats.maximum()\n",
    "        np.save(os.path.join(self.root_dir, \"y_log_min.npy\"), self.y_log_min)\n",
    "        np.save(os.path.join(self.root_dir, \"y_log_max.npy\"), self.y_log_max)\n",
    "        self.stats_mode = False\n",
    "\n",
    "    def normalize_input(self, x):\n",
    "        return x * self.x_scale + self.x_offset\n",
    "    \n",
    "    def normalize_output(self, y):\n",
    "        y_log = to_log_space(y)\n",
    "        y_quant = quantize(y_log, self.nbins, self.y_log_min, self.y_log_max)\n",
    "        return to_categorical(y_quant, num_classes=self.nbins)\n",
    "        \n",
    "    def denormalize_output(self, y_quant):\n",
    "        ylog = dequantize(y_quant)\n",
    "        return from_log_space(ylog)\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        return(x_normed - self.x_offset)/self.x_scale\n",
    "    \n",
    "    def __sample__(self, shape, dots, image_id):\n",
    "        pbackground = 0.2\n",
    "        threshold_masked = 0.3 # if more than 30% of the patch is masked, reject it\n",
    "        \n",
    "        adots = []\n",
    "        for _, ds in dots.items():\n",
    "            for x, y in ds:\n",
    "                if 0 <= x < shape[1] and 0 <= y < shape[0]:\n",
    "                    adots.append((x, y))\n",
    "                    \n",
    "        bg_or_dots = np.random.choice(2, size=(1, ), p=[pbackground, 1-pbackground])\n",
    "        \n",
    "        while 1:\n",
    "            if bg_or_dots[0] == 0 or len(adots) == 0:\n",
    "                x, y = self.sample_bg(shape, image_id)\n",
    "            else:\n",
    "                x, y = self.sample_dot(shape, adots, image_id)\n",
    "\n",
    "            try:\n",
    "                bid, x, y = get_block_loc(shape, x, y)\n",
    "            except:\n",
    "                continue\n",
    "            uid = \"{iid}_{bid}\".format(iid=image_id, bid=bid)\n",
    "            img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "            img_patch = img[y:y+self.target_size[0], x:x+self.target_size[1],:]\n",
    "            masked_pixels = np.count_nonzero(img_patch == 0)\n",
    "            total_pixels = img_patch.shape[0] * img_patch.shape[1]\n",
    "            if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                continue\n",
    "            if masked_pixels/total_pixels < threshold_masked:\n",
    "                dmap = np.load(os.path.join(self.root_dir, \"TrainDensity\", uid + \".npz\"))['dmap']\n",
    "                dmap = np.sum(dmap, axis=-1, keepdims=True)\n",
    "                dmap_patch = dmap[y:y+self.target_size[0], x:x+self.target_size[1], :]\n",
    "                return img_patch, dmap_patch\n",
    "        \n",
    "    def sample_bg(self, shape, image_id):\n",
    "        x = np.random.randint(0, shape[1] - self.target_size[1], size=(1,))[0]\n",
    "        y = np.random.randint(0, shape[0] - self.target_size[0], size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def sample_dot(self, shape, adots, image_id):\n",
    "        half_size = 36\n",
    "        \n",
    "        randi = np.random.choice(len(adots), size=(1,))[0]\n",
    "        rand_dot = adots[randi]\n",
    "        \n",
    "        min_x = max(0, rand_dot[0] - self.target_size[1] + half_size)\n",
    "        max_x = min(shape[1] - self.target_size[1], rand_dot[0] + self.target_size[1] - half_size)\n",
    "        \n",
    "        min_y = max(0, rand_dot[1] - self.target_size[0] + half_size)\n",
    "        max_y = min(shape[0] - self.target_size[0], rand_dot[1] + self.target_size[0] - half_size)\n",
    "        \n",
    "        if min_x >= max_x:\n",
    "            max_x, min_x = min_x, max_x\n",
    "        if min_y >= max_y:\n",
    "            max_y, min_y = min_y, max_y \n",
    "           \n",
    "        x = np.random.randint(min_x, max_x, size=(1,))[0]\n",
    "        y = np.random.randint(min_y, max_y, size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                 \n",
    "        batch_x = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 1), dtype=K.floatx())\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "                \n",
    "            x, y = self.__sample__(shape, dots, image_id)\n",
    "            batch_x[i,:,:,:] = x\n",
    "            batch_y[i,:,:,:] = y    \n",
    "        \n",
    "        if self.stats_mode:\n",
    "            return self.normalize_input(batch_x), batch_y\n",
    "        else:\n",
    "            return self.normalize_input(batch_x), self.normalize_output(batch_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(s[:-4]) for s in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/dots_ok.json\", \"r\") as jfile:\n",
    "    dots_ok = json.load(jfile)\n",
    "dots_ok = [int(s[:-4]) for s in dots_ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = list(set(train_ids).intersection(set(dots_ok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(s[:-4]) for s in val_ids]\n",
    "val_ids = list(set(val_ids).intersection(set(dots_ok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", train_ids)\n",
    "trainPatchesGenerator.load_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", val_ids)\n",
    "valPatchesGenerator.load_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet = get_unet(3, 1, batch_norm=False)\n",
    "sgd = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "unet.compile(optimizer=sgd, loss=mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = unet.fit_generator(trainPatchesGenerator, 200, epochs=10, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=50, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = unet.fit_generator(trainPatchesGenerator, 200, epochs=10, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=50, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet = load_model(\"../data/unet_10epochs_200steps.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "quantize() missing 3 required positional arguments: 'nbins', 'vmin', and 'vmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-21c16a3df7e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalPatchesGenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0f29ab366a84>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mbatch_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-0f29ab366a84>\u001b[0m in \u001b[0;36mnormalize_output\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0my_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_log_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0my_quant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: quantize() missing 3 required positional arguments: 'nbins', 'vmin', and 'vmax'"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 7\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(valPatchesGenerator.denormalize_output(batch_y[i,:,:, 0]))\n",
    "plt.subplot(133)\n",
    "plt.imshow(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(valPatchesGenerator.denormalize_output(batch_y[i,:,:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
