{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import Iterator\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CountsIterator(Iterator):\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(1024, 1024),\n",
    "                 batch_size=32, shuffle=True, seed=42, debug_dir=None):\n",
    "        \n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        self.n_samples_per_block = 4\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(CountsIterator, self).__init__(self.n_indices, batch_size//self.n_samples_per_block, shuffle, seed)\n",
    "    \n",
    "    def normalize_input(self, x_bgr):\n",
    "        x_bgr[..., 0] -= 103.939\n",
    "        x_bgr[..., 1] -= 116.779\n",
    "        x_bgr[..., 2] -= 123.68\n",
    "        return x_bgr\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x[..., 0] += 103.939\n",
    "        x[..., 1] += 116.779\n",
    "        x[..., 2] += 123.68\n",
    "\n",
    "    def random_transform(self, im):\n",
    "        flips = np.random.randint(0, 2, (3,))\n",
    "        if flips[0]:\n",
    "            x = np.rot90(x)\n",
    "            y = np.rot90(y)\n",
    "        if flips[1]:\n",
    "            x = np.flipud(x)\n",
    "            y = np.flipud(y)\n",
    "        if flips[2]:\n",
    "            x = np.fliplr(x)\n",
    "            y = np.fliplr(y)\n",
    "        return x, y\n",
    "    \n",
    "    def sample(self, im, dots):\n",
    "        h, w, c = im.shape\n",
    "        batch_x = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1], 3), dtype=np.float32)\n",
    "        batch_y = np.zeros((self.n_samples_per_block, 5), dtype=np.float32)\n",
    "        xs = np.random.randint(0, w - self.target_size[1], size=(self.n_samples_per_block,))\n",
    "        ys = np.random.randint(0, h - self.target_size[0], size=(self.n_samples_per_block,))\n",
    "        for i in range(self.n_samples_per_block):\n",
    "            counts = self.get_counts(xs[i], ys[i], dots)\n",
    "            batch_x[i, ...] = im[ys[i]:ys[i]+self.target_size[0], xs[i]:xs[i]+self.target_size[1],...]\n",
    "            batch_y[i, ...] = np.asarray(counts, dtype=np.float32)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def get_counts(self, xstart, ystart, dots):\n",
    "        x1 = xstart\n",
    "        y1 = ystart\n",
    "        x2 = xstart + self.target_size[1]\n",
    "        y2 = ystart + self.target_size[0]\n",
    "        counts = [0, 0, 0, 0, 0]\n",
    "        for i, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                if x1 <= x < x2 and y1 <= y < y2:\n",
    "                    counts[i] += 1\n",
    "        return counts\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_samples_per_block,\n",
    "                            self.target_size[0],\n",
    "                            self.target_size[1],\n",
    "                            3),\n",
    "                           dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size * self.n_samples_per_block, 5),\n",
    "                           dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            im = cv2.imread(os.path.join(self.root_dir, \"Train\", str(image_id) + \".jpg\"))\n",
    "                \n",
    "            x, y = self.sample(im, dots)\n",
    "            batch_x[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = x\n",
    "            batch_y[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = y \n",
    "\n",
    "        if self.debug_dir:\n",
    "            for i in range(batch_x.shape[0]):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "        \n",
    "        return self.normalize_input(batch_x), batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(iid) for iid in train_ids]\n",
    "\n",
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(iid) for iid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPupsGenerator = CountsIterator(\"/home/lowik/sealion/data/sealion/\", train_ids)\n",
    "\n",
    "valPupsGenerator = CountsIterator(\"/home/lowik/sealion/data/sealion/\", val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x, batch_y in trainPupsGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1024, 1024, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        2,  0,  5,  0,  0,  0,  0,  0,  0,  2,  1, 42, 52,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
       "        1,  0,  0,  7,  0, 52,  8, 43,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 1, 1)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pups_net.predict(batch_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "pups_net.compile(optimizer=sgd, loss=binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 23s - loss: 0.8444 - acc: 0.7062 - val_loss: 0.9957 - val_acc: 0.6687\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 16s - loss: 0.8745 - acc: 0.7500 - val_loss: 1.4213 - val_acc: 0.7750\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 18s - loss: 1.0770 - acc: 0.7625 - val_loss: 1.1480 - val_acc: 0.7438\n"
     ]
    }
   ],
   "source": [
    "h = pups_net.fit_generator(trainPupsGenerator, 5, epochs=3, verbose=1, callbacks=None, validation_data=valPupsGenerator, validation_steps=5, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
