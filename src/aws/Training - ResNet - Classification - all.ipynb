{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, Flatten, Dense, Lambda\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error, mean_absolute_error, categorical_crossentropy, binary_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Reshape, BatchNormalization\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from pkg_resources import parse_version\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorBoardCallBack(Callback):\n",
    "    \"\"\"Tensorboard basic visualizations.\n",
    "    This callback writes a log for TensorBoard, which allows\n",
    "    you to visualize dynamic graphs of your training and test\n",
    "    metrics, as well as activation histograms for the different\n",
    "    layers in your model.\n",
    "    TensorBoard is a visualization tool provided with TensorFlow.\n",
    "    If you have installed TensorFlow with pip, you should be able\n",
    "    to launch TensorBoard from the command line:\n",
    "    ```\n",
    "    tensorboard --logdir=/full_path_to_your_logs\n",
    "    ```\n",
    "    You can find more information about TensorBoard\n",
    "    [here](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html).\n",
    "    # Arguments\n",
    "        log_dir: the path of the directory where to save the log\n",
    "            files to be parsed by Tensorboard\n",
    "        batch_freq: frequency (in batch) at which to log data\n",
    "            If set to 0, we just log at the end of an epoch,\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 batch_freq=0):\n",
    "        super(TensorBoardCallBack, self).__init__()\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.batch_freq = batch_freq\n",
    "        self.merged = None\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        self.last_batch = 0\n",
    "        self.batch_offset = 0\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "\n",
    "        if hasattr(tf, 'merge_all_summaries'):\n",
    "            self.merged = tf.merge_all_summaries()\n",
    "        else:\n",
    "            self.merged = tf.summary.merge_all()\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Each time we go back to batch 0, we increase the batch_offset\n",
    "        if batch < self.last_batch:\n",
    "            self.batch_offset += self.last_batch + 1\n",
    "        self.last_batch = batch\n",
    "\n",
    "        batch_cross_epoch = self.batch_offset + batch\n",
    "        if batch_cross_epoch % self.batch_freq == 0:\n",
    "            logs = logs or {}\n",
    "\n",
    "            for name, value in logs.items():\n",
    "                if name in ['batch', 'size']:\n",
    "                    continue\n",
    "                summary = tf.Summary()\n",
    "                summary_value = summary.value.add()\n",
    "                summary_value.simple_value = value.item()\n",
    "                summary_value.tag = name\n",
    "                self.writer.add_summary(summary, batch_cross_epoch)\n",
    "            self.writer.flush()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = base_model.layers[-2]\n",
    "sealion_prediction = Conv2D(6, (3, 3), activation=\"softmax\", name='predictions')(h.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_net = Model(inputs=[base_model.input], outputs=[sealion_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_net.predict(np.ones((1, 69, 69, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_loc(shape, x, y, target_size=(224, 224), n_blocks=(4,4), overlap=(448,448)):\n",
    "    h, w = shape\n",
    "    w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "    h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "    for by in range(n_blocks[0]):\n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        for bx in range(n_blocks[1]):\n",
    "            x_start = bx * (w_block - overlap[1])\n",
    "            x_end = x_start + w_block + 1\n",
    "            \n",
    "            if x_start <= x < x_end and y_start <= y < y_end and\\\n",
    "            x_start <= x + target_size[1] - 1 < x_end and y_start <= y + target_size[0] - 1 < y_end:\n",
    "                return bx + by * n_blocks[0], x - x_start, y - y_start\n",
    "    raise NonValidPatch(\"Can't find block...??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchesIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples of subadult_males\n",
    "    :param root_dir: Directory containing training images, and dots.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param class_weights: Weights for each class.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 class_weights = None,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(69, 69),\n",
    "                 batch_size=64, shuffle=True, seed=42, debug_dir=None):\n",
    "        self.n_samples_per_block = 16\n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        # Normalize to use class_weights as a probability distribution.\n",
    "        if class_weights:\n",
    "            self.class_weights = np.asarray(class_weights)/np.sum(class_weights)\n",
    "        else:\n",
    "            self.class_weights = np.ones((self.n_sealion_types+1))/(self.n_sealion_types + 1)\n",
    "            \n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(PatchesIterator, self).__init__(self.n_indices, batch_size//self.n_samples_per_block, shuffle, seed)\n",
    "        \n",
    "    def get_class_distribution(self, n_batches=100):\n",
    "        counts = defaultdict(int)\n",
    "        for _ in range(n_batches):\n",
    "            _, by = self.next()\n",
    "            by = np.argmax(by, axis=-1)\n",
    "            cls, cnts = np.unique(by.ravel(), return_counts=True)\n",
    "            for c, cnt in zip(cls, cnts):\n",
    "                counts[c] += cnt\n",
    "        return counts\n",
    "        \n",
    "    def normalize_input(self, x_bgr):\n",
    "        x = x_bgr.copy()\n",
    "        x[..., 0] -= 103.939\n",
    "        x[..., 1] -= 116.779\n",
    "        x[..., 2] -= 123.68\n",
    "        return x\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x = x_normed.copy()\n",
    "        x[..., 0] += 103.939\n",
    "        x[..., 1] += 116.779\n",
    "        x[..., 2] += 123.68\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, x):\n",
    "        flips = np.random.randint(0, 2, (3,))\n",
    "        if flips[0]:\n",
    "            x = np.rot90(x)\n",
    "        if flips[1]:\n",
    "            x = np.flipud(x)\n",
    "        if flips[2]:\n",
    "            x = np.fliplr(x)\n",
    "        return x\n",
    "    \n",
    "    def get_weights(self, dots):\n",
    "        # Set probability to 0 if some sealion type is not in the block\n",
    "        current_weigths = self.class_weights.copy()\n",
    "        for i in range(self.n_sealion_types):\n",
    "            if not dots[i]:\n",
    "                current_weigths[i] = 0\n",
    "        current_weigths /= np.sum(current_weigths)\n",
    "        return current_weigths\n",
    "    \n",
    "    def sample_position(self, shape, dots, current_weigths, size):\n",
    "        # Choose an output class randomly\n",
    "        output_class = np.random.choice(self.n_sealion_types + 1, size=(1, ), p=current_weigths)[0]\n",
    "        # Sample a location, either for background or for a sealion.\n",
    "        if output_class == self.n_sealion_types:\n",
    "            # avoid bg with sealions in it\n",
    "            return self.sample_bg(shape, dots, size), output_class\n",
    "        else:\n",
    "            return self.sample_dot(shape, dots[output_class], size), output_class\n",
    "\n",
    "    def get_dots_in_block(self, bid, shape, dots, n_blocks=(4,4), overlap=(448,448)):\n",
    "        h, w = shape\n",
    "        w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "        h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "        \n",
    "        bx = bid % n_blocks[0]\n",
    "        by = bid // n_blocks[0]\n",
    "        \n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        x_start = bx * (w_block - overlap[1])\n",
    "        x_end = x_start + w_block + 1\n",
    "        \n",
    "        dots_in_block = [[] for _ in range(self.n_sealion_types)]\n",
    "        for i, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                if x_start <= x < x_end and y_start <= y < y_end:\n",
    "                    dots_in_block[i].append((x - x_start, y - y_start))\n",
    "        return dots_in_block\n",
    "        \n",
    "    def get_random_block(self, image_id, shape, dots, current_weigths):\n",
    "        while True:\n",
    "            try:\n",
    "                (x, y), output_class = self.sample_position(shape, dots, current_weigths, self.target_size)\n",
    "                \n",
    "                # Get the corresponding image block, and (x, y) in this block\n",
    "                bid, x, y = get_block_loc(shape, x, y)\n",
    "                \n",
    "                # Load the block and check if it is valid\n",
    "                uid = \"{iid}_{bid}\".format(iid=image_id, bid=bid)\n",
    "                img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "                if img is not None:\n",
    "                    return bid, img\n",
    "            except NonValidPatch:\n",
    "                continue\n",
    "        \n",
    "    \n",
    "    def sample(self, shape, dots, image_id):   \n",
    "        # If we are stuck on a \"bad\" block, we retry from scratch\n",
    "        while True:\n",
    "            # Set probability to 0 if some sealion type is not in the block\n",
    "            current_weigths = self.get_weights(dots)\n",
    "        \n",
    "            # Get a block randomly (but using the dots and the sampling weights)\n",
    "            bid, img = self.get_random_block(image_id, shape, dots, current_weigths)\n",
    "                \n",
    "            # Recompute dots in the blocks, and sampling weights\n",
    "            dots_block = self.get_dots_in_block(bid, shape, dots)\n",
    "            current_weigths = self.get_weights(dots_block)\n",
    "\n",
    "            # Now, sample n_samples_per_block patches from it\n",
    "            n_samples = 0\n",
    "            bx = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1], 3))\n",
    "            by = np.zeros((self.n_samples_per_block, ))\n",
    "\n",
    "            # Stop if we try too many times, \n",
    "            max_iterations = self.n_samples_per_block * 5\n",
    "            current_iteration = 0\n",
    "            while n_samples < self.n_samples_per_block and current_iteration < max_iterations:\n",
    "                current_iteration += 1\n",
    "                try:\n",
    "                    h, w = self.target_size                \n",
    "                    (x, y), output_class = self.sample_position(img.shape[:2], dots_block, current_weigths, (h, w))\n",
    "                    img_patch = img[y:y+h, x:x+w,:]\n",
    "\n",
    "                    if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                        continue\n",
    "                    \n",
    "                    bx[n_samples, ...] = self.random_transform(img_patch)\n",
    "                    by[n_samples] = output_class\n",
    "                    n_samples += 1\n",
    "                except NonValidPatch:\n",
    "                    continue\n",
    "                    \n",
    "            if current_iteration < max_iterations:\n",
    "                return bx, by\n",
    "            # else, we tried too many times, let's get another block.\n",
    "        \n",
    "        \n",
    "    def contains_dots(self, xstart, ystart, dots, margin):\n",
    "        x1 = xstart - margin\n",
    "        y1 = ystart - margin\n",
    "        x2 = xstart + self.target_size[1] + margin\n",
    "        y2 = ystart + self.target_size[0] + margin\n",
    "        for ds in dots:\n",
    "            for (x, y) in ds:\n",
    "                if x1 <= x < x2 and y1 <= y < y2:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def sample_bg(self, shape, dots, size):\n",
    "        margin = 50 # more than half of the biggest sealion expected size\n",
    "        max_iterations = 10\n",
    "        current_iteration = 0\n",
    "        while current_iteration < max_iterations:\n",
    "            if shape[1] - size[1] <= 0 or shape[0] - size[0] <= 0:\n",
    "                raise NonValidPatch(\"Cant' find background\")\n",
    "            x = np.random.randint(0, shape[1] - size[1], size=(1,))[0]\n",
    "            y = np.random.randint(0, shape[0] - size[0], size=(1,))[0]\n",
    "            if not self.contains_dots(x, y, dots, margin):\n",
    "                return x, y\n",
    "            current_iteration += 1\n",
    "        raise NonValidPatch(\"Cant' find background\")\n",
    "    \n",
    "    def sample_dot(self, shape, dots, size):\n",
    "        margin = 6  # dot will can be in [-6, 6] from the center of the patch\n",
    "        \n",
    "        rand_index = np.random.choice(len(dots), size=(1,))[0]\n",
    "        rand_dot = dots[rand_index]\n",
    "        \n",
    "        min_x = max(0, rand_dot[0] - size[1]//2 - margin)\n",
    "        max_x = max(0, min(shape[1] - size[1], rand_dot[0] - size[1]//2 + margin))\n",
    "        \n",
    "        min_y = max(0, rand_dot[1] - size[0]//2 - margin)\n",
    "        max_y = max(0, min(shape[0] - size[0], rand_dot[1] - size[0]//2 + margin))\n",
    "        \n",
    "        if min_x > max_x:\n",
    "            max_x, min_x = min_x, max_x\n",
    "        if min_y > max_y:\n",
    "            max_y, min_y = min_y, max_y \n",
    "            \n",
    "        if min_x == max_x or min_y == max_y:\n",
    "            raise NonValidPatch()\n",
    "           \n",
    "        x = np.random.randint(min_x, max_x, size=(1,))[0]\n",
    "        y = np.random.randint(min_y, max_y, size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_samples_per_block, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size * self.n_samples_per_block), dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "                \n",
    "            x, y = self.sample(shape, dots, image_id)\n",
    "            batch_x[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = x\n",
    "            batch_y[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block] = y \n",
    "\n",
    "        if self.debug_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "                \n",
    "        permut = np.random.permutation(batch_x.shape[0])\n",
    "        return self.normalize_input(batch_x[permut, ...]), to_categorical(batch_y[permut,...].ravel(), num_classes=6).reshape((-1, 1, 1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(iid) for iid in train_ids]\n",
    "\n",
    "with open(\"../data/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(iid) for iid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = [0.2, 0.2, 0.2, 0.2, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainNoPupsIterator = PatchesIterator(\"/home/ubuntu/sealion/data/\", train_ids, class_weights=class_weights)\n",
    "\n",
    "valNoPupsIterator = PatchesIterator(\"/home/ubuntu/sealion/data/\", val_ids, class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainNoPupsIterator.get_class_distribution(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (batch_x, batch_y) in enumerate(trainNoPupsIterator):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(trainNoPupsIterator.denormalize_input(batch_x[61, ...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(batch_y, axis=-1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_net.predict(batch_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(sealion_net.predict(batch_x)[0,...]) #check softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=5*1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "sealion_net.compile(optimizer=sgd, loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /home/ubuntu/data/sealion/data/models/classification_all/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(\"/home/ubuntu/data/sealion/data/models/classification_all/ckpt_{epoch:02d}-{val_loss:.2f}.h5\")\n",
    "cb_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', epsilon=0.01, cooldown=0, min_lr=0)\n",
    "tensorboard_cb = TensorBoardCallBack(log_dir=\"/home/ubuntu/data/sealion/data/models/classification_all/log_tb\", batch_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = sealion_net.fit_generator(trainNoPupsIterator, 1000, epochs=20,\n",
    "                              verbose=1, callbacks=[cb_checkpoint, cb_reduce_lr, tensorboard_cb],\n",
    "                              validation_data=valNoPupsIterator, validation_steps=200,\n",
    "                              class_weight=None,\n",
    "                              max_q_size=16, workers=4, pickle_safe=False,\n",
    "                              initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (batch_x, batch_y) in enumerate(valNoPupsIterator):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred = sealion_net.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(batch_y, axis=-1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(batch_ypred, axis=-1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(trainNoPupsIterator.denormalize_input(batch_x[-4, ...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on a bigger input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val = cv2.imread(\"/home/ubuntu/sealion/data/TrainBlock/43_5.jpg\")\n",
    "\n",
    "plt.imshow(im_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val_patch = im_val[:837, -837:, :]\n",
    "im_val_patch = im_val_patch.reshape((1, 837, 837, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(im_val_patch[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val_pred = sealion_net.predict(trainNoPupsIterator.normalize_input(im_val_patch.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.argmax(im_val_pred[0,...], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unfreeze the last branch\n",
    "for l in base_model.layers[141:]:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-6, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "sealion_net.compile(optimizer=sgd, loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_checkpoint_ft = ModelCheckpoint(\"/home/ubuntu/data/sealion/data/models/classification_all/ckpt_ft_{epoch:02d}-{val_loss:.2f}.h5\")\n",
    "cb_reduce_lr_ft = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', epsilon=0.001, cooldown=0, min_lr=0)\n",
    "tensorboard_cb_ft = TensorBoardCallBack(log_dir=\"/home/ubuntu/data/sealion/data/models/classification_all/log_tb_ft\", batch_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_finetune = sealion_net.fit_generator(trainNoPupsIterator, 1000, epochs=5,\n",
    "                              verbose=1, callbacks=[cb_checkpoint_ft, cb_reduce_lr_ft, tensorboard_cb_ft],\n",
    "                              validation_data=valNoPupsIterator, validation_steps=200,\n",
    "                              class_weight=None,\n",
    "                              max_q_size=16, workers=4, pickle_safe=False,\n",
    "                              initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check again on large patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val_pred = sealion_net.predict(im_val_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(im_val_patch[0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.argmax(im_val_pred[0,...], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_input_size = 965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.ones((1, 965, 965, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_net.predict(t).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a CNN to get the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_net = load_model(\"/home/ubuntu/data/sealion/data/models/classification_all/ckpt_ft_04-1.04.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = sealion_net.output\n",
    "x = BatchNormalization(name='bn_heatmap')(x)\n",
    "x = Conv2D(64, (29, 29), activation='relu', name='cnt_d1')(x)\n",
    "x = BatchNormalization(name='bn_cnt_d1')(x)\n",
    "x = Conv2D(32, (1, 1), activation='relu', name='cnt_d2')(x)\n",
    "counts = Conv2D(5, (1, 1), activation='relu', name='counts')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net = Model(inputs=[sealion_net.input], outputs=[counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net.predict(np.ones((1, count_input_size, count_input_size, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CountsIterator(Iterator):\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(965, 965),\n",
    "                 batch_size=16, shuffle=True, seed=42, debug_dir=None):\n",
    "        \n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        self.n_samples_per_block = 8\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(CountsIterator, self).__init__(self.n_indices, batch_size//self.n_samples_per_block, shuffle, seed)\n",
    "    \n",
    "    def normalize_input(self, x_bgr):\n",
    "        x = x_bgr.copy()\n",
    "        x[..., 0] -= 103.939\n",
    "        x[..., 1] -= 116.779\n",
    "        x[..., 2] -= 123.68\n",
    "        return x\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x = x_normed.copy()\n",
    "        x[..., 0] += 103.939\n",
    "        x[..., 1] += 116.779\n",
    "        x[..., 2] += 123.68\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, im):\n",
    "        flips = np.random.randint(0, 2, (3,))\n",
    "        if flips[0]:\n",
    "            x = np.rot90(x)\n",
    "            y = np.rot90(y)\n",
    "        if flips[1]:\n",
    "            x = np.flipud(x)\n",
    "            y = np.flipud(y)\n",
    "        if flips[2]:\n",
    "            x = np.fliplr(x)\n",
    "            y = np.fliplr(y)\n",
    "        return x, y\n",
    "    \n",
    "    def sample(self, im, dots):\n",
    "        h, w, c = im.shape\n",
    "        batch_x = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1], 3), dtype=np.float32)\n",
    "        batch_y = np.zeros((self.n_samples_per_block, 5), dtype=np.float32)\n",
    "        xs = np.random.randint(0, w - self.target_size[1], size=(self.n_samples_per_block,))\n",
    "        ys = np.random.randint(0, h - self.target_size[0], size=(self.n_samples_per_block,))\n",
    "        for i in range(self.n_samples_per_block):\n",
    "            counts = self.get_counts(xs[i], ys[i], dots)\n",
    "            batch_x[i, ...] = im[ys[i]:ys[i]+self.target_size[0], xs[i]:xs[i]+self.target_size[1],...]\n",
    "            batch_y[i, ...] = np.asarray(counts, dtype=np.float32)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def get_counts(self, xstart, ystart, dots):\n",
    "        x1 = xstart\n",
    "        y1 = ystart\n",
    "        x2 = xstart + self.target_size[1]\n",
    "        y2 = ystart + self.target_size[0]\n",
    "        counts = [0, 0, 0, 0, 0]\n",
    "        for i, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                if x1 <= x < x2 and y1 <= y < y2:\n",
    "                    counts[i] += 1\n",
    "        return counts\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_samples_per_block,\n",
    "                            self.target_size[0],\n",
    "                            self.target_size[1],\n",
    "                            3),\n",
    "                           dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size * self.n_samples_per_block, 5),\n",
    "                           dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            im = cv2.imread(os.path.join(self.root_dir, \"Train\", str(image_id) + \".jpg\"))\n",
    "                \n",
    "            x, y = self.sample(im, dots)\n",
    "            batch_x[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = x\n",
    "            batch_y[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = y \n",
    "\n",
    "        if self.debug_dir:\n",
    "            for i in range(batch_x.shape[0]):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "        \n",
    "        return self.normalize_input(batch_x), batch_y.reshape(-1, 1, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainCountsGenerator = CountsIterator(\"/home/ubuntu/sealion/data/\", train_ids)\n",
    "valCountsGenerator = CountsIterator(\"/home/ubuntu/sealion/data/\", val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bx, by in trainCountsGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(trainCountsGenerator.denormalize_input(bx)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net.predict(bx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in sealion_count_net.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in sealion_count_net.layers[-5:]:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "sealion_count_net.compile(optimizer=sgd, loss=mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_checkpoint_cnt = ModelCheckpoint(\"/home/ubuntu/data/sealion/data/models/classification_all/ckpt_cnt_{epoch:02d}-{val_loss:.2f}.h5\")\n",
    "cb_reduce_lr_cnt = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', epsilon=1.0, cooldown=0, min_lr=0)\n",
    "tensorboard_cb_cnt = TensorBoardCallBack(log_dir=\"/home/ubuntu/data/sealion/data/models/classification_all/log_tb_cnt\", batch_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_cnt = sealion_count_net.fit_generator(trainCountsGenerator, 1000, epochs=5,\n",
    "                           verbose=1, callbacks=[cb_checkpoint_cnt, cb_reduce_lr_cnt, tensorboard_cb_cnt],\n",
    "                           validation_data=valCountsGenerator, validation_steps=100,\n",
    "                           class_weight=None,\n",
    "                           max_q_size=4, workers=4, pickle_safe=False,\n",
    "                           initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net = load_model(\"/home/ubuntu/data/sealion/data/models/classification_all/ckpt_cnt_00-16.62.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in sealion_count_net.layers[-5 -1 -141:]:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "sealion_count_net.compile(optimizer=sgd, loss=mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_cnt = sealion_count_net.fit_generator(trainCountsGenerator, 1000, epochs=5,\n",
    "                           verbose=1, callbacks=[cb_checkpoint_cnt, cb_reduce_lr_cnt, tensorboard_cb_cnt],\n",
    "                           validation_data=valCountsGenerator, validation_steps=100,\n",
    "                           class_weight=None,\n",
    "                           max_q_size=4, workers=4, pickle_safe=False,\n",
    "                           initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bx, by in valNoPupsCountsIterator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bypred = sealion_count_net.predict(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by[5,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bypred[5,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(mse(by, bypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in sub_adults_count_net.layers:\n",
    "    l.Trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.000001, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "sub_adults_count_net.compile(optimizer=sgd, loss=mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = sub_adults_count_net.fit_generator(trainSubMalesCountsIterator, 1000, epochs=5,\n",
    "                           verbose=1, callbacks=[cb_checkpoint_cnt, cb_reduce_lr_cnt, tensorboard_cb_cnt],\n",
    "                           validation_data=valSubMalesCountsIterator, validation_steps=100,\n",
    "                           class_weight=None,\n",
    "                           max_q_size=8, workers=4, pickle_safe=False,\n",
    "                           initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val = cv2.imread(\"/home/ubuntu/sealion/data/TrainBlock/881_13.jpg\")\n",
    "dmap = np.load(\"/home/ubuntu/sealion/data/TrainEllipseDensity/881_13.npz\")[\"dmap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(im_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val_patch = im_val[0:count_size:, 700:700+count_size, :]\n",
    "im_val_patch = im_val_patch.reshape((1, count_size, count_size, 3))\n",
    "dmap_patch = dmap[0:0+count_size:, 700:700+count_size,...]\n",
    "plt.imshow(im_val_patch[0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(dmap_patch[...,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net.predict(trainNoPupsCountsIterator.normalize_input(im_val_patch.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(np.sum(dmap_patch, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val_patch = im_val[400:400+count_size, :count_size, :]\n",
    "im_val_patch = im_val_patch.reshape((1, count_size, count_size, 3))\n",
    "dmap_patch = dmap[400:400+count_size, :count_size]\n",
    "plt.imshow(im_val_patch[0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(dmap_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_count_net.predict(trainNoPupsCountsIterator.normalize_input(im_val_patch.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(np.sum(dmap_patch, axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_counts(im, net, patchGenerator, zeros, patch_size=(count_size, count_size), batch_size=8, overlap=(16, 16)):\n",
    "    h, w, c = im.shape\n",
    "    n_patches_x = int(np.ceil((w - patch_size[1])/(patch_size[1] - overlap[1]) + 1))\n",
    "    n_patches_y = int(np.ceil((h - patch_size[0])/(patch_size[0] - overlap[0]) + 1))\n",
    "    print(n_patches_x, n_patches_x)\n",
    "    \n",
    "    counts = [[] for _ in range(4)]\n",
    "    batch_pos = []\n",
    "    patch_count = np.zeros((h, w, 1), dtype=np.int8)\n",
    "    batch_x = np.zeros((batch_size, ) + patch_size + (c, ), dtype=np.float32)\n",
    "    \n",
    "    current_batch_size = 0\n",
    "    for py in range(n_patches_y):\n",
    "        y_start = py * (patch_size[0] - overlap[0])\n",
    "        y_start = min(h - patch_size[0], y_start)\n",
    "        y_end = y_start + patch_size[0]\n",
    "        for px in range(n_patches_x):\n",
    "            x_start = px * (patch_size[1] - overlap[1])\n",
    "            x_start = min(w - patch_size[1], x_start)\n",
    "            x_end = x_start + patch_size[1]\n",
    "            \n",
    "            # Keep filling the batch\n",
    "            batch_x[current_batch_size, :, :, :] = im[y_start:y_end, x_start:x_end, :]\n",
    "            batch_pos.append((y_start, y_end, x_start, x_end))\n",
    "            patch_count[y_start:y_end, x_start:x_end] += 1\n",
    "            current_batch_size += 1\n",
    "            \n",
    "            if current_batch_size == batch_size or (py == n_patches_y - 1 and px == n_patches_x - 1) :\n",
    "                # time to predict\n",
    "                batch_x_normed = patchGenerator.normalize_input(batch_x)\n",
    "                batch_counts = net.predict(batch_x_normed)\n",
    "                for b in range(current_batch_size):\n",
    "                    for i, cnt in enumerate(batch_counts[b].ravel()):\n",
    "                        counts[i].append(cnt - zeros[i])\n",
    "                current_batch_size = 0\n",
    "                \n",
    "    return counts, batch_pos, patch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_val = cv2.imread(\"/home/ubuntu/sealion/data/Train/299.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeros = [0.29107, 0.387059, 0.33593, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#zeros = [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts, batch_pos, patch_count = predict_counts(im_val, sealion_count_net, trainNoPupsCountsIterator, zeros, overlap=(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(np.min(counts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redundancy = np.sum(patch_count)/patch_count.size\n",
    "for i in range(4):\n",
    "    sum_cnt = np.sum(counts[i])\n",
    "    print(i, \": \", sum_cnt/redundancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ubuntu/data/sealion/data/my_correct_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.train_id == 299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sval_ids = set(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_val = df[df.train_id.isin(sval_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_val.sort_values(by=[\"adult_females\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_count.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(val_ids)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
