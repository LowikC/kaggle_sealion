{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Activation, Cropping2D, Reshape, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error, categorical_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Reshape, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from pkg_resources import parse_version\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorBoardCallBack(Callback):\n",
    "    \"\"\"Tensorboard basic visualizations.\n",
    "    This callback writes a log for TensorBoard, which allows\n",
    "    you to visualize dynamic graphs of your training and test\n",
    "    metrics, as well as activation histograms for the different\n",
    "    layers in your model.\n",
    "    TensorBoard is a visualization tool provided with TensorFlow.\n",
    "    If you have installed TensorFlow with pip, you should be able\n",
    "    to launch TensorBoard from the command line:\n",
    "    ```\n",
    "    tensorboard --logdir=/full_path_to_your_logs\n",
    "    ```\n",
    "    You can find more information about TensorBoard\n",
    "    [here](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html).\n",
    "    # Arguments\n",
    "        log_dir: the path of the directory where to save the log\n",
    "            files to be parsed by Tensorboard\n",
    "        batch_freq: frequency (in batch) at which to log data\n",
    "            If set to 0, we just log at the end of an epoch,\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 batch_freq=0):\n",
    "        super(TensorBoardCallBack, self).__init__()\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.batch_freq = batch_freq\n",
    "        self.merged = None\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        self.last_batch = 0\n",
    "        self.batch_offset = 0\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "\n",
    "        if hasattr(tf, 'merge_all_summaries'):\n",
    "            self.merged = tf.merge_all_summaries()\n",
    "        else:\n",
    "            self.merged = tf.summary.merge_all()\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Each time we go back to batch 0, we increase the batch_offset\n",
    "        if batch < self.last_batch:\n",
    "            self.batch_offset += self.last_batch + 1\n",
    "        self.last_batch = batch\n",
    "\n",
    "        batch_cross_epoch = self.batch_offset + batch\n",
    "        if batch_cross_epoch % self.batch_freq == 0:\n",
    "            logs = logs or {}\n",
    "\n",
    "            for name, value in logs.items():\n",
    "                if name in ['batch', 'size']:\n",
    "                    continue\n",
    "                summary = tf.Summary()\n",
    "                summary_value = summary.value.add()\n",
    "                summary_value.simple_value = value.item()\n",
    "                summary_value.tag = name\n",
    "                self.writer.add_summary(summary, batch_cross_epoch)\n",
    "            self.writer.flush()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_down_block(x, n_filters, block_id, with_maxpool=True, activation=\"elu\"):\n",
    "    y = Conv2D(n_filters, (3, 3), activation=activation, \n",
    "               padding='valid', name=\"conv{}_1\".format(block_id))(x)\n",
    "    print(y.shape)\n",
    "    y = BatchNormalization(name=\"bn{}_1\".format(block_id))(y)\n",
    "    \n",
    "    y = Conv2D(n_filters, (3, 3), activation=activation,\n",
    "               padding='valid', name=\"conv{}_2\".format(block_id))(y)\n",
    "    conv = BatchNormalization(name=\"bn{}_2\".format(block_id))(y)\n",
    "    print(y.shape)\n",
    "    if not with_maxpool:\n",
    "        return conv\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2), name=\"max_pool{}\".format(block_id))(conv)\n",
    "    print(pool.shape)\n",
    "    return conv, pool    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_up_block(x, y, n_filters, block_id, activation=\"elu\"):\n",
    "    up_x = UpSampling2D(size=(2, 2), name=\"upsample{}\".format(block_id))(x)\n",
    "    \n",
    "    # Compute crop needed to have the same shape for up_x and y\n",
    "    _, hx, wx, _ = up_x.shape\n",
    "    _, hy, wy, _ = y.shape\n",
    "    cropy = int(hy - hx)//2\n",
    "    cropx = int(wy - wx)//2\n",
    "    crop_y = Cropping2D(cropping=((cropy, cropy), (cropx, cropx)),\n",
    "                        name=\"crop{}\".format(block_id))(y)\n",
    "    print(\"Crop: \", cropy, cropx)\n",
    "    up = concatenate([up_x, crop_y], axis=-1,\n",
    "                     name=\"concat{}\".format(block_id))\n",
    "    print(up.shape)\n",
    "    up = Conv2D(n_filters, (3, 3), \n",
    "                activation=activation,\n",
    "                padding='valid',\n",
    "                name=\"conv{}_1\".format(block_id))(up)\n",
    "    print(up.shape)\n",
    "    up = Conv2D(n_filters, (3, 3),\n",
    "                activation=activation,\n",
    "                padding='valid',\n",
    "                name=\"conv{}_2\".format(block_id))(up)\n",
    "    print(up.shape)\n",
    "    return up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet(im_height, im_width, n_channels=3, n_classes=6,\n",
    "             n_filters=[64, 128, 256, 512, 1024]):\n",
    "    inputs = Input((im_height, im_width, n_channels))\n",
    "    \n",
    "    conv1, pool1 = unet_down_block(inputs, n_filters[0], 1)\n",
    "    conv2, pool2 = unet_down_block(pool1,  n_filters[1], 2)\n",
    "    conv3, pool3 = unet_down_block(pool2,  n_filters[2], 3)\n",
    "    conv4, pool4 = unet_down_block(pool3,  n_filters[3], 4)\n",
    "    conv5 = unet_down_block(pool4, n_filters[4], 5, with_maxpool=False)\n",
    "    \n",
    "    conv6 = unet_up_block(conv5, conv4, n_filters[3], 6)\n",
    "    conv7 = unet_up_block(conv6, conv3, n_filters[2], 7)\n",
    "    #conv8 = unet_up_block(conv7, conv2, n_filters[1], 8)\n",
    "    #conv9 = unet_up_block(conv8, conv1, n_filters[0], 9)\n",
    "    \n",
    "    #conv10 = Conv2D(n_classes, (1, 1), activation='softmax')(conv9)\n",
    "    segmentation = Conv2D(n_classes, (1, 1), activation='softmax', name=\"segmentation\")(conv7)\n",
    "    flatten = Flatten(name=\"flat_seg\")(segmentation)\n",
    "    counts_conv1 = Dense(64, activation='elu', name=\"counts_conv1\")(flatten)\n",
    "    counts = Dense(5, activation='relu', name='counts')(counts_conv1)\n",
    "    model = Model(inputs=[inputs], outputs=[segmentation, counts], name=\"unet_counts\")\n",
    "    #model = Model(inputs=[inputs], outputs=[segmentation], name=\"unet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = get_unet( 524, 524, 3, n_filters=[32, 64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.ones((1, 524, 524, 3))\n",
    "seg, counts = unet.predict(t)\n",
    "print(\"Segmentation output: \", seg.shape)\n",
    "print(\"Counts output: \", counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(524 - 352)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 class_weights,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(524, 524),\n",
    "                 scale = 4,\n",
    "                 crop = (86, 86),\n",
    "                 batch_size=16, shuffle=True, seed=42,\n",
    "                 debug_dir=None):\n",
    "        self.n_samples_per_block = 8\n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        # Normalize to use class_weights as a probability distribution.\n",
    "        if class_weights:\n",
    "            self.class_weights = np.asarray(class_weights)/np.sum(class_weights)\n",
    "        else:\n",
    "            self.class_weights = np.ones((self.n_sealion_types+1))/(self.n_sealion_types + 1)\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.crop = crop\n",
    "        self.scale = scale\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size//self.n_samples_per_block, shuffle, seed)\n",
    "        \n",
    "    def compute_class_distribution(self, n_batches):\n",
    "        seg_freqs = defaultdict(int)\n",
    "        count_freqs = {0: defaultdict(int),\n",
    "                             1: defaultdict(int),\n",
    "                             2: defaultdict(int),\n",
    "                             3: defaultdict(int),\n",
    "                             4: defaultdict(int)}\n",
    "        for b in range(n_batches):\n",
    "            _, [by, bcounts] = self.next()\n",
    "            by = np.argmax(by, axis=-1)\n",
    "            ids, freqs = np.unique(by, return_counts=True)\n",
    "            for i in range(ids.shape[0]):\n",
    "                seg_freqs[ids[i]] += freqs[i]\n",
    "            for b in range(bcounts.shape[0]):\n",
    "                counts = bcounts[b]\n",
    "                for i in range(counts.shape[0]):\n",
    "                    count_freqs[i][counts[i]] += 1\n",
    "        \n",
    "        return seg_freqs, count_freqs\n",
    "\n",
    "    def normalize_input(self, x_bgr):\n",
    "        x = x_bgr.copy()\n",
    "        x[..., 0] -= 103.939\n",
    "        x[..., 1] -= 116.779\n",
    "        x[..., 2] -= 123.68\n",
    "        return x\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x = x_normed.copy()\n",
    "        x[..., 0] += 103.939\n",
    "        x[..., 1] += 116.779\n",
    "        x[..., 2] += 123.68\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, x, y):\n",
    "        flips = np.random.randint(0, 2, (3,))\n",
    "        if flips[0]:\n",
    "            x = np.rot90(x)\n",
    "            y = np.rot90(y)\n",
    "        if flips[1]:\n",
    "            x = np.flipud(x)\n",
    "            y = np.flipud(y)\n",
    "        if flips[2]:\n",
    "            x = np.fliplr(x)\n",
    "            y = np.fliplr(y)\n",
    "        return x, y\n",
    "                     \n",
    "    def get_dots_in_patch(self, sx, sy, dots):\n",
    "        dots_in_patch = [[] for _ in dots]\n",
    "        for i, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                if sx <= x < sx + self.target_size[1] and sy <= y < sy + self.target_size[0]:\n",
    "                    dots_in_patch[i].append((x - sx, y - sy))\n",
    "        return dots_in_patch\n",
    "    \n",
    "    def build_counts(self, dots):\n",
    "        h = (self.target_size[0] - 2 * self.crop[0])//self.scale\n",
    "        w = (self.target_size[1] - 2 * self.crop[1])//self.scale\n",
    "        counts = np.zeros((5, ), dtype=np.int32)\n",
    "        for c, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                xr = int(round((x - self.crop[1])/self.scale))\n",
    "                yr = int(round((y - self.crop[0])/self.scale))\n",
    "\n",
    "                if 0 <= xr < w and 0 <= yr < h:\n",
    "                    counts[c] += 1\n",
    "        return counts\n",
    "          \n",
    "    def get_weights(self, dots):\n",
    "        # Set probability to 0 if some sealion type is not in the block\n",
    "        current_weigths = self.class_weights.copy()\n",
    "        for i in range(self.n_sealion_types):\n",
    "            if not dots[i]:\n",
    "                current_weigths[i] = 0\n",
    "        current_weigths /= np.sum(current_weigths)\n",
    "        return current_weigths\n",
    "    \n",
    "    def sample(self, shape, dots, image_id):\n",
    "        margin = self.crop[0] + 30\n",
    "        max_iterations = self.n_samples_per_block * 5\n",
    "        \n",
    "        img = cv2.imread(os.path.join(self.root_dir, \"Train2x\", str(image_id) + \".jpg\"))\n",
    "        smap = np.load(os.path.join(self.root_dir, \"TrainSegmentationIgnored2x\", str(image_id) + \".npz\"))[\"smap\"]                                                                          \n",
    "        n_samples = 0\n",
    "        bx = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1], 3))\n",
    "        by = np.zeros((self.n_samples_per_block,\n",
    "                       (self.target_size[0] - 2 * self.crop[0])//self.scale,\n",
    "                       (self.target_size[1] - 2 * self.crop[1])//self.scale),\n",
    "                     dtype=np.uint8)\n",
    "        bcounts = np.zeros((self.n_samples_per_block, 5))\n",
    "\n",
    "        current_iteration = 0\n",
    "        weights = self.get_weights(dots)\n",
    "        \n",
    "        # Samples n dots, with some probabilty to get the background only\n",
    "        while n_samples < self.n_samples_per_block and current_iteration < max_iterations:\n",
    "            current_iteration += 1\n",
    "            try:\n",
    "                # Choose an output class randomly\n",
    "                output_class = np.random.choice(self.n_sealion_types + 1, size=(1, ), p=weights)[0]\n",
    "                \n",
    "                # Background, select randomly a patch in the image (high chance to get only background)\n",
    "                if output_class == self.n_sealion_types:\n",
    "                    sx_min = 0\n",
    "                    sx_max = shape[1] - self.target_size[1]\n",
    "                    sy_min = 0\n",
    "                    sy_max = shape[0] - self.target_size[0]\n",
    "                # Choose a dot randomly in that class\n",
    "                else:  \n",
    "                    dot_index = np.random.randint(0, len(dots[output_class]))\n",
    "                    rx, ry = dots[output_class][dot_index]\n",
    "                    sx_min = min(max(0, rx - self.target_size[1] + margin), shape[1] - self.target_size[1])\n",
    "                    sx_max = min(max(0, rx - margin), shape[1] - self.target_size[1])\n",
    "                    sy_min = min(max(0, ry - self.target_size[0] + margin), shape[0] - self.target_size[1])\n",
    "                    sy_max = min(max(0, ry - margin), shape[0] - self.target_size[0]) \n",
    "                \n",
    "                    if sx_min >= sx_max:\n",
    "                        sx_min = min(max(0, rx - self.target_size[1]), shape[1] - self.target_size[1])\n",
    "                        sx_max = min(max(0, rx), shape[1] - self.target_size[1])\n",
    "                        \n",
    "                    if sy_min >= sy_max:\n",
    "                        sy_min = min(max(0, ry - self.target_size[0]), shape[0] - self.target_size[1])\n",
    "                        sy_max = min(max(0, ry), shape[0] - self.target_size[0]) \n",
    "                    \n",
    "                if sx_min >= sx_max or sy_min >= sy_max:\n",
    "                        continue\n",
    "                        \n",
    "                # Choose the top-left corner so that the dot selected is in the patch.\n",
    "                sx = np.random.randint(sx_min, sx_max)\n",
    "                sy = np.random.randint(sy_min, sy_max)\n",
    "\n",
    "                dots_in_patch = self.get_dots_in_patch(sx, sy, dots)\n",
    "                \n",
    "                img_patch = img[sy:sy+self.target_size[0], sx:sx+self.target_size[1],:]\n",
    "                if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                    continue\n",
    "                spatch = smap[sy + self.crop[0]:sy + self.target_size[0] - self.crop[0],\n",
    "                              sx + self.crop[1]:sx + self.target_size[1] - self.crop[1]]\n",
    "                spatch_scaled = cv2.resize(spatch,\n",
    "                                           ((self.target_size[0] - 2 * self.crop[0])//self.scale,\n",
    "                                            (self.target_size[1] - 2 * self.crop[1])//self.scale),\n",
    "                                           interpolation=cv2.INTER_NEAREST)\n",
    "                counts = self.build_counts(dots_in_patch)\n",
    "                img_patch, spatch_scaled = self.random_transform(img_patch, spatch_scaled)\n",
    "                bx[n_samples, ...] = img_patch\n",
    "                by[n_samples, ...] = spatch_scaled\n",
    "                bcounts[n_samples, ...] = counts\n",
    "                n_samples += 1\n",
    "            except NonValidPatch:\n",
    "                continue\n",
    "                    \n",
    "        if current_iteration < max_iterations:\n",
    "            return bx, by, bcounts\n",
    "        else:\n",
    "            print(\"Error with image \", image_id)\n",
    "            raise Exception(\"hoho\")\n",
    "    \n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_samples_per_block,\n",
    "                            self.target_size[0],\n",
    "                            self.target_size[1],\n",
    "                            3),\n",
    "                           dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size * self.n_samples_per_block,\n",
    "                            (self.target_size[0] - 2 * self.crop[0])//self.scale,\n",
    "                            (self.target_size[1] - 2 * self.crop[1])//self.scale),\n",
    "                           dtype=np.int32)\n",
    "        batch_counts = np.zeros((current_batch_size * self.n_samples_per_block, 5), dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "            \n",
    "            # Scale dots coordinates\n",
    "            dots_resized = []\n",
    "            for ds in dots:\n",
    "                ds_resized = []\n",
    "                for (x, y) in ds:\n",
    "                    ds_resized.append((x//2, y//2))\n",
    "                dots_resized.append(ds_resized)\n",
    "                \n",
    "            shape = (shape[0]//2, shape[1]//2)\n",
    "                                      \n",
    "                \n",
    "            x, y, counts = self.sample(shape, dots_resized, image_id)\n",
    "            batch_x[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = x\n",
    "            batch_y[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = y \n",
    "            batch_counts[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = counts\n",
    "        if self.debug_dir:\n",
    "            for i in range(batch_x.shape[0]):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"smap_{}.jpg\".format(i)), to_img(batch_y[i]))\n",
    "        \n",
    "        b, h, w = batch_y.shape\n",
    "        batch_y = to_categorical(batch_y, num_classes=self.n_sealion_types + 2).reshape((b, h, w, -1))\n",
    "        return self.normalize_input(batch_x), [batch_y, batch_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(iid) for iid in train_ids]\n",
    "\n",
    "with open(\"../data/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(iid) for iid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = [1, 1, 0.2, 0.8, 0.7, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPatchesGenerator = PatchIterator(\"/home/ubuntu/sealion/data/\", train_ids, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valPatchesGenerator = PatchIterator(\"/home/ubuntu/sealion/data/\", val_ids, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, [batch_y, batch_counts] in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape: \", batch_x.shape)\n",
    "print(\"Y shape: \", batch_y.shape)\n",
    "print(\"Counts shape: \", batch_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred, counts_pred = unet.predict(batch_x, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.argmax(batch_y[i,...], axis=-1))\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.argmax(y_pred[i,...], axis=-1))\n",
    "print(\"True counts: \", batch_counts[i, ...])\n",
    "print(\"Pred counts: \", counts_pred[i, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_img(smap):\n",
    "    colors_rgb = [(1, 7, 179), (178, 12, 178), (5, 41, 79), (177, 54, 26), (26, 171, 43), (0, 0, 0), (255, 255, 255)]\n",
    "    im = np.zeros(smap.shape + (3, ), dtype=np.uint8)\n",
    "    for i in range(7):\n",
    "        im[smap==i, :] = colors_rgb[i]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_freqs, counts_freqs = trainPatchesGenerator.compute_class_distribution(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts_mean(counts_freqs):\n",
    "    means = []\n",
    "    for c, freqs in counts_freqs.items():\n",
    "        sum_weighted = 0\n",
    "        total = 0\n",
    "        for cnt, f in freqs.items():\n",
    "            sum_weighted += cnt * f\n",
    "            total += f\n",
    "        means.append(sum_weighted/total)\n",
    "    return np.asarray(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_counts_mean(counts_freqs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_counts = np.max(get_counts_mean(counts_freqs))/get_counts_mean(counts_freqs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    weights = K.max(y_true * weights_per_class, axis=-1)\n",
    "    # Add the class ignored to the prediction, so that we can compute categorical_crossentropy\n",
    "    y_pred_pad = tf.pad(y_pred, [[0, 0], [0, 0], [0, 0], [0, 1]])\n",
    "    loss_per_pixel = K.categorical_crossentropy(y_pred_pad, y_true)\n",
    "    return K.mean(loss_per_pixel * weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counts_rmse(counts_true, counts_pred):\n",
    "    rmse_per_type = K.sqrt(K.mean(K.square(counts_true - counts_pred), axis=0))\n",
    "    return K.mean(rmse_per_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /home/ubuntu/data/sealion/data/models/segmentation_small_count/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_checkpoint = ModelCheckpoint(\"/home/ubuntu/data/sealion/data/models/segmentation_small_count/ckpt_{epoch:02d}-{val_loss:.2f}.h5\")\n",
    "cb_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, mode='auto', epsilon=0.01, cooldown=0, min_lr=0)\n",
    "tensorboard_cb = TensorBoardCallBack(log_dir=\"/home/ubuntu/data/sealion/data/models/segmentation_small_count//log_tb\", batch_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_per_class = np.array([1, 1, 1, 1, 1, 0.1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-3, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "unet.compile(optimizer=sgd, loss=[weighted_categorical_crossentropy, counts_rmse], loss_weights=[1.0, 1.0], metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = unet.fit_generator(trainPatchesGenerator, 1000, epochs=20,\n",
    "                           verbose=1, callbacks=[cb_checkpoint, cb_reduce_lr, tensorboard_cb],\n",
    "                           validation_data=valPatchesGenerator, validation_steps=200,\n",
    "                           class_weight=None,\n",
    "                           max_q_size=8, workers=4, pickle_safe=False,\n",
    "                           initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, [batch_y, counts] in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred, counts_pred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.argmax(batch_y[i,...], axis=-1))\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.argmax(y_pred[i,...], axis=-1))\n",
    "print(\"True counts: \", counts[i, ...])\n",
    "print(\"Pred counts: \", counts_pred[i, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet.save(\"../data/unet_segmentation_ellipse_dmap_sgd_10epochs_200steps.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, batch_y in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.min(batch_ypred[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg = np.argmax(batch_ypred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique(gg, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.argmax(batch_y[i,...], axis=-1))\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.argmax(batch_ypred[i,...], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0]) > 0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 7\n",
    "print(\"GT: \", np.sum(valPatchesGenerator.denormalize_output(batch_y[i,:,:, 0])))\n",
    "print(\"Pred: \", np.sum(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_image_process(im, net, patchGenerator, patch_size=(224, 224), batch_size=8, overlap=(64, 64)):\n",
    "    h, w, c = im.shape\n",
    "    n_patches_x = int(np.ceil((w - patch_size[1])/(patch_size[1] - overlap[1]) + 1))\n",
    "    n_patches_y = int(np.ceil((h - patch_size[0])/(patch_size[0] - overlap[0]) + 1))\n",
    "    print(n_patches_x, n_patches_x)\n",
    "    \n",
    "    dmap = np.zeros((h, w, 1), dtype=np.float32)\n",
    "    dmap_count = np.zeros((h, w, 1), dtype=np.int8)\n",
    "    batch_x = np.zeros((batch_size, ) + patch_size + (c, ), dtype=np.float32)\n",
    "    batch_pos = np.zeros((batch_size, 4), dtype=np.int32)\n",
    "    \n",
    "    current_batch_size = 0\n",
    "    for py in range(n_patches_y):\n",
    "        y_start = py * (patch_size[0] - overlap[0])\n",
    "        y_start = min(h - patch_size[0], y_start)\n",
    "        y_end = y_start + patch_size[0]\n",
    "        for px in range(n_patches_x):\n",
    "            x_start = px * (patch_size[1] - overlap[1])\n",
    "            x_start = min(w - patch_size[1], x_start)\n",
    "            x_end = x_start + patch_size[1]\n",
    "            \n",
    "            # Keep filling the batch\n",
    "            batch_x[current_batch_size, :, :, :] = im[y_start:y_end, x_start:x_end, :]\n",
    "            batch_pos[current_batch_size, :] = np.array([y_start, y_end, x_start, x_end])\n",
    "            current_batch_size += 1\n",
    "            \n",
    "            if current_batch_size == batch_size or (py == n_patches_y - 1 and px == n_patches_x - 1) :\n",
    "                # time to predict\n",
    "                batch_x_normed = patchGenerator.normalize_input(batch_x)\n",
    "                batch_ylog = net.predict(batch_x_normed)\n",
    "                batch_y = patchGenerator.denormalize_output(batch_ylog)\n",
    "                # Fill the full dmap\n",
    "                for i in range(current_batch_size):\n",
    "                    y_start, y_end, x_start, x_end = tuple(batch_pos[i,:])\n",
    "                    dmap[y_start:y_end, x_start:x_end, :] += batch_y[i,:,:,:]\n",
    "                    dmap_count[y_start:y_end, x_start:x_end] += 1\n",
    "                current_batch_size = 0\n",
    "                \n",
    "    return dmap, dmap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"../data/sealion/Train/872.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap, dmap_count = full_image_process(im, unet, valPatchesGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(dmap[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_avg = dmap/dmap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(dmap_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_gt = np.load(\"../data/sealion/TrainDensity/872_0.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
