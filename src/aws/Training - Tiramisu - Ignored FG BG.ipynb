{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.core import Dropout, Activation, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, Deconvolution2D, AtrousConvolution2D, UpSampling2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import mean_squared_error, mean_absolute_error, categorical_crossentropy, binary_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DenseNetFCN(input_shape, batch_norm=True, nb_dense_block=5, growth_rate=16, nb_layers_per_block=4,\n",
    "                reduction=0.0, dropout_rate=0.0, weight_decay=1E-4, init_conv_filters=48, classes=1):\n",
    "    \"\"\"Instantiate the DenseNet FCN architecture.\n",
    "        Note that when using TensorFlow,\n",
    "        for best performance you should set\n",
    "        `image_dim_ordering=\"tf\"` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        # Arguments\n",
    "            nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_layers_per_block: number of layers in each dense block.\n",
    "                Can be a positive integer or a list.\n",
    "                If positive integer, a set number of layers per dense block.\n",
    "                If list, nb_layer is used as provided. Note that list size must\n",
    "                be (nb_dense_block + 1)\n",
    "            reduction: reduction factor of transition blocks.\n",
    "                Note : reduction value is inverted to compute compression.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            init_conv_filters: number of layers in the initial convolution layer\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "            activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
    "                Note that if sigmoid is used, classes must be 1.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "    \"\"\"\n",
    "    if type(nb_layers_per_block) is not list and nb_dense_block < 1:\n",
    "        raise ValueError('Number of dense layers per block must be greater than 1. Argument '\n",
    "                         'value was %d.' % (nb_layers_per_block))\n",
    "\n",
    "    # Determine proper input shape\n",
    "    min_size = 2 ** nb_dense_block\n",
    "\n",
    "    if input_shape is not None:\n",
    "        if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
    "                (input_shape[1] is not None and input_shape[1] < min_size)):\n",
    "            raise ValueError('Input size must be at least ' +\n",
    "                             str(min_size) + 'x' + str(min_size) + ', got '\n",
    "                                                                   '`input_shape=' + str(input_shape) + '`')\n",
    "    else:\n",
    "        input_shape = (None, None, classes)\n",
    "\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = __create_fcn_dense_net(classes, img_input, batch_norm, nb_dense_block,\n",
    "                               growth_rate, reduction, dropout_rate, weight_decay,\n",
    "                               nb_layers_per_block,init_conv_filters, input_shape)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, x, name='fcn-densenet')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def __conv_block(ip, nb_filter, batch_norm=True, bottleneck=False, dropout_rate=None, weight_decay=1E-4):\n",
    "    ''' Apply BatchNorm, Relu, 3x3 Conv2D, optional bottleneck block and dropout\n",
    "    Args:\n",
    "        ip: Input keras tensor\n",
    "        nb_filter: number of filters\n",
    "        bottleneck: add bottleneck block\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: keras tensor with batch_norm, relu and convolution2d added (optional bottleneck)\n",
    "    '''\n",
    "\n",
    "    concat_axis = -1\n",
    "\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization(axis=concat_axis, gamma_regularizer=l2(weight_decay),\n",
    "                                beta_regularizer=l2(weight_decay))(ip)\n",
    "    else:\n",
    "        x = ip\n",
    "        \n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if bottleneck:\n",
    "        inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n",
    "\n",
    "        x = Convolution2D(inter_channel, 1, 1, init='he_uniform', border_mode='same', bias=False,\n",
    "                          W_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "        if dropout_rate:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization(axis=concat_axis, gamma_regularizer=l2(weight_decay),\n",
    "                                   beta_regularizer=l2(weight_decay))(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter, (3, 3), padding=\"same\", use_bias=False,\n",
    "                      kernel_initializer=\"he_uniform\",\n",
    "                      kernel_regularizer=l2(weight_decay))(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __transition_block(ip, nb_filter, batch_norm=True, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
    "    ''' Apply BatchNorm, Relu 1x1, Conv2D, optional compression, dropout and Maxpooling2D\n",
    "    Args:\n",
    "        ip: keras tensor\n",
    "        nb_filter: number of filters\n",
    "        compression: calculated as 1 - reduction. Reduces the number of feature maps\n",
    "                    in the transition block.\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: keras tensor, after applying batch_norm, relu-conv, dropout, maxpool\n",
    "    '''\n",
    "\n",
    "    concat_axis = -1\n",
    "\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization(axis=concat_axis, gamma_regularizer=l2(weight_decay),\n",
    "                               beta_regularizer=l2(weight_decay))(ip)\n",
    "    else:\n",
    "        x = ip\n",
    "        \n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(int(nb_filter * compression), (1, 1), padding=\"same\", use_bias=False,\n",
    "                      kernel_initializer=\"he_uniform\",\n",
    "                      kernel_regularizer=l2(weight_decay))(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __dense_block(x, nb_layers, nb_filter, growth_rate, batch_norm=True, bottleneck=False, dropout_rate=None, weight_decay=1E-4,\n",
    "                  grow_nb_filters=True, return_concat_list=False):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "    Args:\n",
    "        x: keras tensor\n",
    "        nb_layers: the number of layers of conv_block to append to the model.\n",
    "        nb_filter: number of filters\n",
    "        growth_rate: growth rate\n",
    "        bottleneck: bottleneck block\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "        grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "        return_concat_list: return the list of feature maps along with the actual output\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    '''\n",
    "\n",
    "    concat_axis = -1\n",
    "\n",
    "    x_list = [x]\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        x = __conv_block(x, growth_rate, batch_norm, bottleneck, dropout_rate, weight_decay)\n",
    "        x_list.append(x)\n",
    "\n",
    "        x = Concatenate(axis=concat_axis)(x_list)\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    if return_concat_list:\n",
    "        return x, nb_filter, x_list\n",
    "    else:\n",
    "        return x, nb_filter\n",
    "\n",
    "\n",
    "def __transition_up_block(ip):\n",
    "    ''' SubpixelConvolutional Upscaling (factor = 2)\n",
    "    Args:\n",
    "        ip: keras tensor\n",
    "    Returns: keras tensor, after applying upsampling operation.\n",
    "    '''\n",
    "    x = UpSampling2D()(ip)\n",
    "    return x\n",
    "\n",
    "\n",
    "def __create_fcn_dense_net(nb_classes, img_input, batch_norm=True, nb_dense_block=5, growth_rate=12,\n",
    "                           reduction=0.0, dropout_rate=None, weight_decay=1E-4,\n",
    "                           nb_layers_per_block=4, init_conv_filters=48,\n",
    "                           input_shape=None):\n",
    "    ''' Build the DenseNet model\n",
    "    Args:\n",
    "        nb_classes: number of classes\n",
    "        img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
    "        nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "        growth_rate: number of filters to add per dense block\n",
    "        reduction: reduction factor of transition blocks. Note : reduction value is inverted to compute compression\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay\n",
    "        nb_layers_per_block: number of layers in each dense block.\n",
    "            Can be a positive integer or a list.\n",
    "            If positive integer, a set number of layers per dense block.\n",
    "            If list, nb_layer is used as provided. Note that list size must\n",
    "            be (nb_dense_block + 1)\n",
    "        input_shape: Only used for shape inference in fully convolutional networks.\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    '''\n",
    "\n",
    "    concat_axis = -1\n",
    "    rows, cols, _ = input_shape\n",
    "\n",
    "    if reduction != 0.0:\n",
    "        assert reduction <= 1.0 and reduction > 0.0, \"reduction value must lie between 0.0 and 1.0\"\n",
    "\n",
    "    # layers in each dense block\n",
    "    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n",
    "        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n",
    "\n",
    "        assert len(nb_layers) == (nb_dense_block + 1), \"If list, nb_layer is used as provided. \" \\\n",
    "                                                       \"Note that list size must be (nb_dense_block + 1)\"\n",
    "\n",
    "        bottleneck_nb_layers = nb_layers[-1]\n",
    "        rev_layers = nb_layers[::-1]\n",
    "        nb_layers.extend(rev_layers[1:])\n",
    "    else:\n",
    "        bottleneck_nb_layers = nb_layers_per_block\n",
    "        nb_layers = [nb_layers_per_block] * (2 * nb_dense_block + 1)\n",
    "\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Initial convolution\n",
    "    x = Convolution2D(init_conv_filters, (3, 3), padding=\"same\", use_bias=False, \n",
    "                      kernel_initializer=\"he_uniform\",\n",
    "                      kernel_regularizer=l2(weight_decay),\n",
    "                      name=\"initial_conv2D\")(img_input)\n",
    "\n",
    "    nb_filter = init_conv_filters\n",
    "\n",
    "    skip_list = []\n",
    "\n",
    "    # Add dense blocks and transition down block\n",
    "    for block_idx in range(nb_dense_block):\n",
    "        x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter, growth_rate,\n",
    "                                     batch_norm=batch_norm,\n",
    "                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # Skip connection\n",
    "        skip_list.append(x)\n",
    "\n",
    "        # add transition_block\n",
    "        x = __transition_block(x, nb_filter,\n",
    "                               batch_norm=batch_norm,\n",
    "                               compression=compression, dropout_rate=dropout_rate,\n",
    "                               weight_decay=weight_decay)\n",
    "\n",
    "        nb_filter = int(nb_filter * compression)  # this is calculated inside transition_down_block\n",
    "\n",
    "    # The last dense_block does not have a transition_down_block\n",
    "    # return the concatenated feature maps without the concatenation of the input\n",
    "    _, nb_filter, concat_list = __dense_block(x, bottleneck_nb_layers, nb_filter, growth_rate,\n",
    "                                              batch_norm=batch_norm,\n",
    "                                              dropout_rate=dropout_rate, weight_decay=weight_decay,\n",
    "                                              return_concat_list=True)\n",
    "\n",
    "    skip_list = skip_list[::-1]  # reverse the skip list\n",
    "\n",
    "    # Add dense blocks and transition up block\n",
    "    for block_idx in range(nb_dense_block):\n",
    "        n_filters_keep = growth_rate * nb_layers[nb_dense_block + block_idx]\n",
    "\n",
    "        # upsampling block must upsample only the feature maps (concat_list[1:]),\n",
    "        # not the concatenation of the input with the feature maps (concat_list[0].\n",
    "        l = Concatenate(axis=concat_axis)(concat_list[1:])\n",
    "\n",
    "        t = __transition_up_block(l)\n",
    "\n",
    "        # concatenate the skip connection with the transition block\n",
    "        x = Concatenate(axis=concat_axis)([t, skip_list[block_idx]])\n",
    "\n",
    "        # Dont allow the feature map size to grow in upsampling dense blocks\n",
    "        _, nb_filter, concat_list = __dense_block(x, nb_layers[nb_dense_block + block_idx + 1], nb_filter=growth_rate,\n",
    "                                                  growth_rate=growth_rate, batch_norm=batch_norm,\n",
    "                                                  dropout_rate=dropout_rate,\n",
    "                                                  weight_decay=weight_decay,\n",
    "                                                  return_concat_list=True, grow_nb_filters=False)\n",
    "\n",
    "\n",
    "    x = Convolution2D(1, (1, 1), padding='same', use_bias=False,\n",
    "                      kernel_regularizer=l2(weight_decay),\n",
    "                      activation='sigmoid')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet = DenseNetFCN(input_shape=(None, None, 3), batch_norm=False, nb_dense_block=4, growth_rate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.ones((1, 224, 224, 3))\n",
    "p = unet.predict(t)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(unet, to_file='/home/ubuntu/data/tiramisu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from pkg_resources import parse_version\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorBoardCallBack(Callback):\n",
    "    \"\"\"Tensorboard basic visualizations.\n",
    "    This callback writes a log for TensorBoard, which allows\n",
    "    you to visualize dynamic graphs of your training and test\n",
    "    metrics, as well as activation histograms for the different\n",
    "    layers in your model.\n",
    "    TensorBoard is a visualization tool provided with TensorFlow.\n",
    "    If you have installed TensorFlow with pip, you should be able\n",
    "    to launch TensorBoard from the command line:\n",
    "    ```\n",
    "    tensorboard --logdir=/full_path_to_your_logs\n",
    "    ```\n",
    "    You can find more information about TensorBoard\n",
    "    [here](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html).\n",
    "    # Arguments\n",
    "        log_dir: the path of the directory where to save the log\n",
    "            files to be parsed by Tensorboard\n",
    "        batch_freq: frequency (in batch) at which to log data\n",
    "            If set to 0, we just log at the end of an epoch,\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 batch_freq=0):\n",
    "        super(TensorBoardCallBack, self).__init__()\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.batch_freq = batch_freq\n",
    "        self.merged = None\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        self.last_batch = 0\n",
    "        self.batch_offset = 0\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "\n",
    "        if hasattr(tf, 'merge_all_summaries'):\n",
    "            self.merged = tf.merge_all_summaries()\n",
    "        else:\n",
    "            self.merged = tf.summary.merge_all()\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Each time we go back to batch 0, we increase the batch_offset\n",
    "        if batch < self.last_batch:\n",
    "            self.batch_offset += self.last_batch + 1\n",
    "        self.last_batch = batch\n",
    "\n",
    "        batch_cross_epoch = self.batch_offset + batch\n",
    "        if batch_cross_epoch % self.batch_freq == 0:\n",
    "            logs = logs or {}\n",
    "\n",
    "            for name, value in logs.items():\n",
    "                if name in ['batch', 'size']:\n",
    "                    continue\n",
    "                summary = tf.Summary()\n",
    "                summary_value = summary.value.add()\n",
    "                summary_value.simple_value = value.item()\n",
    "                summary_value.tag = name\n",
    "                self.writer.add_summary(summary, batch_cross_epoch)\n",
    "            self.writer.flush()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_loc(shape, x, y, target_size=(396, 396), n_blocks=(4,4), overlap=(448,448)):\n",
    "    h, w = shape\n",
    "    w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "    h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "    for by in range(n_blocks[0]):\n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        for bx in range(n_blocks[1]):\n",
    "            x_start = bx * (w_block - overlap[1])\n",
    "            x_end = x_start + w_block + 1\n",
    "            \n",
    "            if x_start <= x < x_end and y_start <= y < y_end and\\\n",
    "            x_start <= x + target_size[1] - 1 < x_end and y_start <= y + target_size[0] - 1 < y_end:\n",
    "                return bx + by * n_blocks[0], x - x_start, y - y_start\n",
    "    raise NonValidPatch(\"Can't find block...??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 class_weights = None,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(224, 224),\n",
    "                 batch_size=16, shuffle=True, seed=42,\n",
    "                 debug_dir=None):\n",
    "        self.n_samples_per_block = 4\n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        \n",
    "        # Normalize to use class_weights as a probability distribution.\n",
    "        if class_weights:\n",
    "            self.class_weights = np.asarray(class_weights)/np.sum(class_weights)\n",
    "        else:\n",
    "            self.class_weights = np.ones((self.n_sealion_types+1))/(self.n_sealion_types + 1)\n",
    "        \n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size//self.n_samples_per_block, shuffle, seed)\n",
    "        \n",
    "    def compute_class_distribution(self, n_batches):\n",
    "        total = 0\n",
    "        count_per_classes = defaultdict(int)\n",
    "        for b in range(n_batches):\n",
    "            _, by = self.next()\n",
    "            ids, counts = np.unique(by, return_counts=True)\n",
    "            for i in range(ids.shape[0]):\n",
    "                count_per_classes[ids[i]] += counts[i]\n",
    "                total += counts[i]\n",
    "            \n",
    "        class_counts = []\n",
    "        for i in range(3):\n",
    "            class_counts.append(count_per_classes[i])\n",
    "        return class_counts\n",
    "\n",
    "    def normalize_input(self, x_bgr):\n",
    "        x = x_bgr.copy()\n",
    "        x[..., 0] -= 103.939\n",
    "        x[..., 1] -= 116.779\n",
    "        x[..., 2] -= 123.68\n",
    "        return x\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x = x_normed.copy()\n",
    "        x[..., 0] += 103.939\n",
    "        x[..., 1] += 116.779\n",
    "        x[..., 2] += 123.68\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, x, y):\n",
    "        flips = np.random.randint(0, 2, (3,))\n",
    "        if flips[0]:\n",
    "            x = np.rot90(x)\n",
    "            y = np.rot90(y)\n",
    "        if flips[1]:\n",
    "            x = np.flipud(x)\n",
    "            y = np.flipud(y)\n",
    "        if flips[2]:\n",
    "            x = np.fliplr(x)\n",
    "            y = np.fliplr(y)\n",
    "        return x, y\n",
    "\n",
    "    def get_weights(self, dots):\n",
    "        # Set probability to 0 if some sealion type is not in the block\n",
    "        current_weigths = self.class_weights.copy()\n",
    "        for i in range(self.n_sealion_types):\n",
    "            if not dots[i]:\n",
    "                current_weigths[i] = 0\n",
    "        current_weigths /= np.sum(current_weigths)\n",
    "        return current_weigths\n",
    "    \n",
    "    def sample_position(self, shape, dots, current_weigths):\n",
    "        # Choose an output class randomly\n",
    "        output_class = np.random.choice(self.n_sealion_types + 1, size=(1, ), p=current_weigths)[0]\n",
    "        # Sample a location, either for background or for a sealion.\n",
    "        if output_class == self.n_sealion_types:\n",
    "            # avoid bg with pups in it\n",
    "            return self.sample_bg(shape), output_class\n",
    "        else:\n",
    "            return self.sample_dot(shape, dots[output_class]), output_class\n",
    "                     \n",
    "    def get_dots_in_block(self, bid, shape, dots, target_size=(224, 224), n_blocks=(4,4), overlap=(448,448)):\n",
    "        h, w = shape\n",
    "        w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "        h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "        \n",
    "        bx = bid % n_blocks[0]\n",
    "        by = bid // n_blocks[0]\n",
    "        \n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        x_start = bx * (w_block - overlap[1])\n",
    "        x_end = x_start + w_block + 1\n",
    "        \n",
    "        dots_in_block = [[] for _ in range(self.n_sealion_types)]\n",
    "        for i, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                if x_start <= x < x_end and y_start <= y < y_end:\n",
    "                    dots_in_block[i].append((x - x_start, y - y_start))\n",
    "        return dots_in_block\n",
    "        \n",
    "    def get_random_block(self, image_id, shape, dots, current_weigths):\n",
    "        while True:\n",
    "            try:\n",
    "                (x, y), output_class = self.sample_position(shape, dots, current_weigths)\n",
    "                \n",
    "                # Get the corresponding image block, and (x, y) in this block\n",
    "                bid, x, y = get_block_loc(shape, x, y)\n",
    "                \n",
    "                # Load the block and check if it is valid\n",
    "                uid = \"{iid}_{bid}\".format(iid=image_id, bid=bid)\n",
    "                img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "                if img is not None:\n",
    "                    smap = np.load(os.path.join(self.root_dir, \"TrainFgBg\", uid + \".npz\"))['smap']\n",
    "                    return bid, img, smap\n",
    "            except NonValidPatch:\n",
    "                continue\n",
    "    \n",
    "    def sample(self, shape, dots, image_id):        \n",
    "        # If we are stuck on a \"bad\" block, we retry from scratch\n",
    "        while True:\n",
    "            # Set probability to 0 if some sealion type is not in the block\n",
    "            current_weigths = self.get_weights(dots)\n",
    "        \n",
    "            # Get a block randomly (but using the dots and the sampling weights)\n",
    "            bid, img, smap = self.get_random_block(image_id, shape, dots, current_weigths)\n",
    "                \n",
    "            # Recompute dots in the blocks, and sampling weights\n",
    "            dots_block = self.get_dots_in_block(bid, shape, dots)\n",
    "            current_weigths = self.get_weights(dots_block)\n",
    "\n",
    "            # Now, sample n_samples_per_block patches from it\n",
    "            n_samples = 0\n",
    "            bx = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1], 3))\n",
    "            by = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1]))\n",
    "\n",
    "            # Stop if we try too many times, \n",
    "            max_iterations = self.n_samples_per_block * 5\n",
    "            current_iteration = 0\n",
    "            while n_samples < self.n_samples_per_block and current_iteration < max_iterations:\n",
    "                current_iteration += 1\n",
    "                try:\n",
    "                    (x, y), output_class = self.sample_position(img.shape[:2], dots_block, current_weigths)\n",
    "                    img_patch = img[y:y+self.target_size[0], x:x+self.target_size[1],:]\n",
    "                    if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                        continue\n",
    "                    smap_patch = smap[y:y+self.target_size[0], x:x+self.target_size[1]]\n",
    "                    img_patch, smap_patch = self.random_transform(img_patch, smap_patch)             \n",
    "                    \n",
    "                    bx[n_samples, ...] = img_patch\n",
    "                    by[n_samples, ...] = smap_patch\n",
    "                    n_samples += 1\n",
    "                except NonValidPatch:\n",
    "                    continue\n",
    "                    \n",
    "            if current_iteration < max_iterations:\n",
    "                return bx, by\n",
    "            # else, we tried too many times, let's get another block.\n",
    "        \n",
    "    def sample_bg(self, shape):\n",
    "        \"\"\" Just sample a random patch\n",
    "        \"\"\"\n",
    "        x = np.random.randint(0, shape[1] - self.target_size[1], size=(1,))[0]\n",
    "        y = np.random.randint(0, shape[0] - self.target_size[0], size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def sample_dot(self, shape, dots):\n",
    "        \"\"\" Sample so that a random selected sealion is fully inside the patch\n",
    "        \"\"\"\n",
    "        half_size = 40\n",
    "        \n",
    "        randi = np.random.choice(len(dots), size=(1,))[0]\n",
    "        rand_dot = dots[randi]\n",
    "        \n",
    "        min_x = max(0, rand_dot[0] - self.target_size[1] + half_size)\n",
    "        max_x = min(shape[1] - self.target_size[1], rand_dot[0] + self.target_size[1] - half_size)\n",
    "        \n",
    "        min_y = max(0, rand_dot[1] - self.target_size[0] + half_size)\n",
    "        max_y = min(shape[0] - self.target_size[0], rand_dot[1] + self.target_size[0] - half_size)\n",
    "        \n",
    "        if min_x > max_x:\n",
    "            max_x, min_x = min_x, max_x\n",
    "        if min_y > max_y:\n",
    "            max_y, min_y = min_y, max_y \n",
    "            \n",
    "        if min_x == max_x or min_y == max_y:\n",
    "            raise NonValidPatch()\n",
    "           \n",
    "        x = np.random.randint(min_x, max_x, size=(1,))[0]\n",
    "        y = np.random.randint(min_y, max_y, size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_samples_per_block,\n",
    "                            self.target_size[0],\n",
    "                            self.target_size[1],\n",
    "                            3),\n",
    "                           dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size * self.n_samples_per_block,\n",
    "                            self.target_size[0],\n",
    "                            self.target_size[1]),\n",
    "                           dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "                \n",
    "            x, y = self.sample(shape, dots, image_id)\n",
    "            batch_x[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = x\n",
    "            batch_y[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = y \n",
    "\n",
    "        if self.debug_dir:\n",
    "            for i in range(batch_x.shape[0]):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"smap_{}.jpg\".format(i)), to_img(batch_y[i]))\n",
    "                \n",
    "        permut = np.random.permutation(batch_x.shape[0])\n",
    "        # swap foreground and ignore label\n",
    "        batch_y[batch_y==1]=3\n",
    "        batch_y[batch_y==2]=1\n",
    "        batch_y[batch_y==3]=2\n",
    "        return self.normalize_input(batch_x[permut, ...]), batch_y[permut, ...].reshape(-1, self.target_size[0], self.target_size[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(iid) for iid in train_ids]\n",
    "\n",
    "with open(\"../data/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(iid) for iid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = [1, 1, 1, 1, 1, 1/20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPatchesGenerator = PatchIterator(\"/home/ubuntu/sealion/data/\", train_ids, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valPatchesGenerator = PatchIterator(\"/home/ubuntu/sealion/data/\", val_ids, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, batch_y in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bpred = unet.predict(batch_x, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(batch_y[i,..., 0])\n",
    "plt.subplot(133)\n",
    "plt.imshow(bpred[i,..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes_counts = trainPatchesGenerator.compute_class_distribution(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60907971/1919868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_fg = 3.17\n",
    "weight_bg = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy_ignore(y_true, y_pred):\n",
    "    \"\"\" ypred: b, h, w, 1, value between 0 and 1\n",
    "        ytrue: b, h, w, 1, value 0, 1 or 2\n",
    "    \"\"\"\n",
    "    mask_bg = K.cast(K.equal(y_true, 0), K.floatx())\n",
    "    mask_fg = K.cast(K.equal(y_true, 1), K.floatx())\n",
    "    weights = (mask_fg * weight_fg + mask_bg * weight_bg)\n",
    "    loss_per_pixel = K.binary_crossentropy(y_true, y_pred)\n",
    "    loss_weighted = loss_per_pixel * weights\n",
    "    sum_weights = K.sum(weights)\n",
    "    sum_loss = K.sum(loss_weighted)\n",
    "    return sum_loss/sum_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_ign(y_true, y_pred):\n",
    "    mask_ign = K.cast(K.not_equal(y_true, 2), K.floatx())\n",
    "    y_pred_th = K.round(K.clip(y_pred, 0, 1))\n",
    "    correct_predictions = K.sum(K.cast(K.equal(y_true, y_pred_th), K.floatx()) * mask_ign)\n",
    "    total_predictions = K.sum(mask_ign)\n",
    "    return correct_predictions/total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = K.reshape(K.constant(np.array([[0, 1, 2], [0, 2, 1], [1, 1, 0]])), (1, 3, 3))\n",
    "\n",
    "y_pred = K.reshape(K.constant(np.array([[0.1, 0.9, 1.0], [0.8, 2, 0.99], [0.01, 0.9, 0.01]])), (1, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = weighted_binary_crossentropy_ignore(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_ign(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(\"loss: \", loss.eval())\n",
    "    print(\"acc: \", acc.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    mask_ign = K.cast(K.not_equal(y_true, 2), K.floatx())\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)) * mask_ign)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)) * mask_ign)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    mask_ign = K.cast(K.not_equal(y_true, 2), K.floatx())\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)) * mask_ign)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)) * mask_ign)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    \"\"\"Computes the F score.\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    \"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "    \"\"\"\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /home/ubuntu/data/sealion/data/models/segmentation_tiramisu/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_checkpoint = ModelCheckpoint(\"/home/ubuntu/data/sealion/data/models/segmentation_tiramisu/ckpt_{epoch:02d}-{val_loss:.2f}.h5\")\n",
    "cb_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', epsilon=0.01, cooldown=0, min_lr=0)\n",
    "tensorboard_cb = TensorBoardCallBack(log_dir=\"/home/ubuntu/data/sealion/data/models/segmentation_tiramisu/log_tb\", batch_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "unet.compile(optimizer=sgd, loss=weighted_binary_crossentropy_ignore, metrics=[accuracy_ign, fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = unet.fit_generator(trainPatchesGenerator, 1000, epochs=20,\n",
    "                       verbose=1, callbacks=[cb_checkpoint, cb_reduce_lr, tensorboard_cb],\n",
    "                       validation_data=valPatchesGenerator, validation_steps=200,\n",
    "                       class_weight=None,\n",
    "                       max_q_size=16, workers=4, pickle_safe=False,\n",
    "                       initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, batch_y in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bpred = unet.predict(batch_x, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 7\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(batch_y[i,..., 0])\n",
    "plt.subplot(133)\n",
    "plt.imshow(bpred[i,..., 0] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
