{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Activation, Cropping2D, Reshape, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error, categorical_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Reshape, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from pkg_resources import parse_version\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorBoardCallBack(Callback):\n",
    "    \"\"\"Tensorboard basic visualizations.\n",
    "    This callback writes a log for TensorBoard, which allows\n",
    "    you to visualize dynamic graphs of your training and test\n",
    "    metrics, as well as activation histograms for the different\n",
    "    layers in your model.\n",
    "    TensorBoard is a visualization tool provided with TensorFlow.\n",
    "    If you have installed TensorFlow with pip, you should be able\n",
    "    to launch TensorBoard from the command line:\n",
    "    ```\n",
    "    tensorboard --logdir=/full_path_to_your_logs\n",
    "    ```\n",
    "    You can find more information about TensorBoard\n",
    "    [here](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html).\n",
    "    # Arguments\n",
    "        log_dir: the path of the directory where to save the log\n",
    "            files to be parsed by Tensorboard\n",
    "        batch_freq: frequency (in batch) at which to log data\n",
    "            If set to 0, we just log at the end of an epoch,\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 batch_freq=0):\n",
    "        super(TensorBoardCallBack, self).__init__()\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.batch_freq = batch_freq\n",
    "        self.merged = None\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        self.last_batch = 0\n",
    "        self.batch_offset = 0\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "\n",
    "        if hasattr(tf, 'merge_all_summaries'):\n",
    "            self.merged = tf.merge_all_summaries()\n",
    "        else:\n",
    "            self.merged = tf.summary.merge_all()\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        # Each time we go back to batch 0, we increase the batch_offset\n",
    "        if batch < self.last_batch:\n",
    "            self.batch_offset += self.last_batch + 1\n",
    "        self.last_batch = batch\n",
    "\n",
    "        batch_cross_epoch = self.batch_offset + batch\n",
    "        if batch_cross_epoch % self.batch_freq == 0:\n",
    "            logs = logs or {}\n",
    "\n",
    "            for name, value in logs.items():\n",
    "                if name in ['batch', 'size']:\n",
    "                    continue\n",
    "                summary = tf.Summary()\n",
    "                summary_value = summary.value.add()\n",
    "                summary_value.simple_value = value.item()\n",
    "                summary_value.tag = name\n",
    "                self.writer.add_summary(summary, batch_cross_epoch)\n",
    "            self.writer.flush()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        for name, value in logs.items():\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_down_block(x, n_filters, block_id, with_maxpool=True, activation=\"elu\"):\n",
    "    y = Conv2D(n_filters, (3, 3), activation=activation, \n",
    "               padding='valid', name=\"conv{}_1\".format(block_id))(x)\n",
    "    print(y.shape)\n",
    "    y = BatchNormalization(name=\"bn{}_1\".format(block_id))(y)\n",
    "    \n",
    "    y = Conv2D(n_filters, (3, 3), activation=activation,\n",
    "               padding='valid', name=\"conv{}_2\".format(block_id))(y)\n",
    "    conv = BatchNormalization(name=\"bn{}_2\".format(block_id))(y)\n",
    "    print(y.shape)\n",
    "    if not with_maxpool:\n",
    "        return conv\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2), name=\"max_pool{}\".format(block_id))(conv)\n",
    "    print(pool.shape)\n",
    "    return conv, pool    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_up_block(x, y, n_filters, block_id, activation=\"elu\"):\n",
    "    up_x = UpSampling2D(size=(2, 2), name=\"upsample{}\".format(block_id))(x)\n",
    "    \n",
    "    # Compute crop needed to have the same shape for up_x and y\n",
    "    _, hx, wx, _ = up_x.shape\n",
    "    _, hy, wy, _ = y.shape\n",
    "    cropy = int(hy - hx)//2\n",
    "    cropx = int(wy - wx)//2\n",
    "    crop_y = Cropping2D(cropping=((cropy, cropy), (cropx, cropx)),\n",
    "                        name=\"crop{}\".format(block_id))(y)\n",
    "    print(\"Crop: \", cropy, cropx)\n",
    "    up = concatenate([up_x, crop_y], axis=-1,\n",
    "                     name=\"concat{}\".format(block_id))\n",
    "    print(up.shape)\n",
    "    up = Conv2D(n_filters, (3, 3), \n",
    "                activation=activation,\n",
    "                padding='valid',\n",
    "                name=\"conv{}_1\".format(block_id))(up)\n",
    "    print(up.shape)\n",
    "    up = Conv2D(n_filters, (3, 3),\n",
    "                activation=activation,\n",
    "                padding='valid',\n",
    "                name=\"conv{}_2\".format(block_id))(up)\n",
    "    print(up.shape)\n",
    "    return up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_count = 128\n",
    "precision = 2\n",
    "n_bins = max_count/precision + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cntnet(im_height, im_width, n_channels=1, n_classes=6,\n",
    "                 n_filters=[64, 128, 256, 512, 1024]):\n",
    "    inputs = Input((im_height, im_width, n_channels))\n",
    "    \n",
    "    conv1, pool1 = unet_down_block(inputs, n_filters[0], 1)\n",
    "    conv2, pool2 = unet_down_block(pool1,  n_filters[1], 2)\n",
    "    conv3, pool3 = unet_down_block(pool2,  n_filters[2], 3)\n",
    "    conv4, pool4 = unet_down_block(pool3,  n_filters[3], 4)\n",
    "    conv5 = unet_down_block(pool4, n_filters[4], 5, with_maxpool=False)\n",
    "    conv6 = Conv2D(64, (1, 1), activation=\"elu\")(conv5)\n",
    "    flatten = Flatten(name=\"flat_conv5\")(conv6)\n",
    "    counts = []\n",
    "    for i in range(5):\n",
    "        cnt = Dense(64, activation='softmax', name='counts_{}'.format(i))(flatten)\n",
    "        counts.append(cnt)\n",
    "    model = Model(inputs=[inputs], outputs=counts, name=\"cnt_net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 510, 510, 32)\n",
      "(?, 508, 508, 32)\n",
      "(?, 254, 254, 32)\n",
      "(?, 252, 252, 64)\n",
      "(?, 250, 250, 64)\n",
      "(?, 125, 125, 64)\n",
      "(?, 123, 123, 128)\n",
      "(?, 121, 121, 128)\n",
      "(?, 60, 60, 128)\n",
      "(?, 58, 58, 256)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 256)\n",
      "(?, 26, 26, 512)\n",
      "(?, 24, 24, 512)\n"
     ]
    }
   ],
   "source": [
    "unet = get_cntnet( 512, 512, 1, n_filters=[32, 64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts output:  [array([[ 0.01679845,  0.0147111 ,  0.01433711,  0.01361067,  0.01527904,\n",
      "         0.01796181,  0.01472435,  0.01757992,  0.01453477,  0.01416406,\n",
      "         0.01636623,  0.01666088,  0.01537805,  0.01648011,  0.01295653,\n",
      "         0.01746112,  0.01436688,  0.01468341,  0.01658837,  0.01318694,\n",
      "         0.01410331,  0.01552801,  0.01436455,  0.01290928,  0.01434053,\n",
      "         0.01201358,  0.0167123 ,  0.01479643,  0.01619869,  0.0126367 ,\n",
      "         0.01844923,  0.01509077,  0.01334485,  0.01703164,  0.01854808,\n",
      "         0.01721284,  0.01693775,  0.01912404,  0.0164237 ,  0.01537149,\n",
      "         0.01498435,  0.01671297,  0.01678836,  0.01816384,  0.01475664,\n",
      "         0.01754376,  0.01434493,  0.01458366,  0.01415847,  0.01780373,\n",
      "         0.01689469,  0.01787047,  0.0150187 ,  0.01827472,  0.01561543,\n",
      "         0.01274641,  0.01526002,  0.0149188 ,  0.0141732 ,  0.01747424,\n",
      "         0.01684515,  0.01349454,  0.01547644,  0.01712885]], dtype=float32), array([[ 0.01468844,  0.01458998,  0.01436813,  0.01450922,  0.01478309,\n",
      "         0.01838469,  0.01589531,  0.01838198,  0.01519278,  0.01544606,\n",
      "         0.01763718,  0.01683656,  0.01652749,  0.01345084,  0.01803143,\n",
      "         0.01803672,  0.01530301,  0.0135781 ,  0.01526409,  0.01448795,\n",
      "         0.0175533 ,  0.01447716,  0.01594792,  0.01362466,  0.01735458,\n",
      "         0.01784955,  0.01604119,  0.01445824,  0.01222253,  0.01923533,\n",
      "         0.01444643,  0.01452134,  0.01491309,  0.01590268,  0.01350731,\n",
      "         0.01549201,  0.01494545,  0.01694096,  0.01418108,  0.01406692,\n",
      "         0.01607759,  0.01634248,  0.01191595,  0.01415693,  0.01657934,\n",
      "         0.01793074,  0.01668028,  0.01663327,  0.01554691,  0.01282469,\n",
      "         0.01667114,  0.01339878,  0.01599177,  0.01557742,  0.01690715,\n",
      "         0.01636524,  0.0192148 ,  0.01800116,  0.01391922,  0.01275376,\n",
      "         0.01558368,  0.01417845,  0.01848102,  0.01519336]], dtype=float32), array([[ 0.01796186,  0.01665496,  0.01758477,  0.01303447,  0.01457975,\n",
      "         0.01726976,  0.01484438,  0.013093  ,  0.01597228,  0.01623557,\n",
      "         0.0161048 ,  0.0160147 ,  0.01891069,  0.01607113,  0.01391334,\n",
      "         0.01424273,  0.01565006,  0.01607053,  0.01558582,  0.01387505,\n",
      "         0.02054315,  0.0177445 ,  0.01927378,  0.01774524,  0.01663314,\n",
      "         0.01518257,  0.01454035,  0.01338827,  0.01253275,  0.01536529,\n",
      "         0.01627058,  0.01467129,  0.01794676,  0.01470309,  0.01685774,\n",
      "         0.01455892,  0.01532555,  0.01314593,  0.01790107,  0.01536276,\n",
      "         0.01579051,  0.01363024,  0.02080469,  0.01452181,  0.0150279 ,\n",
      "         0.01452993,  0.01419619,  0.01468667,  0.01814086,  0.015381  ,\n",
      "         0.01510914,  0.01547527,  0.01441434,  0.01335813,  0.01604211,\n",
      "         0.01400631,  0.01372323,  0.01561636,  0.01600057,  0.0151026 ,\n",
      "         0.01303497,  0.01884871,  0.01277604,  0.01642006]], dtype=float32), array([[ 0.01393984,  0.01272477,  0.01461267,  0.012989  ,  0.01646951,\n",
      "         0.01443126,  0.02023496,  0.01842242,  0.01605474,  0.01417824,\n",
      "         0.01449697,  0.01352797,  0.01648455,  0.01474881,  0.01624304,\n",
      "         0.01766616,  0.01282962,  0.01627422,  0.01457867,  0.01622696,\n",
      "         0.01493038,  0.01733774,  0.01558264,  0.01446447,  0.0154427 ,\n",
      "         0.015207  ,  0.01578087,  0.02030584,  0.01383896,  0.01876912,\n",
      "         0.0125096 ,  0.01618595,  0.0145354 ,  0.01442513,  0.01381365,\n",
      "         0.01725209,  0.01751408,  0.0181882 ,  0.01557441,  0.01758388,\n",
      "         0.01184291,  0.01775751,  0.01636625,  0.01740169,  0.01445644,\n",
      "         0.01560393,  0.02528161,  0.01406776,  0.01336607,  0.01582912,\n",
      "         0.01453406,  0.01449051,  0.01548656,  0.01509997,  0.01699509,\n",
      "         0.01577034,  0.01482572,  0.01461128,  0.017765  ,  0.01403962,\n",
      "         0.01829926,  0.01592924,  0.01199169,  0.01181189]], dtype=float32), array([[ 0.01343569,  0.01252166,  0.01989433,  0.0165579 ,  0.01342708,\n",
      "         0.01498588,  0.01507808,  0.0144818 ,  0.01945424,  0.01500777,\n",
      "         0.01424179,  0.01495895,  0.01485704,  0.01793389,  0.01448139,\n",
      "         0.01604727,  0.01334434,  0.01557645,  0.01382351,  0.01509593,\n",
      "         0.01417452,  0.01427201,  0.01498053,  0.01440151,  0.01528282,\n",
      "         0.01286439,  0.01718976,  0.01847766,  0.01601588,  0.01645262,\n",
      "         0.01685398,  0.01244444,  0.01246905,  0.01865039,  0.01675981,\n",
      "         0.01484203,  0.01587068,  0.01256006,  0.01988104,  0.01303731,\n",
      "         0.01792535,  0.01496324,  0.01467612,  0.01741934,  0.01490244,\n",
      "         0.0168642 ,  0.01349856,  0.02063989,  0.01535346,  0.01600271,\n",
      "         0.01409125,  0.02024297,  0.01617692,  0.02255114,  0.01519826,\n",
      "         0.01487049,  0.0155617 ,  0.01612698,  0.014099  ,  0.01442864,\n",
      "         0.01512856,  0.01651914,  0.01438113,  0.01569302]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "t = np.ones((1, 512, 512, 1))\n",
    "counts = unet.predict(t)\n",
    "print(\"Counts output: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = (512 - 24 * 16)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 512, 512, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                 (None, 510, 510, 32)  320                                          \n",
      "____________________________________________________________________________________________________\n",
      "bn1_1 (BatchNormalization)       (None, 510, 510, 32)  128                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv1_2 (Conv2D)                 (None, 508, 508, 32)  9248                                         \n",
      "____________________________________________________________________________________________________\n",
      "bn1_2 (BatchNormalization)       (None, 508, 508, 32)  128                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)         (None, 254, 254, 32)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                 (None, 252, 252, 64)  18496                                        \n",
      "____________________________________________________________________________________________________\n",
      "bn2_1 (BatchNormalization)       (None, 252, 252, 64)  256                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2 (Conv2D)                 (None, 250, 250, 64)  36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "bn2_2 (BatchNormalization)       (None, 250, 250, 64)  256                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)         (None, 125, 125, 64)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1 (Conv2D)                 (None, 123, 123, 128) 73856                                        \n",
      "____________________________________________________________________________________________________\n",
      "bn3_1 (BatchNormalization)       (None, 123, 123, 128) 512                                          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2 (Conv2D)                 (None, 121, 121, 128) 147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "bn3_2 (BatchNormalization)       (None, 121, 121, 128) 512                                          \n",
      "____________________________________________________________________________________________________\n",
      "max_pool3 (MaxPooling2D)         (None, 60, 60, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1 (Conv2D)                 (None, 58, 58, 256)   295168                                       \n",
      "____________________________________________________________________________________________________\n",
      "bn4_1 (BatchNormalization)       (None, 58, 58, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2 (Conv2D)                 (None, 56, 56, 256)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "bn4_2 (BatchNormalization)       (None, 56, 56, 256)   1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "max_pool4 (MaxPooling2D)         (None, 28, 28, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1 (Conv2D)                 (None, 26, 26, 512)   1180160                                      \n",
      "____________________________________________________________________________________________________\n",
      "bn5_1 (BatchNormalization)       (None, 26, 26, 512)   2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2 (Conv2D)                 (None, 24, 24, 512)   2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "bn5_2 (BatchNormalization)       (None, 24, 24, 512)   2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 24, 24, 64)    32832                                        \n",
      "____________________________________________________________________________________________________\n",
      "flat_conv5 (Flatten)             (None, 36864)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "counts_0 (Dense)                 (None, 64)            2359360                                      \n",
      "____________________________________________________________________________________________________\n",
      "counts_1 (Dense)                 (None, 64)            2359360                                      \n",
      "____________________________________________________________________________________________________\n",
      "counts_2 (Dense)                 (None, 64)            2359360                                      \n",
      "____________________________________________________________________________________________________\n",
      "counts_3 (Dense)                 (None, 64)            2359360                                      \n",
      "____________________________________________________________________________________________________\n",
      "counts_4 (Dense)                 (None, 64)            2359360                                      \n",
      "====================================================================================================\n",
      "Total params: 16,549,216\n",
      "Trainable params: 16,545,248\n",
      "Non-trainable params: 3,968\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 class_weights,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(512, 512),\n",
    "                 scale = 4,\n",
    "                 crop = (64, 64),\n",
    "                 batch_size=16, shuffle=True, seed=42,\n",
    "                 debug_dir=None):\n",
    "        self.n_samples_per_block = 8\n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        # Normalize to use class_weights as a probability distribution.\n",
    "        if class_weights:\n",
    "            self.class_weights = np.asarray(class_weights)/np.sum(class_weights)\n",
    "        else:\n",
    "            self.class_weights = np.ones((self.n_sealion_types+1))/(self.n_sealion_types + 1)\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.crop = crop\n",
    "        self.scale = scale\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size//self.n_samples_per_block, shuffle, seed)\n",
    "        \n",
    "    def compute_class_distribution(self, n_batches):\n",
    "        seg_freqs = defaultdict(int)\n",
    "        count_freqs = {0: defaultdict(int),\n",
    "                             1: defaultdict(int),\n",
    "                             2: defaultdict(int),\n",
    "                             3: defaultdict(int),\n",
    "                             4: defaultdict(int)}\n",
    "        for b in range(n_batches):\n",
    "            _, [by, bcounts] = self.next()\n",
    "            by = np.argmax(by, axis=-1)\n",
    "            ids, freqs = np.unique(by, return_counts=True)\n",
    "            for i in range(ids.shape[0]):\n",
    "                seg_freqs[ids[i]] += freqs[i]\n",
    "            for b in range(bcounts.shape[0]):\n",
    "                counts = bcounts[b]\n",
    "                for i in range(counts.shape[0]):\n",
    "                    count_freqs[i][counts[i]] += 1\n",
    "        \n",
    "        return seg_freqs, count_freqs\n",
    "\n",
    "    def normalize_input(self, x_bgr):\n",
    "        x = x_bgr.copy()\n",
    "        return x\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x = x_normed.copy()\n",
    "        return x\n",
    "\n",
    "    def normalize_output(self, y):\n",
    "        yc = y.copy()\n",
    "        for i in range(y.shape[0]):\n",
    "            yc[i] = self.quantify(y[i])\n",
    "        return to_categorical(yc, 64)\n",
    "    \n",
    "    def quantify(self, y):\n",
    "        if y == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(y//2 + 1, 63)\n",
    "        \n",
    "    def dequantify(self, y_normed):\n",
    "        if y_normed == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            cnt = (y_normed - 1) * 2\n",
    "            if cnt == 0:\n",
    "                cnt = 1\n",
    "            return cnt\n",
    "        \n",
    "    def denormalize_output(self, y_normed): \n",
    "        yc = y_normed.copy()\n",
    "        for i in range(y_normed.shape[0]):\n",
    "            yc[i] = self.dequantifiy(y_normed[i])\n",
    "        return yc\n",
    "        \n",
    "    def random_transform(self, x):\n",
    "        flips = np.random.randint(0, 2, (3,))\n",
    "        if flips[0]:\n",
    "            x = np.rot90(x)\n",
    "        if flips[1]:\n",
    "            x = np.flipud(x)\n",
    "        if flips[2]:\n",
    "            x = np.fliplr(x)\n",
    "        return x\n",
    "                     \n",
    "    def get_dots_in_patch(self, sx, sy, dots):\n",
    "        dots_in_patch = [[] for _ in dots]\n",
    "        for i, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                if sx <= x < sx + self.target_size[1] and sy <= y < sy + self.target_size[0]:\n",
    "                    dots_in_patch[i].append((x - sx, y - sy))\n",
    "        return dots_in_patch\n",
    "    \n",
    "    def build_counts(self, dots):\n",
    "        h = (self.target_size[0] - 2 * self.crop[0])//self.scale\n",
    "        w = (self.target_size[1] - 2 * self.crop[1])//self.scale\n",
    "        counts = np.zeros((5, ), dtype=np.int32)\n",
    "        for c, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                xr = int(round((x - self.crop[1])/self.scale))\n",
    "                yr = int(round((y - self.crop[0])/self.scale))\n",
    "\n",
    "                if 0 <= xr < w and 0 <= yr < h:\n",
    "                    counts[c] += 1\n",
    "        return counts\n",
    "          \n",
    "    def get_weights(self, dots):\n",
    "        # Set probability to 0 if some sealion type is not in the block\n",
    "        current_weigths = self.class_weights.copy()\n",
    "        for i in range(self.n_sealion_types):\n",
    "            if not dots[i]:\n",
    "                current_weigths[i] = 0\n",
    "        current_weigths /= np.sum(current_weigths)\n",
    "        return current_weigths\n",
    "    \n",
    "    def sample(self, shape, dots, image_id):\n",
    "        margin = self.crop[0] + 30\n",
    "        max_iterations = self.n_samples_per_block * 5\n",
    "        \n",
    "        smap = np.load(os.path.join(self.root_dir, \"TrainSegmentationIgnored2x\", str(image_id) + \".npz\"))[\"smap\"]                                                                          \n",
    "        n_samples = 0\n",
    "        bx = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1]))\n",
    "        bcounts = np.zeros((self.n_samples_per_block, 5))\n",
    "\n",
    "        current_iteration = 0\n",
    "        weights = self.get_weights(dots)\n",
    "        \n",
    "        # Samples n dots, with some probabilty to get the background only\n",
    "        while n_samples < self.n_samples_per_block and current_iteration < max_iterations:\n",
    "            current_iteration += 1\n",
    "            try:\n",
    "                # Choose an output class randomly\n",
    "                output_class = np.random.choice(self.n_sealion_types + 1, size=(1, ), p=weights)[0]\n",
    "                \n",
    "                # Background, select randomly a patch in the image (high chance to get only background)\n",
    "                if output_class == self.n_sealion_types:\n",
    "                    sx_min = 0\n",
    "                    sx_max = shape[1] - self.target_size[1]\n",
    "                    sy_min = 0\n",
    "                    sy_max = shape[0] - self.target_size[0]\n",
    "                # Choose a dot randomly in that class\n",
    "                else:  \n",
    "                    dot_index = np.random.randint(0, len(dots[output_class]))\n",
    "                    rx, ry = dots[output_class][dot_index]\n",
    "                    sx_min = min(max(0, rx - self.target_size[1] + margin), shape[1] - self.target_size[1])\n",
    "                    sx_max = min(max(0, rx - margin), shape[1] - self.target_size[1])\n",
    "                    sy_min = min(max(0, ry - self.target_size[0] + margin), shape[0] - self.target_size[1])\n",
    "                    sy_max = min(max(0, ry - margin), shape[0] - self.target_size[0]) \n",
    "                \n",
    "                    if sx_min >= sx_max:\n",
    "                        sx_min = min(max(0, rx - self.target_size[1]), shape[1] - self.target_size[1])\n",
    "                        sx_max = min(max(0, rx), shape[1] - self.target_size[1])\n",
    "                        \n",
    "                    if sy_min >= sy_max:\n",
    "                        sy_min = min(max(0, ry - self.target_size[0]), shape[0] - self.target_size[1])\n",
    "                        sy_max = min(max(0, ry), shape[0] - self.target_size[0]) \n",
    "                    \n",
    "                if sx_min >= sx_max or sy_min >= sy_max:\n",
    "                        continue\n",
    "                        \n",
    "                # Choose the top-left corner so that the dot selected is in the patch.\n",
    "                sx = np.random.randint(sx_min, sx_max)\n",
    "                sy = np.random.randint(sy_min, sy_max)\n",
    "\n",
    "                dots_in_patch = self.get_dots_in_patch(sx, sy, dots)\n",
    "                \n",
    "                smap_patch = smap[sy:sy+self.target_size[0], sx:sx+self.target_size[1]]\n",
    "                counts = self.build_counts(dots_in_patch)\n",
    "                smap_patch = self.random_transform(smap_patch)\n",
    "                bx[n_samples, ...] = smap_patch\n",
    "                bcounts[n_samples, ...] = counts\n",
    "                n_samples += 1\n",
    "            except NonValidPatch:\n",
    "                continue\n",
    "                    \n",
    "        if current_iteration < max_iterations:\n",
    "            return bx, bcounts\n",
    "        else:\n",
    "            print(\"Error with image \", image_id)\n",
    "            raise Exception(\"hoho\")\n",
    "    \n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_samples_per_block,\n",
    "                            self.target_size[0],\n",
    "                            self.target_size[1]),\n",
    "                           dtype=K.floatx())\n",
    "        batch_counts = np.zeros((current_batch_size * self.n_samples_per_block, 5), dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "            \n",
    "            # Scale dots coordinates\n",
    "            dots_resized = []\n",
    "            for ds in dots:\n",
    "                ds_resized = []\n",
    "                for (x, y) in ds:\n",
    "                    ds_resized.append((x//2, y//2))\n",
    "                dots_resized.append(ds_resized)\n",
    "                \n",
    "            shape = (shape[0]//2, shape[1]//2)\n",
    "                                      \n",
    "                \n",
    "            x, counts = self.sample(shape, dots_resized, image_id)\n",
    "            batch_x[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = x\n",
    "            batch_counts[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = counts\n",
    "        \n",
    "        b, h, w = batch_x.shape\n",
    "        return batch_x.reshape((b, h, w, 1)), [self.normalize_output(batch_counts[:, 0]),\n",
    "                                               self.normalize_output(batch_counts[:, 1]),\n",
    "                                               self.normalize_output(batch_counts[:, 2]),\n",
    "                                               self.normalize_output(batch_counts[:, 3]),\n",
    "                                               self.normalize_output(batch_counts[:, 4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(iid) for iid in train_ids]\n",
    "\n",
    "with open(\"../data/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(iid) for iid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = [1, 1, 0.2, 0.8, 0.7, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPatchesGenerator = PatchIterator(\"/home/ubuntu/sealion/data/\", train_ids, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valPatchesGenerator = PatchIterator(\"/home/ubuntu/sealion/data/\", val_ids, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x, batch_counts in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (16, 512, 512, 1)\n",
      "Counts shape:  (16, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", batch_x.shape)\n",
    "print(\"Counts shape: \", batch_counts[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_pred = unet.predict(batch_x, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35 43 43 43 43 43 43 43 43 43 43 43 43 34 35 43]\n",
      "[1 2 1 1 2 1 0 2 2 2 2 2 2 2 2 1]\n",
      "[45 45 45 57 45 45 45 45 45 45 57 45 45 57 45 45]\n",
      "[1 1 0 1 1 1 1 2 0 1 1 1 2 1 2 1]\n",
      "[20 20 42 20 20 20 20 20 20 20 20 20 20 20 22 20]\n",
      "[6 5 5 6 3 0 0 6 0 0 7 9 9 6 6 0]\n",
      "[46 46 46 46 46 46 46 46 46 46 46 46 46 46 46 46]\n",
      "[3 3 3 3 2 0 0 3 0 1 0 0 1 1 1 1]\n",
      "[53 53 53 53 53 53 53 53 53 53 53 53 53 53 53 53]\n",
      "[0 0 0 0 0 0 0 0 2 0 5 6 8 8 5 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(np.argmax(counts_pred[i], axis=-1))\n",
    "    print(np.argmax(batch_counts[i], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, 0]))\n",
    "print(\"True counts: \", batch_counts[i, ...])\n",
    "print(\"Pred counts: \", counts_pred[i, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_img(smap):\n",
    "    colors_rgb = [(1, 7, 179), (178, 12, 178), (5, 41, 79), (177, 54, 26), (26, 171, 43), (0, 0, 0), (255, 255, 255)]\n",
    "    im = np.zeros(smap.shape + (3, ), dtype=np.uint8)\n",
    "    for i in range(7):\n",
    "        im[smap==i, :] = colors_rgb[i]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_freqs, counts_freqs = trainPatchesGenerator.compute_class_distribution(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.losses import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /home/ubuntu/data/sealion/data/models/segmentation_debug_counts/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cb_checkpoint = ModelCheckpoint(\"/home/ubuntu/data/sealion/data/models/segmentation_debug_counts/ckpt_{epoch:02d}-{val_loss:.2f}.h5\")\n",
    "cb_reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, mode='auto', epsilon=0.01, cooldown=0, min_lr=0)\n",
    "tensorboard_cb = TensorBoardCallBack(log_dir=\"/home/ubuntu/data/sealion/data/models/segmentation_debug_counts/log_tb\", batch_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "unet.compile(optimizer=sgd, loss=[categorical_crossentropy, categorical_crossentropy, categorical_crossentropy, categorical_crossentropy, categorical_crossentropy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 2058s - loss: 8.9102 - counts_0_loss: 1.2292 - counts_1_loss: 1.5294 - counts_2_loss: 2.4306 - counts_3_loss: 2.4136 - counts_4_loss: 1.3074 - val_loss: 29.4470 - val_counts_0_loss: 5.5828 - val_counts_1_loss: 5.3369 - val_counts_2_loss: 8.8155 - val_counts_3_loss: 8.4668 - val_counts_4_loss: 1.2451\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 2051s - loss: 7.3916 - counts_0_loss: 0.7860 - counts_1_loss: 1.2302 - counts_2_loss: 2.1305 - counts_3_loss: 2.1500 - counts_4_loss: 1.0949 - val_loss: 42.8922 - val_counts_0_loss: 10.4355 - val_counts_1_loss: 12.7339 - val_counts_2_loss: 9.5958 - val_counts_3_loss: 6.8701 - val_counts_4_loss: 3.2569\n",
      "Epoch 3/20\n",
      " 999/1000 [============================>.] - ETA: 1s - loss: 6.9232 - counts_0_loss: 0.6589 - counts_1_loss: 1.0825 - counts_2_loss: 2.0314 - counts_3_loss: 2.0948 - counts_4_loss: 1.0556\n",
      "Epoch 00002: reducing learning rate to 9.999999747378752e-06.\n",
      "1000/1000 [==============================] - 2051s - loss: 6.9214 - counts_0_loss: 0.6585 - counts_1_loss: 1.0819 - counts_2_loss: 2.0313 - counts_3_loss: 2.0951 - counts_4_loss: 1.0546 - val_loss: 42.1336 - val_counts_0_loss: 10.3767 - val_counts_1_loss: 11.4293 - val_counts_2_loss: 9.9878 - val_counts_3_loss: 7.5392 - val_counts_4_loss: 2.8006\n",
      "Epoch 4/20\n",
      " 242/1000 [======>.......................] - ETA: 1451s - loss: 6.7747 - counts_0_loss: 0.6371 - counts_1_loss: 1.0342 - counts_2_loss: 2.0311 - counts_3_loss: 2.1207 - counts_4_loss: 0.9515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-68fcede54425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                            initial_epoch=0)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1876\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = unet.fit_generator(trainPatchesGenerator, 1000, epochs=20,\n",
    "                           verbose=1, callbacks=[cb_checkpoint, cb_reduce_lr, tensorboard_cb],\n",
    "                           validation_data=valPatchesGenerator, validation_steps=200,\n",
    "                           class_weight=None,\n",
    "                           max_q_size=8, workers=4, pickle_safe=False,\n",
    "                           initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, counts in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_pred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, 0]))\n",
    "print(\"True counts: \", batch_counts[i, ...])\n",
    "print(\"Pred counts: \", counts_pred[i, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet.save(\"../data/unet_segmentation_ellipse_dmap_sgd_10epochs_200steps.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, batch_y in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.min(batch_ypred[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg = np.argmax(batch_ypred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique(gg, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(valPatchesGenerator.denormalize_input(batch_x[i,:,:, :]))\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.argmax(batch_y[i,...], axis=-1))\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.argmax(batch_ypred[i,...], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0]) > 0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 7\n",
    "print(\"GT: \", np.sum(valPatchesGenerator.denormalize_output(batch_y[i,:,:, 0])))\n",
    "print(\"Pred: \", np.sum(valPatchesGenerator.denormalize_output(batch_ypred[i,:,:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_image_process(im, net, patchGenerator, patch_size=(224, 224), batch_size=8, overlap=(64, 64)):\n",
    "    h, w, c = im.shape\n",
    "    n_patches_x = int(np.ceil((w - patch_size[1])/(patch_size[1] - overlap[1]) + 1))\n",
    "    n_patches_y = int(np.ceil((h - patch_size[0])/(patch_size[0] - overlap[0]) + 1))\n",
    "    print(n_patches_x, n_patches_x)\n",
    "    \n",
    "    dmap = np.zeros((h, w, 1), dtype=np.float32)\n",
    "    dmap_count = np.zeros((h, w, 1), dtype=np.int8)\n",
    "    batch_x = np.zeros((batch_size, ) + patch_size + (c, ), dtype=np.float32)\n",
    "    batch_pos = np.zeros((batch_size, 4), dtype=np.int32)\n",
    "    \n",
    "    current_batch_size = 0\n",
    "    for py in range(n_patches_y):\n",
    "        y_start = py * (patch_size[0] - overlap[0])\n",
    "        y_start = min(h - patch_size[0], y_start)\n",
    "        y_end = y_start + patch_size[0]\n",
    "        for px in range(n_patches_x):\n",
    "            x_start = px * (patch_size[1] - overlap[1])\n",
    "            x_start = min(w - patch_size[1], x_start)\n",
    "            x_end = x_start + patch_size[1]\n",
    "            \n",
    "            # Keep filling the batch\n",
    "            batch_x[current_batch_size, :, :, :] = im[y_start:y_end, x_start:x_end, :]\n",
    "            batch_pos[current_batch_size, :] = np.array([y_start, y_end, x_start, x_end])\n",
    "            current_batch_size += 1\n",
    "            \n",
    "            if current_batch_size == batch_size or (py == n_patches_y - 1 and px == n_patches_x - 1) :\n",
    "                # time to predict\n",
    "                batch_x_normed = patchGenerator.normalize_input(batch_x)\n",
    "                batch_ylog = net.predict(batch_x_normed)\n",
    "                batch_y = patchGenerator.denormalize_output(batch_ylog)\n",
    "                # Fill the full dmap\n",
    "                for i in range(current_batch_size):\n",
    "                    y_start, y_end, x_start, x_end = tuple(batch_pos[i,:])\n",
    "                    dmap[y_start:y_end, x_start:x_end, :] += batch_y[i,:,:,:]\n",
    "                    dmap_count[y_start:y_end, x_start:x_end] += 1\n",
    "                current_batch_size = 0\n",
    "                \n",
    "    return dmap, dmap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"../data/sealion/Train/872.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap, dmap_count = full_image_process(im, unet, valPatchesGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(dmap[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_avg = dmap/dmap_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(dmap_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmap_gt = np.load(\"../data/sealion/TrainDensity/872_0.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
