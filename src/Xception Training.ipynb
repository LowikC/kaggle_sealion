{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_loc(shape, x, y, target_size=(224, 224), n_blocks=(4,4), overlap=(448,448)):\n",
    "    h, w = shape\n",
    "    w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "    h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "    for by in range(n_blocks[0]):\n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        for bx in range(n_blocks[1]):\n",
    "            x_start = bx * (w_block - overlap[1])\n",
    "            x_end = x_start + w_block + 1\n",
    "            \n",
    "            if x_start <= x < x_end and y_start <= y < y_end and\\\n",
    "            x_start <= x + target_size[1] - 1 < x_end and y_start <= y + target_size[0] - 1 < y_end:\n",
    "                return bx + by * n_blocks[0], x - x_start, y - y_start\n",
    "    raise NonValidPatch(\"Can't find block...??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StreamStats(object):\n",
    "    \"\"\" See https://www.johndcook.com/blog/standard_deviation/\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.M = None\n",
    "        self.S = None\n",
    "        self.k = 0\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "        \n",
    "    def update(self, x):\n",
    "        self.k += 1\n",
    "        if self.k == 1:\n",
    "            self.M = x\n",
    "            self.S = 0\n",
    "            self.min = x\n",
    "            self.max = x\n",
    "        else:\n",
    "            prevM = self.M\n",
    "            prevS = self.S\n",
    "            self.M = prevM + (x - prevM)/self.k\n",
    "            self.S = prevS + (x - prevM) * (x - self.M)\n",
    "            self.min = np.minimum(x, self.min)\n",
    "            self.max = np.maximum(x, self.max)\n",
    "            \n",
    "    def mean(self):\n",
    "        return self.M\n",
    "        \n",
    "    def variance(self):\n",
    "        if self.k - 1 > 0:\n",
    "            return self.S / (self.k - 1)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def std(self):\n",
    "        return np.sqrt(self.variance())\n",
    "    \n",
    "    def minimum(self):\n",
    "        return self.min\n",
    "    \n",
    "    def maximum(self):\n",
    "        return self.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, and dots.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param class_weights: Weights for each class.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 class_weights = None,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(91, 91),\n",
    "                 batch_size=32, shuffle=True, seed=42, debug_dir=None):\n",
    "        \n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        # Normalize to use class_weights as a probability distribution.\n",
    "        if class_weights:\n",
    "            self.class_weights = np.asarray(class_weights)/np.sum(class_weights)\n",
    "        else:\n",
    "            self.class_weights = np.ones((self.n_sealion_types+1))/(self.n_sealion_types + 1)\n",
    "            \n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size, shuffle, seed)\n",
    "    \n",
    "    def normalize_input(self, x):\n",
    "        return preprocess_input(x)\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x = x_normed / 2\n",
    "        x += 0.5\n",
    "        x *= 255\n",
    "        return np.clip(x, 0, 255)\n",
    "    \n",
    "    def random_transform(self, im):\n",
    "        flip_hor = np.random.randint(0, 2)\n",
    "        flip_ver = np.random.randint(0, 2)\n",
    "        if flip_hor == 1:\n",
    "            im = cv2.flip(im, 0)\n",
    "        if flip_ver == 1:\n",
    "            im = cv2.flip(im, 1)\n",
    "        return im\n",
    "    \n",
    "    def sample(self, shape, dots, image_id):\n",
    "        # if more than 30% of the patch is masked, reject it\n",
    "        threshold_masked = 0.3 \n",
    "        \n",
    "        # Set probability to 0 if some sealion type is not in the block\n",
    "        current_weigths = self.class_weights.copy()\n",
    "        for i in range(self.n_sealion_types):\n",
    "            if not dots[i]:\n",
    "                current_weigths[i] = 0\n",
    "        current_weigths /= np.sum(current_weigths)\n",
    "\n",
    "        while 1:\n",
    "            # Choose an output class randomly\n",
    "            output_class = np.random.choice(self.n_sealion_types + 1, size=(1, ), p=current_weigths)[0]\n",
    "\n",
    "            try:\n",
    "                # Sample a location, either for background or for a sealion.\n",
    "                if output_class == self.n_sealion_types:\n",
    "                    x, y = self.sample_bg(shape, dots, image_id)\n",
    "                else:\n",
    "                    x, y = self.sample_dot(shape, dots[output_class], image_id)\n",
    "            \n",
    "                # Get the corresponding image block, and (x, y) in this block\n",
    "                bid, x, y = get_block_loc(shape, x, y)\n",
    "            except NonValidPatch:\n",
    "                continue\n",
    "            \n",
    "            uid = \"{iid}_{bid}\".format(iid=image_id, bid=bid)\n",
    "            img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "            if img is None:\n",
    "                continue\n",
    "            img_patch = img[y:y+self.target_size[0], x:x+self.target_size[1],:]\n",
    "            masked_pixels = np.count_nonzero(img_patch == 0)\n",
    "            total_pixels = img_patch.shape[0] * img_patch.shape[1]\n",
    "            if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                continue\n",
    "            if masked_pixels/total_pixels < threshold_masked:\n",
    "                img_patch_rgb = img_patch[...,::-1]\n",
    "                return self.random_transform(img_patch_rgb), output_class\n",
    "        \n",
    "    def contains_dots(self, xstart, ystart, dots):\n",
    "        xend = xstart + self.target_size[1]\n",
    "        yend = ystart + self.target_size[0]\n",
    "        for ds in dots:\n",
    "            for (x, y) in ds:\n",
    "                if xstart <= x < xend and ystart <= y < yend:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def sample_bg(self, shape, dots, image_id):\n",
    "        max_iterations = 10\n",
    "        current_iteration = 0\n",
    "        while current_iteration < max_iterations:\n",
    "            x = np.random.randint(0, shape[1] - self.target_size[1], size=(1,))[0]\n",
    "            y = np.random.randint(0, shape[0] - self.target_size[0], size=(1,))[0]\n",
    "            if not self.contains_dots(x, y, dots):\n",
    "                return x, y\n",
    "            current_iteration += 1\n",
    "        raise NonValidPatch(\"Cant' find background\")\n",
    "    \n",
    "    def sample_dot(self, shape, dots, image_id):\n",
    "        margin = self.target_size[0]//8\n",
    "        \n",
    "        rand_index = np.random.choice(len(dots), size=(1,))[0]\n",
    "        rand_dot = dots[rand_index]\n",
    "        \n",
    "        min_x = max(0, rand_dot[0] - self.target_size[1]//2 - margin)\n",
    "        max_x = min(shape[1] - self.target_size[1], rand_dot[0] - self.target_size[1]//2 + margin)\n",
    "        \n",
    "        min_y = max(0, rand_dot[1] - self.target_size[0]//2 - margin)\n",
    "        max_y = min(shape[0] - self.target_size[0], rand_dot[1] - self.target_size[0]//2 + margin)\n",
    "        \n",
    "        if min_x > max_x:\n",
    "            max_x, min_x = min_x, max_x\n",
    "        if min_y > max_y:\n",
    "            max_y, min_y = min_y, max_y \n",
    "            \n",
    "        if min_x == max_x or min_y == max_y:\n",
    "            raise NonValidPatch()\n",
    "           \n",
    "        x = np.random.randint(min_x, max_x, size=(1,))[0]\n",
    "        y = np.random.randint(min_y, max_y, size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                 \n",
    "        batch_x = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size), dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDotsB\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "                \n",
    "            x, y = self.sample(shape, dots, image_id)\n",
    "            batch_x[i, ...] = x\n",
    "            batch_y[i] = y \n",
    "\n",
    "        if self.debug_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "                \n",
    "        return self.normalize_input(batch_x), to_categorical(batch_y, num_classes=self.n_sealion_types + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(s[:-4]) for s in train_ids]\n",
    "\n",
    "with open(\"../data/sealion/dots_ok.json\", \"r\") as jfile:\n",
    "    dots_ok = json.load(jfile)\n",
    "dots_ok = [int(s[:-4]) for s in dots_ok]\n",
    "\n",
    "train_ids = list(set(train_ids).intersection(set(dots_ok)))\n",
    "\n",
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(s[:-4]) for s in val_ids]\n",
    "val_ids = list(set(val_ids).intersection(set(dots_ok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_types = [\"adult_males\", \n",
    "    \"subadult_males\",\n",
    "    \"adult_females\",\n",
    "    \"juveniles\",\n",
    "    \"pups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = [0.34,  0.42, 0.05, 0.09, 0.11, 1/5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", train_ids, class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", val_ids, class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "predictions = Dense(len(sealion_types) + 1, activation='softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each epoch, we will do 32 * 300 = 9600 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "300/300 [==============================] - 994s - loss: 1.3386 - acc: 0.5026 - val_loss: 1.1611 - val_acc: 0.5494\n",
      "Epoch 2/3\n",
      "300/300 [==============================] - 1031s - loss: 1.2072 - acc: 0.5384 - val_loss: 1.1809 - val_acc: 0.5363\n",
      "Epoch 3/3\n",
      "300/300 [==============================] - 950s - loss: 1.1480 - acc: 0.5532 - val_loss: 1.1535 - val_acc: 0.5569\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(trainPatchesGenerator, 300, epochs=3, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=50, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bx, by in trainPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "300/300 [==============================] - 1671s - loss: 1.0946 - acc: 0.5760 - val_loss: 1.0678 - val_acc: 0.5687\n",
      "Epoch 2/3\n",
      "125/300 [===========>..................] - ETA: 890s - loss: 1.0082 - acc: 0.6085"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(trainPatchesGenerator, 300, epochs=3, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=50, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../data/sealion/xcption_3_3_epochs_300steps.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"../data/sealion/TrainBlock/872_2.jpg\")\n",
    "im = im.reshape((1, ) + im.shape)\n",
    "y_pred = model.predict(trainPatchesGenerator.normalize_input(im))\n",
    "y_class = np.argmax(y_pred, axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
