{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.layers import Dense, AvgPool2D, Conv2D, Reshape\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_loc(shape, x, y, target_size=(224, 224), n_blocks=(4,4), overlap=(448,448)):\n",
    "    h, w = shape\n",
    "    w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "    h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "    for by in range(n_blocks[0]):\n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        for bx in range(n_blocks[1]):\n",
    "            x_start = bx * (w_block - overlap[1])\n",
    "            x_end = x_start + w_block + 1\n",
    "            \n",
    "            if x_start <= x < x_end and y_start <= y < y_end and\\\n",
    "            x_start <= x + target_size[1] - 1 < x_end and y_start <= y + target_size[0] - 1 < y_end:\n",
    "                return bx + by * n_blocks[0], x - x_start, y - y_start\n",
    "    raise NonValidPatch(\"Can't find block...??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StreamStats(object):\n",
    "    \"\"\" See https://www.johndcook.com/blog/standard_deviation/\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.M = None\n",
    "        self.S = None\n",
    "        self.k = 0\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "        \n",
    "    def update(self, x):\n",
    "        self.k += 1\n",
    "        if self.k == 1:\n",
    "            self.M = x\n",
    "            self.S = 0\n",
    "            self.min = x\n",
    "            self.max = x\n",
    "        else:\n",
    "            prevM = self.M\n",
    "            prevS = self.S\n",
    "            self.M = prevM + (x - prevM)/self.k\n",
    "            self.S = prevS + (x - prevM) * (x - self.M)\n",
    "            self.min = np.minimum(x, self.min)\n",
    "            self.max = np.maximum(x, self.max)\n",
    "            \n",
    "    def mean(self):\n",
    "        return self.M\n",
    "        \n",
    "    def variance(self):\n",
    "        if self.k - 1 > 0:\n",
    "            return self.S / (self.k - 1)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def std(self):\n",
    "        return np.sqrt(self.variance())\n",
    "    \n",
    "    def minimum(self):\n",
    "        return self.min\n",
    "    \n",
    "    def maximum(self):\n",
    "        return self.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoPupsIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples of subadult_males\n",
    "    :param root_dir: Directory containing training images, and dots.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param class_weights: Weights for each class.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 class_weights = None,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(92, 92),\n",
    "                 batch_size=64, shuffle=True, seed=42, debug_dir=None):\n",
    "        self.n_samples_per_block = 16\n",
    "        self.n_sealion_types = 5\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        # Normalize to use class_weights as a probability distribution.\n",
    "        if class_weights:\n",
    "            self.class_weights = np.asarray(class_weights)/np.sum(class_weights)\n",
    "        else:\n",
    "            self.class_weights = np.ones((self.n_sealion_types+1))/(self.n_sealion_types + 1)\n",
    "            \n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(NoPupsIterator, self).__init__(self.n_indices, batch_size//self.n_samples_per_block, shuffle, seed)\n",
    "        \n",
    "    def get_class_distribution(self, n_batches=100):\n",
    "        counts = defaultdict(int)\n",
    "        for _ in range(n_batches):\n",
    "            _, by = self.next()\n",
    "            by = np.argmax(by, axis=-1)\n",
    "            cls, cnts = np.unique(by.ravel(), return_counts=True)\n",
    "            for c, cnt in zip(cls, cnts):\n",
    "                counts[c] += cnt\n",
    "        return counts\n",
    "        \n",
    "    def normalize_input(self, x_bgr):\n",
    "        x = x_bgr.copy()\n",
    "        x[..., 0] -= 103.939\n",
    "        x[..., 1] -= 116.779\n",
    "        x[..., 2] -= 123.68\n",
    "        return x\n",
    "    \n",
    "    def denormalize_input(self, x_normed):\n",
    "        x = x_normed.copy()\n",
    "        x[..., 0] += 103.939\n",
    "        x[..., 1] += 116.779\n",
    "        x[..., 2] += 123.68\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, im):\n",
    "        flip_hor = np.random.randint(0, 2)\n",
    "        flip_ver = np.random.randint(0, 2)\n",
    "        if flip_hor == 1:\n",
    "            im = cv2.flip(im, 0)\n",
    "        if flip_ver == 1:\n",
    "            im = cv2.flip(im, 1)\n",
    "        return im\n",
    "    \n",
    "    def get_weights(self, dots):\n",
    "        # Set probability to 0 if some sealion type is not in the block\n",
    "        current_weigths = self.class_weights.copy()\n",
    "        for i in range(self.n_sealion_types):\n",
    "            if not dots[i]:\n",
    "                current_weigths[i] = 0\n",
    "        current_weigths /= np.sum(current_weigths)\n",
    "        return current_weigths\n",
    "    \n",
    "    def sample_position(self, shape, dots, current_weigths, size):\n",
    "        # Choose an output class randomly\n",
    "        output_class = np.random.choice(self.n_sealion_types + 1, size=(1, ), p=current_weigths)[0]\n",
    "        # Sample a location, either for background or for a sealion.\n",
    "        if output_class == self.n_sealion_types:\n",
    "            # avoid bg with pups in it\n",
    "            return self.sample_bg(shape, dots, size), output_class\n",
    "        else:\n",
    "            return self.sample_dot(shape, dots[output_class], size), output_class\n",
    "\n",
    "    def get_dots_in_block(self, bid, shape, dots, n_blocks=(4,4), overlap=(448,448)):\n",
    "        h, w = shape\n",
    "        w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "        h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "        \n",
    "        bx = bid % n_blocks[0]\n",
    "        by = bid // n_blocks[0]\n",
    "        \n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        x_start = bx * (w_block - overlap[1])\n",
    "        x_end = x_start + w_block + 1\n",
    "        \n",
    "        dots_in_block = [[] for _ in range(self.n_sealion_types)]\n",
    "        for i, ds in enumerate(dots):\n",
    "            for (x, y) in ds:\n",
    "                if x_start <= x < x_end and y_start <= y < y_end:\n",
    "                    dots_in_block[i].append((x - x_start, y - y_start))\n",
    "        return dots_in_block\n",
    "        \n",
    "    def get_random_block(self, image_id, shape, dots, current_weigths):\n",
    "        while True:\n",
    "            try:\n",
    "                (x, y), output_class = self.sample_position(shape, dots, current_weigths, self.target_size)\n",
    "                \n",
    "                # Get the corresponding image block, and (x, y) in this block\n",
    "                bid, x, y = get_block_loc(shape, x, y)\n",
    "                \n",
    "                # Load the block and check if it is valid\n",
    "                uid = \"{iid}_{bid}\".format(iid=image_id, bid=bid)\n",
    "                img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))\n",
    "                if img is not None:\n",
    "                    return bid, img\n",
    "            except NonValidPatch:\n",
    "                continue\n",
    "        \n",
    "    \n",
    "    def sample(self, shape, dots, image_id):\n",
    "        # if more than 30% of the patch is masked, reject it\n",
    "        threshold_masked = 0.3 \n",
    "        \n",
    "        # If we are stuck on a \"bad\" block, we retry from scratch\n",
    "        while True:\n",
    "            # Set probability to 0 if some sealion type is not in the block\n",
    "            current_weigths = self.get_weights(dots)\n",
    "        \n",
    "            # Get a block randomly (but using the dots and the sampling weights)\n",
    "            bid, img = self.get_random_block(image_id, shape, dots, current_weigths)\n",
    "                \n",
    "            # Recompute dots in the blocks, and sampling weights\n",
    "            dots_block = self.get_dots_in_block(bid, shape, dots)\n",
    "            current_weigths = self.get_weights(dots_block)\n",
    "\n",
    "            # Now, sample n_samples_per_block patches from it\n",
    "            n_samples = 0\n",
    "            bx = np.zeros((self.n_samples_per_block, self.target_size[0], self.target_size[1], 3))\n",
    "            by = np.zeros((self.n_samples_per_block, ))\n",
    "\n",
    "            # Stop if we try too many times, \n",
    "            max_iterations = self.n_samples_per_block * 5\n",
    "            current_iteration = 0\n",
    "            while n_samples < self.n_samples_per_block and current_iteration < max_iterations:\n",
    "                current_iteration += 1\n",
    "                try:\n",
    "                    zoom_max = 1.2\n",
    "                    zoom_min = 0.8\n",
    "                    hmin = int(self.target_size[0]/zoom_max)\n",
    "                    hmax = int(self.target_size[0]/zoom_min)\n",
    "                    wmin = int(self.target_size[1]/zoom_max)\n",
    "                    wmax = int(self.target_size[1]/zoom_min)\n",
    "                    \n",
    "                    h = np.random.randint(hmin, hmax, size=(1,))[0]\n",
    "                    w = np.random.randint(wmin, wmax, size=(1,))[0]\n",
    " \n",
    "                    (x, y), output_class = self.sample_position(img.shape[:2], dots_block, current_weigths, (h, w))\n",
    "                    img_patch = img[y:y+h, x:x+w,:]\n",
    "\n",
    "                    img_patch = cv2.resize(img_patch, dsize=(self.target_size[1], self.target_size[0]))\n",
    "                    masked_pixels = np.count_nonzero(img_patch == 0)\n",
    "                    total_pixels = img_patch.shape[0] * img_patch.shape[1]\n",
    "                    if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                        continue\n",
    "                    if masked_pixels/total_pixels < threshold_masked:\n",
    "                        bx[n_samples, ...] = self.random_transform(img_patch)\n",
    "                        by[n_samples] = output_class if output_class < 4 else 4\n",
    "                        n_samples += 1\n",
    "                except NonValidPatch:\n",
    "                    continue\n",
    "                    \n",
    "            if current_iteration < max_iterations:\n",
    "                return bx, by\n",
    "            # else, we tried too many times, let's get another block.\n",
    "        \n",
    "        \n",
    "    def contains_dots(self, xstart, ystart, dots, margin):\n",
    "        x1 = xstart - margin\n",
    "        y1 = ystart - margin\n",
    "        x2 = xstart + self.target_size[1] + margin\n",
    "        y2 = ystart + self.target_size[0] + margin\n",
    "        for ds in dots:\n",
    "            for (x, y) in ds:\n",
    "                if x1 <= x < x2 and y1 <= y < y2:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def sample_bg(self, shape, dots, size):\n",
    "        margin = 40 # more than half of the sealion expected size\n",
    "        max_iterations = 10\n",
    "        current_iteration = 0\n",
    "        while current_iteration < max_iterations:\n",
    "            if shape[1] - size[1] <= 0 or shape[0] - size[0] <= 0:\n",
    "                raise NonValidPatch(\"Cant' find background\")\n",
    "            x = np.random.randint(0, shape[1] - size[1], size=(1,))[0]\n",
    "            y = np.random.randint(0, shape[0] - size[0], size=(1,))[0]\n",
    "            if not self.contains_dots(x, y, dots, margin):\n",
    "                return x, y\n",
    "            current_iteration += 1\n",
    "        raise NonValidPatch(\"Cant' find background\")\n",
    "    \n",
    "    def sample_dot(self, shape, dots, size):\n",
    "        margin = size[0]//10\n",
    "        \n",
    "        rand_index = np.random.choice(len(dots), size=(1,))[0]\n",
    "        rand_dot = dots[rand_index]\n",
    "        \n",
    "        min_x = max(0, rand_dot[0] - size[1]//2 - margin)\n",
    "        max_x = max(0, min(shape[1] - size[1], rand_dot[0] - size[1]//2 + margin))\n",
    "        \n",
    "        min_y = max(0, rand_dot[1] - size[0]//2 - margin)\n",
    "        max_y = max(0, min(shape[0] - size[0], rand_dot[1] - size[0]//2 + margin))\n",
    "        \n",
    "        if min_x > max_x:\n",
    "            max_x, min_x = min_x, max_x\n",
    "        if min_y > max_y:\n",
    "            max_y, min_y = min_y, max_y \n",
    "            \n",
    "        if min_x == max_x or min_y == max_y:\n",
    "            raise NonValidPatch()\n",
    "           \n",
    "        x = np.random.randint(min_x, max_x, size=(1,))[0]\n",
    "        y = np.random.randint(min_y, max_y, size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_samples_per_block, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size * self.n_samples_per_block), dtype=np.int32)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "                \n",
    "            x, y = self.sample(shape, dots, image_id)\n",
    "            batch_x[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block, ...] = x\n",
    "            batch_y[i*self.n_samples_per_block:(i+1)*self.n_samples_per_block] = y \n",
    "\n",
    "        if self.debug_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"patch_{}.jpg\".format(i)), batch_x[i])\n",
    "                \n",
    "        permut = np.random.permutation(batch_x.shape[0])\n",
    "        return self.normalize_input(batch_x[permut, ...]), to_categorical(batch_y[permut,...], num_classes=5).reshape((-1, 1, 1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(s) for s in train_ids]\n",
    "\n",
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(s) for s in val_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_types = [\"adult_males\", \n",
    "    \"subadult_males\",\n",
    "    \"adult_females\",\n",
    "    \"juveniles\",\n",
    "    \"pups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weights = [0.1,  0.1, 0.1, 0.1, 0, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPatchesGenerator = NoPupsIterator(\"/home/lowik/sealion/data/sealion/\", train_ids, class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valPatchesGenerator = NoPupsIterator(\"/home/lowik/sealion/data/sealion/\", val_ids, class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = base_model.layers[-2]\n",
    "sealion_prediction = Conv2D(5, (3, 3), activation=\"softmax\")(h.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sealion_net = Model(inputs=[base_model.input], outputs=[sealion_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sealion_net.predict(np.ones((1, 92, 92, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sealion_net.predict(np.ones((1, 92*2, 92*2, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bx, by in trainPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  1.19998351e-01,   8.60839784e-01,   2.77264463e-03,\n",
       "            1.55479144e-02,   8.41396919e-04]]],\n",
       "\n",
       "\n",
       "       [[[  7.79132098e-02,   4.52489227e-01,   1.17500365e-01,\n",
       "            2.19280049e-01,   1.32817060e-01]]],\n",
       "\n",
       "\n",
       "       [[[  1.51233450e-02,   6.69259608e-01,   2.67610103e-01,\n",
       "            4.29757163e-02,   5.03114797e-03]]],\n",
       "\n",
       "\n",
       "       [[[  4.85859424e-01,   2.68659145e-01,   9.93461162e-02,\n",
       "            1.00647219e-01,   4.54880595e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.70679137e-01,   2.77053535e-01,   2.72047877e-01,\n",
       "            2.51753926e-01,   2.84654796e-02]]],\n",
       "\n",
       "\n",
       "       [[[  6.21781219e-03,   8.96522343e-01,   4.22375575e-02,\n",
       "            4.90865335e-02,   5.93572343e-03]]],\n",
       "\n",
       "\n",
       "       [[[  1.04864925e-01,   1.32874027e-03,   8.93055499e-01,\n",
       "            3.94794879e-05,   7.11383123e-04]]],\n",
       "\n",
       "\n",
       "       [[[  1.88481230e-02,   1.39194906e-01,   9.57535859e-03,\n",
       "            8.23085368e-01,   9.29619558e-03]]],\n",
       "\n",
       "\n",
       "       [[[  3.68588090e-01,   1.01822913e-01,   2.36121744e-01,\n",
       "            1.46347314e-01,   1.47119939e-01]]],\n",
       "\n",
       "\n",
       "       [[[  2.86189243e-02,   8.11857730e-02,   8.08014274e-01,\n",
       "            6.34815842e-02,   1.86994337e-02]]],\n",
       "\n",
       "\n",
       "       [[[  4.21593711e-03,   7.19353557e-01,   2.62294173e-01,\n",
       "            5.61157614e-03,   8.52477737e-03]]],\n",
       "\n",
       "\n",
       "       [[[  2.57061630e-01,   5.72625995e-01,   5.14480583e-02,\n",
       "            1.03589691e-01,   1.52746756e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.19630732e-01,   1.71161726e-01,   4.36434522e-02,\n",
       "            6.49190664e-01,   1.63734611e-02]]],\n",
       "\n",
       "\n",
       "       [[[  6.99642599e-02,   6.47398472e-01,   1.36142612e-01,\n",
       "            1.25363797e-01,   2.11308319e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.25852274e-02,   8.75910044e-01,   2.37996783e-02,\n",
       "            8.76164809e-02,   8.85162954e-05]]],\n",
       "\n",
       "\n",
       "       [[[  8.17318708e-02,   4.64788407e-01,   3.37472439e-01,\n",
       "            5.43122105e-02,   6.16951510e-02]]],\n",
       "\n",
       "\n",
       "       [[[  9.38345268e-02,   5.44664919e-01,   2.04996932e-02,\n",
       "            3.01527023e-01,   3.94737795e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.11695252e-01,   1.72766447e-01,   6.77467167e-01,\n",
       "            3.38412151e-02,   4.22986969e-03]]],\n",
       "\n",
       "\n",
       "       [[[  1.54900178e-01,   3.26819047e-02,   7.26833284e-01,\n",
       "            7.13814124e-02,   1.42032513e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.39977440e-01,   5.93153715e-01,   1.26970792e-02,\n",
       "            2.47272521e-01,   6.89922040e-03]]],\n",
       "\n",
       "\n",
       "       [[[  4.60176766e-02,   6.51617169e-01,   1.10867275e-02,\n",
       "            2.90842742e-01,   4.35687834e-04]]],\n",
       "\n",
       "\n",
       "       [[[  2.07754642e-01,   2.24244058e-01,   2.18610257e-01,\n",
       "            2.83809841e-01,   6.55811951e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.12072185e-01,   6.71100378e-01,   7.60737211e-02,\n",
       "            1.38589874e-01,   2.16379249e-03]]],\n",
       "\n",
       "\n",
       "       [[[  2.13812012e-02,   9.48694587e-01,   5.98419178e-03,\n",
       "            2.01657768e-02,   3.77421686e-03]]],\n",
       "\n",
       "\n",
       "       [[[  2.50163078e-01,   1.77543998e-01,   3.75288278e-01,\n",
       "            1.87570080e-01,   9.43454541e-03]]],\n",
       "\n",
       "\n",
       "       [[[  1.19880714e-01,   3.03813159e-01,   1.01809114e-01,\n",
       "            2.52608865e-01,   2.21888244e-01]]],\n",
       "\n",
       "\n",
       "       [[[  7.18694106e-02,   3.03260416e-01,   2.59419158e-02,\n",
       "            5.93852162e-01,   5.07612340e-03]]],\n",
       "\n",
       "\n",
       "       [[[  5.81851304e-02,   7.00933635e-02,   6.91093922e-01,\n",
       "            2.13143863e-02,   1.59313202e-01]]],\n",
       "\n",
       "\n",
       "       [[[  2.47052819e-01,   1.70859873e-01,   1.03370309e-01,\n",
       "            1.54516876e-01,   3.24200153e-01]]],\n",
       "\n",
       "\n",
       "       [[[  1.99585259e-01,   3.79022837e-01,   2.87841633e-02,\n",
       "            3.81973445e-01,   1.06342454e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.76808238e-02,   9.42515135e-01,   4.37593926e-03,\n",
       "            3.32458019e-02,   2.18225666e-03]]],\n",
       "\n",
       "\n",
       "       [[[  1.92221478e-01,   3.37283939e-01,   1.50304630e-01,\n",
       "            7.71553144e-02,   2.43034631e-01]]],\n",
       "\n",
       "\n",
       "       [[[  1.50663173e-02,   3.66071075e-01,   5.60120344e-01,\n",
       "            5.51264137e-02,   3.61586339e-03]]],\n",
       "\n",
       "\n",
       "       [[[  1.92644641e-01,   4.89581048e-01,   6.80878200e-03,\n",
       "            2.91155815e-01,   1.98096614e-02]]],\n",
       "\n",
       "\n",
       "       [[[  2.53058910e-01,   2.42978796e-01,   1.54720083e-01,\n",
       "            3.14307183e-01,   3.49350199e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.62305370e-01,   9.86957178e-02,   1.07738607e-01,\n",
       "            5.01959026e-01,   1.29301250e-01]]],\n",
       "\n",
       "\n",
       "       [[[  3.63059551e-03,   3.68184626e-01,   1.52728111e-01,\n",
       "            4.46678042e-01,   2.87786219e-02]]],\n",
       "\n",
       "\n",
       "       [[[  8.96986723e-02,   2.06426963e-01,   5.93151301e-02,\n",
       "            2.55578011e-01,   3.88981193e-01]]],\n",
       "\n",
       "\n",
       "       [[[  3.50424886e-01,   5.94886720e-01,   1.35885365e-02,\n",
       "            2.99952757e-02,   1.11044934e-02]]],\n",
       "\n",
       "\n",
       "       [[[  4.37283255e-02,   8.81366372e-01,   4.80997115e-02,\n",
       "            2.62789894e-02,   5.26616466e-04]]],\n",
       "\n",
       "\n",
       "       [[[  4.31293309e-01,   1.91648796e-01,   4.75157537e-02,\n",
       "            2.07757503e-01,   1.21784620e-01]]],\n",
       "\n",
       "\n",
       "       [[[  1.50327280e-01,   5.00430346e-01,   5.20243235e-02,\n",
       "            1.06666796e-01,   1.90551266e-01]]],\n",
       "\n",
       "\n",
       "       [[[  1.35855144e-02,   7.83883572e-01,   1.36883138e-02,\n",
       "            1.54570609e-01,   3.42719480e-02]]],\n",
       "\n",
       "\n",
       "       [[[  7.72480341e-03,   3.46586525e-01,   5.57690024e-01,\n",
       "            8.07024073e-03,   7.99283609e-02]]],\n",
       "\n",
       "\n",
       "       [[[  2.65192866e-01,   4.31192428e-01,   8.38488936e-02,\n",
       "            1.88419357e-01,   3.13464291e-02]]],\n",
       "\n",
       "\n",
       "       [[[  6.34365201e-01,   1.01569733e-02,   5.92362620e-02,\n",
       "            5.79727860e-03,   2.90444344e-01]]],\n",
       "\n",
       "\n",
       "       [[[  1.81580409e-02,   1.53330639e-01,   7.03316256e-02,\n",
       "            7.54399121e-01,   3.78057733e-03]]],\n",
       "\n",
       "\n",
       "       [[[  2.64660329e-01,   2.03486875e-01,   1.71378732e-01,\n",
       "            2.72175431e-01,   8.82986113e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.13890044e-01,   1.98382229e-01,   6.24669909e-01,\n",
       "            2.96242461e-02,   3.34335715e-02]]],\n",
       "\n",
       "\n",
       "       [[[  4.46502119e-03,   8.95515501e-01,   6.77379295e-02,\n",
       "            2.65413243e-02,   5.74030215e-03]]],\n",
       "\n",
       "\n",
       "       [[[  1.11735635e-01,   4.27290678e-01,   1.58530667e-01,\n",
       "            2.76603729e-01,   2.58393176e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.03230871e-01,   9.77358073e-02,   4.09482926e-01,\n",
       "            1.40857279e-01,   2.48693153e-01]]],\n",
       "\n",
       "\n",
       "       [[[  2.04354703e-01,   6.32165611e-01,   1.95750240e-02,\n",
       "            1.24691121e-01,   1.92135517e-02]]],\n",
       "\n",
       "\n",
       "       [[[  6.43813685e-02,   1.73908204e-01,   2.45651126e-01,\n",
       "            9.63061377e-02,   4.19753194e-01]]],\n",
       "\n",
       "\n",
       "       [[[  9.64445472e-02,   1.52014896e-01,   5.33087611e-01,\n",
       "            6.12027124e-02,   1.57250240e-01]]],\n",
       "\n",
       "\n",
       "       [[[  3.38770717e-01,   1.64679050e-01,   3.56570669e-02,\n",
       "            2.59300828e-01,   2.01592356e-01]]],\n",
       "\n",
       "\n",
       "       [[[  3.86682481e-01,   2.37474546e-01,   1.76056951e-01,\n",
       "            9.39815491e-02,   1.05804458e-01]]],\n",
       "\n",
       "\n",
       "       [[[  2.04367489e-02,   7.80976892e-01,   1.12931943e-02,\n",
       "            1.86787635e-01,   5.05571021e-04]]],\n",
       "\n",
       "\n",
       "       [[[  4.36952442e-01,   1.97776213e-01,   1.30863100e-01,\n",
       "            1.44023657e-01,   9.03845727e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.43825812e-02,   9.79115367e-01,   5.08450251e-03,\n",
       "            1.56497234e-04,   1.26100925e-03]]],\n",
       "\n",
       "\n",
       "       [[[  1.61693409e-01,   1.93788812e-01,   3.60632166e-02,\n",
       "            4.86940175e-01,   1.21514358e-01]]],\n",
       "\n",
       "\n",
       "       [[[  1.03497379e-01,   5.93721569e-01,   5.06774783e-02,\n",
       "            2.35170215e-01,   1.69334617e-02]]],\n",
       "\n",
       "\n",
       "       [[[  9.29183140e-02,   2.32281387e-01,   2.87202485e-02,\n",
       "            6.21218860e-01,   2.48612538e-02]]],\n",
       "\n",
       "\n",
       "       [[[  1.66746989e-01,   2.72103697e-01,   2.67995089e-01,\n",
       "            2.64220238e-01,   2.89339945e-02]]]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sealion_net.predict(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {0: 1241, 1: 943, 2: 1039, 3: 1025, 4: 2152})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPatchesGenerator.get_class_distribution(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.002, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "sealion_net.compile(optimizer=sgd, loss=categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each epoch, we will do 32 * 300 = 9600 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "300/300 [==============================] - 1066s - loss: 3.2209 - acc: 0.5965 - val_loss: 3.5236 - val_acc: 0.6503\n",
      "Epoch 2/3\n",
      " 45/300 [===>..........................] - ETA: 711s - loss: 3.7646 - acc: 0.5806"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-40d787a4d41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msealion_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPatchesGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalPatchesGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1876\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lowik/virtualenvs/kaggle/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = sealion_net.fit_generator(trainPatchesGenerator, 300, epochs=3, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=50, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../data/sealion/xception_fc_3_epochs_300steps_last_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, momentum=0.9, decay=0.0005, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit_generator(trainPatchesGenerator, 300, epochs=3, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=50, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../data/sealion/xception_fc_3_3_epochs_300steps.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bx, by in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_pred = model.predict(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.ones((1, 91*2, 91*2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp = model.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"../data/test_fcb.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "91 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_normed = trainPatchesGenerator.normalize_input(im.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_normed = im_normed.reshape((1, 546, 546, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py = model.predict(im_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(py, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "plt.imshow(trainPatchesGenerator.denormalize_input(bx[i, ...]))\n",
    "print(\"Predict probas: \", by_pred[i, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"../data/sealion/TrainBlock/872_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = im.reshape((1, ) + im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_norm = trainPatchesGenerator.normalize_input(im.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(im_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1741/91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_class = np.argmax(y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_class[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
