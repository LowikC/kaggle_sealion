{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, Flatten, Dense, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error, mean_absolute_error, categorical_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Reshape, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_squared_error(y_true, y_pred):\n",
    "    return K.sum(K.sum(K.sum(K.square(y_pred - y_true), axis=-1), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_rmse(y_true, y_pred):\n",
    "    \"\"\" Compute the count rmse from the gt and predicted density map.\n",
    "    :param y_true: Groundtruth density map, 4D tensor of shape (n_samples, height, width, types of sealion)\n",
    "    :param y_pred: Predicted density map, 4D tensor of shape (n_samples, height, width, types of sealion)\n",
    "    :return A Tensor of shape () (single value), with the RMSE(y_true, y_pred), averaged over the columns.\n",
    "    \"\"\"\n",
    "    # shape is (n_samples, height, width, types of sealion)\n",
    "    # we want to reduce it to (n_samples, types of sealion)\n",
    "    # We don't round the counts, as it will be called on patches, with probably non-integer sum over the density map.\n",
    "    counts_true = K.sum(K.sum(y_true, axis=1), axis=1)\n",
    "    counts_pred = K.sum(K.sum(y_pred, axis=1), axis=1)\n",
    "    rmse_per_column = K.sqrt(K.mean(K.square(counts_pred - counts_true), axis=0))\n",
    "    rmse = K.mean(rmse_per_column)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_mse(y_true, y_pred):\n",
    "    \"\"\" Compute the count mse from the gt and predicted density map.\n",
    "    :param y_true: Groundtruth density map, 4D tensor of shape (n_samples, height, width, types of sealion)\n",
    "    :param y_pred: Predicted density map, 4D tensor of shape (n_samples, height, width, types of sealion)\n",
    "    :return A Tensor of shape (n_samples,), with the MSE(count_true, count_pred) for each sample.\n",
    "    \"\"\"\n",
    "    # shape is (n_samples, height, width, types of sealion)\n",
    "    # we want to reduce it to (n_samples, types of sealion)\n",
    "    # We don't round the counts, as it will be called on patches, with probably non-integer sum over the density map.\n",
    "    counts_true = K.sum(K.sum(y_true, axis=1), axis=1)\n",
    "    counts_pred = K.sum(K.sum(y_pred, axis=1), axis=1)\n",
    "    rmse_per_sample = K.square(counts_pred - counts_true)\n",
    "    return rmse_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_count_mse(y_true, y_pred):\n",
    "    \"\"\" Compute the count mse from the gt and predicted density map.\n",
    "    :param y_true: Groundtruth density map, 4D tensor of shape (n_samples, height, width, types of sealion)\n",
    "    :param y_pred: Predicted density map, 4D tensor of shape (n_samples, height, width, types of sealion)\n",
    "    :return A Tensor of shape (n_samples,), with the MSE(count_true, count_pred) for each sample.\n",
    "    \"\"\"\n",
    "    # shape is (n_samples, height, width, types of sealion)\n",
    "    # we want to reduce it to (n_samples, types of sealion)\n",
    "    # We don't round the counts, as it will be called on patches, with probably non-integer sum over the density map.\n",
    "    counts_true = np.sum(np.sum(y_true, axis=1), axis=1)\n",
    "    counts_pred = np.sum(np.sum(y_pred, axis=1), axis=1)\n",
    "    rmse_per_sample = np.square(counts_pred - counts_true)\n",
    "    n, h, w, c = y_true.shape\n",
    "    return rmse_per_sample/(w * h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet(n_channels, n_classes, lr=0.001):\n",
    "    # Fully convolutional, we don't specify the image size\n",
    "    inputs = Input((None, None, n_channels))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    #conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    #conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    #conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    #conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    #conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, (1, 1), activation=None)(conv9)  # outputs N density map, one for each type of sealion\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=lr), loss=mean_squared_error)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnet(img_rows, img_cols, n_channels, n_classes, lr=0.001):\n",
    "    inputs = Input((img_rows, img_cols, n_channels))\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    #conv1 = Dropout(0.2)(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    #conv2 = Dropout(0.2)(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    #conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    #conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    #conv5 = Dropout(0.2)(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    avg = AveragePooling2D((7, 7))(conv5)   #(h/(16 * 7), w/(16 * 7), 512)\n",
    "    avg = Flatten()(avg)\n",
    "    avg = BatchNormalization()(avg)\n",
    "    \n",
    "    hidden = Dense(128, activation='relu')(avg)\n",
    "    hidden = BatchNormalization()(hidden)\n",
    "    counts = Dense(n_classes, activation='softmax')(hidden)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[counts])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=lr), loss=categorical_crossentropy)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_loc(shape, x, y, target_size=(224, 224), n_blocks=(4,4), overlap=(448,448)):\n",
    "    h, w = shape\n",
    "    w_block = (w + (n_blocks[1] - 1) * overlap[1]) // n_blocks[1]\n",
    "    h_block = (h + (n_blocks[0] - 1) * overlap[0]) // n_blocks[0]\n",
    "    for by in range(n_blocks[0]):\n",
    "        y_start = by * (h_block - overlap[0])\n",
    "        y_end = y_start + h_block + 1\n",
    "        for bx in range(n_blocks[1]):\n",
    "            x_start = bx * (w_block - overlap[1])\n",
    "            x_end = x_start + w_block + 1\n",
    "            \n",
    "            if x_start <= x < x_end and y_start <= y < y_end and\\\n",
    "            x_start <= x + target_size[1] - 1 < x_end and y_start <= y + target_size[0] - 1 < y_end:\n",
    "                return bx + by * n_blocks[0], x - x_start, y - y_start\n",
    "    raise Exception(\"Can't find block...??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    \"\"\"Iterator yielding training samples\n",
    "    :param root_dir: Directory containing training images, density map and sampling map.\n",
    "    :param image_ids: Set of image ids to use to sample patches.\n",
    "    :param x_mean: Mean per channel for input normalization\n",
    "    :param x_std: Standard deviation per channel for input normalization\n",
    "    :param y_scale: Scale to apply on the output density map\n",
    "    :param output_counts: Indicate if the iterator should return only counts, otherwise density maps.\n",
    "    :param n_samples_per_image: Number of patches to sample on each image.\n",
    "    :param target_size: Size of the patches sampled.\n",
    "    :param batch_size: Number of patches sampled per batch\n",
    "    :param shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "    :param seed: Random seed for data shuffling.\n",
    "    :return batch_x, batch_x. \n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 3) array\n",
    "        batch_x is a (batch_size, target_size[0], target_size[1], 1) array if output_counts is False\n",
    "        otherwise, it is a (batch_size, 5) array.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 x_mean, x_std, y_scale,\n",
    "                 output_counts=False,\n",
    "                 count_max=64,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(224, 224),\n",
    "                 batch_size=8, shuffle=True, seed=42):\n",
    "        \n",
    "        self.image_ids = image_ids\n",
    "        self.max_count = count_max\n",
    "        self.x_mean = x_mean\n",
    "        self.x_std = x_std\n",
    "        self.y_scale = y_scale\n",
    "        self.output_counts = output_counts\n",
    "        self.root_dir = root_dir\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "                 \n",
    "        super(PatchIterator, self).__init__(self.n_indices, batch_size, shuffle, seed)\n",
    "        \n",
    "    def __normalize_input__(self, batch_x):\n",
    "        return (batch_x/255 - self.x_mean)/self.x_std\n",
    "    \n",
    "    def __normalize_output__(self, batch_y):\n",
    "        ma = 0.006\n",
    "        mi = 0\n",
    "        a = 1/(ma - mi)\n",
    "        b = -a * mi\n",
    "        mean = 4.1060985197746936e-06\n",
    "        std = 1.12463456142464e-05\n",
    "        scale_mean = a * mean + b\n",
    "        scale_std = a * std\n",
    "        log_mean = np.log(scale_mean)\n",
    "        log_std = np.log(std)\n",
    "        scaled_01 =  (a * batch_y + b)\n",
    "        log = np.log(scaled_01 + 1e-9)\n",
    "        return ((log - log_mean)/log_std) * self.y_scale\n",
    "\n",
    "    def __sample__(self, shape, dots, image_id):\n",
    "        pbackground = 0.2\n",
    "        threshold_masked = 0.3 # if more than 30% of the patch is masked, reject it\n",
    "        \n",
    "        adots = []\n",
    "        for _, ds in dots.items():\n",
    "            for x, y in ds:\n",
    "                if 0 <= x < shape[1] and 0 <= y < shape[0]:\n",
    "                    adots.append((x, y))\n",
    "                    \n",
    "        bg_or_dots = np.random.choice(2, size=(1, ), p=[pbackground, 1-pbackground])\n",
    "        \n",
    "        while 1:\n",
    "            if bg_or_dots[0] == 0 or len(adots) == 0:\n",
    "                x, y = self.sample_bg(shape, image_id)\n",
    "            else:\n",
    "                x, y = self.sample_dot(shape, adots, image_id)\n",
    "\n",
    "            try:\n",
    "                bid, x, y = get_block_loc(shape, x, y)\n",
    "            except:\n",
    "                continue\n",
    "            uid = \"{iid}_{bid}\".format(iid=image_id, bid=bid)\n",
    "            img = cv2.imread(os.path.join(self.root_dir, \"TrainBlock\", uid + \".jpg\"))/255\n",
    "            img_patch = img[y:y+self.target_size[0], x:x+self.target_size[1],:]\n",
    "            masked_pixels = np.count_nonzero(img_patch == 0)\n",
    "            total_pixels = img_patch.shape[0] * img_patch.shape[1]\n",
    "            if img_patch.shape[0] != self.target_size[0] or img_patch.shape[1] != self.target_size[1]:\n",
    "                continue\n",
    "            if masked_pixels/total_pixels < threshold_masked:\n",
    "                dmap = np.load(os.path.join(self.root_dir, \"TrainDensity\", uid + \".npz\"))['dmap']\n",
    "                return img_patch, dmap[y:y+self.target_size[0], x:x+self.target_size[1],:]\n",
    "        \n",
    "    def sample_bg(self, shape, image_id):\n",
    "        x = np.random.randint(0, shape[1] - self.target_size[1], size=(1,))[0]\n",
    "        y = np.random.randint(0, shape[0] - self.target_size[0], size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def sample_dot(self, shape, adots, image_id):\n",
    "        half_size = 36\n",
    "        \n",
    "        randi = np.random.choice(len(adots), size=(1,))[0]\n",
    "        rand_dot = adots[randi]\n",
    "        \n",
    "        min_x = max(0, rand_dot[0] - self.target_size[1] + half_size)\n",
    "        max_x = min(shape[1] - self.target_size[1], rand_dot[0] + self.target_size[1] - half_size)\n",
    "        \n",
    "        min_y = max(0, rand_dot[1] - self.target_size[0] + half_size)\n",
    "        max_y = min(shape[0] - self.target_size[0], rand_dot[1] + self.target_size[0] - half_size)\n",
    "        \n",
    "        if min_x >= max_x:\n",
    "            max_x, min_x = min_x, max_x\n",
    "        if min_y >= max_y:\n",
    "            max_y, min_y = min_y, max_y \n",
    "           \n",
    "        x = np.random.randint(min_x, max_x, size=(1,))[0]\n",
    "        y = np.random.randint(min_y, max_y, size=(1,))[0]\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                 \n",
    "        batch_x = np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 3), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size, self.max_count)) if self.output_counts\\\n",
    "        else np.zeros((current_batch_size, self.target_size[0], self.target_size[1], 1), dtype=K.floatx())\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_successive_samples patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            with open(os.path.join(self.root_dir, \"TrainDots\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                dots = pickle.load(pfile)\n",
    "            with open(os.path.join(self.root_dir, \"TrainShape\", str(image_id) + \".pkl\"), \"rb\") as pfile:\n",
    "                shape = pickle.load(pfile)\n",
    "                \n",
    "            x, y = self.__sample__(shape, dots, image_id)\n",
    "            batch_x[i,:,:,:] = x\n",
    "            if not self.output_counts: \n",
    "                batch_y[i,:,:] = np.sum(y, axis=-1, keepdims=True)\n",
    "            else:\n",
    "                counts = np.sum(y)\n",
    "                batch_y[i, :] = to_categorical(np.round(counts).astype(np.int), num_classes=self.max_count)     \n",
    "\n",
    "        return self.__normalize_input__(batch_x), self.__normalize_output__(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_density(im, density):\n",
    "    max_density = np.max(density)\n",
    "    if max_density > 0:\n",
    "        normalized_density = density/max_density\n",
    "    else:\n",
    "        normalized_density = density\n",
    "    im_fp32 = im.astype(np.float32)\n",
    "    im_masked = im_fp32.copy()\n",
    "    im_masked[:,:,0] = (im_fp32[:,:,0] * normalized_density)\n",
    "    im_masked[:,:,1] = (im_fp32[:,:,1] * normalized_density)\n",
    "    im_masked[:,:,2] = (im_fp32[:,:,2] * normalized_density)\n",
    "    return im_masked.astype(np.uint8), (normalized_density * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(s[:-4]) for s in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/dots_ok.json\", \"r\") as jfile:\n",
    "    dots_ok = json.load(jfile)\n",
    "dots_ok = [int(s[:-4]) for s in dots_ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = list(set(train_ids).intersection(set(dots_ok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(s[:-4]) for s in val_ids]\n",
    "val_ids = list(set(val_ids).intersection(set(dots_ok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_bgr = np.load(\"../data/sealion/mean_bgr.npy\")\n",
    "std_bgr = np.load(\"../data/sealion/std_bgr.npy\")\n",
    "trainPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", train_ids, mean_bgr, std_bgr, 5, output_counts=False)\n",
    "valPatchesGenerator = PatchIterator(\"/home/lowik/sealion/data/sealion/\", val_ids, mean_bgr, std_bgr, 5, output_counts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, batch_y in trainPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(batch_x, batch_y)):\n",
    "    im, mask = show_density(x, y[:,:,0])\n",
    "    cv2.imwrite(\"../data/dmap\" + str(i) + \".png\", mask)\n",
    "    #cv2.imwrite(\"../data/dmapx\" + str(i) + \".png\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = get_unet(3, 1, 0.001)\n",
    "h = unet.fit_generator(trainPatchesGenerator, 100, epochs=2, verbose=1, callbacks=None, validation_data=valPatchesGenerator, validation_steps=20, class_weight=None, max_q_size=10, workers=2, pickle_safe=False, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch_x, batch_y in valPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ypred = unet.predict(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(np_count_mse(batch_y, batch_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(np.mean(mean_squared_error(batch_y, batch_ypred).eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(batch_y[1,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(batch_ypred[7,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    print(np.mean(mean_squared_error(batch_y, batch_ypred).eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
