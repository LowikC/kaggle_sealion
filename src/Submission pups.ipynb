{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from math import sqrt\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_test_ids = set()\n",
    "for fn in os.listdir(\"../data/sealion/Test/\"):\n",
    "    if fn.endswith(\".jpg\"):\n",
    "        uid, _ = os.path.splitext(fn)\n",
    "        real_test_ids.add(int(uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_groundtruth_counts(path):\n",
    "    df = pd.read_csv(path)\n",
    "    gt_counts = dict()\n",
    "    \n",
    "    def fill_counts(x, counts):\n",
    "        counts[int(x.train_id)] = [x.adult_males, x.subadult_males, x.adult_females, x.juveniles, x.pups]\n",
    "    \n",
    "    _ = df.apply(fill_counts, axis=1, args=(gt_counts, ))\n",
    "    return gt_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_counts = get_groundtruth_counts(\"../data/sealion/my_correct_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_ids = set(gt_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pups_counts = dict()\n",
    "with open(\"../data/sealion/pups_mean.csv\", \"r\") as ifile:\n",
    "    for line in ifile:\n",
    "        iid, cnt = line.split(\",\")\n",
    "        pups_counts[int(iid)] = int(round(float(cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_counts_mean_pups(ids, train_counts, pups_counts):\n",
    "    \"\"\" Return a dict id -> counts (5 elts list)\n",
    "    \"\"\"\n",
    "    means = [0, 0, 0, 0, 0]\n",
    "    for _, counts in train_counts.items():\n",
    "        for sid in range(5):\n",
    "            means[sid] += counts[sid]\n",
    "            \n",
    "    for sid in range(5):\n",
    "        means[sid] /= len(train_counts)\n",
    "        means[sid] = int(round(means[sid]))\n",
    "        \n",
    "    counts = dict()\n",
    "    for iid in ids:\n",
    "        counts[iid] = means.copy()\n",
    "        counts[iid][4] = pups_counts[iid]\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18636"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pups_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18636"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = predict_counts_mean_pups(real_test_ids, gt_counts, pups_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission(counts, out_fn):\n",
    "    with open(out_fn, \"w\") as ofile:\n",
    "        ofile.write(\"test_id,adult_males,subadult_males,adult_females,juveniles,pups\\n\")\n",
    "        for iid in sorted(counts.keys()):\n",
    "            str_counts = \",\".join([str(int(round(c))) for c in counts[iid]])\n",
    "            ofile.write(\"{iid},{counts}\\n\".format(iid=iid, counts=str_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495436712"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(datetime.timestamp(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_submission(counts, \"../data/submissions/1495436712_mean_prediction_and_pups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id,adult_males,subadult_males,adult_females,juveniles,pups\r\n",
      "0,6,4,39,21,1\r\n",
      "1,6,4,39,21,1\r\n",
      "2,6,4,39,21,7\r\n",
      "3,6,4,39,21,0\r\n",
      "4,6,4,39,21,8\r\n",
      "5,6,4,39,21,15\r\n",
      "6,6,4,39,21,0\r\n",
      "7,6,4,39,21,3\r\n",
      "8,6,4,39,21,2\r\n"
     ]
    }
   ],
   "source": [
    "!head ../data/submissions/1495436712_mean_prediction_and_pups.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18637 ../data/submissions/1495436712_mean_prediction_and_pups.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../data/submissions/1495436712_mean_prediction_and_pups.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rmse(predicted_counts, groundtruth_counts):\n",
    "    N_SEALION_TYPES = 5\n",
    "    # Check if all predicted ids are also in validation ids\n",
    "    predicted_ids = set(predicted_counts.keys())\n",
    "    set_validation_ids  = set(groundtruth_counts.keys())\n",
    "    assert(predicted_ids.issubset(set_validation_ids))\n",
    "    \n",
    "    # Compute rmse for each type\n",
    "    rmses = [0 for _ in range(N_SEALION_TYPES)]\n",
    "    for iid, pred_counts in predicted_counts.items():\n",
    "        true_counts = groundtruth_counts[iid]\n",
    "        for sid in range(N_SEALION_TYPES):\n",
    "            dc = pred_counts[sid] - true_counts[sid]\n",
    "            rmses[sid] += dc * dc\n",
    "            \n",
    "    for sid in range(N_SEALION_TYPES):\n",
    "        rmses[sid] /= len(predicted_counts)\n",
    "        rmses[sid] = sqrt(rmses[sid])\n",
    "    print(rmses)    \n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "train_ids = [int(iid) for iid in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)\n",
    "val_ids = [int(iid) for iid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/sealion/test.json\", \"r\") as jfile:\n",
    "    test_ids = json.load(jfile)\n",
    "test_ids = [int(iid) for iid in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_groundtruth_counts(path):\n",
    "    df = pd.read_csv(path)\n",
    "    gt_counts = dict()\n",
    "    \n",
    "    def fill_counts(x, counts):\n",
    "        counts[int(x.train_id)] = [x.adult_males, x.subadult_males, x.adult_females, x.juveniles, x.pups]\n",
    "    \n",
    "    _ = df.apply(fill_counts, axis=1, args=(gt_counts, ))\n",
    "    return gt_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt_counts = get_groundtruth_counts(\"../data/sealion/my_correct_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_counts = predict_counts(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.049316595915556, 7.558386963046154, 68.45912419388125, 34.073367635478476, 47.029873365383885]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.434013750741066"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(predicted_counts, gt_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_counts_mean(ids, train_counts):\n",
    "    \"\"\" Return a dict id -> counts (5 elts list)\n",
    "    \"\"\"\n",
    "    means = [0, 0, 0, 0, 0]\n",
    "    for _, counts in train_counts.items():\n",
    "        for sid in range(5):\n",
    "            means[sid] += counts[sid]\n",
    "            \n",
    "    for sid in range(5):\n",
    "        means[sid] /= len(train_counts)\n",
    "        means[sid] = int(round(means[sid]))\n",
    "        \n",
    "    counts = dict()\n",
    "    for iid in ids:\n",
    "        counts[iid] = means\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_counts = dict()\n",
    "for iid in train_ids:\n",
    "    train_counts[iid] = gt_counts[iid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_counts_mean = predict_counts_mean(val_ids, train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.240077451365028, 6.019164151163489, 57.90684110872403, 28.50832718875528, 44.32211003779318]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.9993039875602"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(predicted_counts_mean, gt_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(list(gt_counts.keys())).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.678891744646627, 5.88353922016963, 63.28530268446995, 53.31381499384857, 42.47828931691034]\n",
      "[6, 4, 39, 20, 18] 34.327967592\n",
      "[7.53808893620436, 5.291502622129181, 59.64080244644346, 32.54364158472338, 47.079966086978594]\n",
      "[6, 4, 40, 22, 17] 30.4188003353\n",
      "[7.7484175599630865, 6.879922480183431, 69.69856738383257, 42.15703013583165, 51.301787665943166]\n",
      "[6, 4, 39, 20, 17] 35.5571450452\n",
      "[8.322102136254081, 7.182374112387586, 77.21469876028365, 32.7914391421398, 50.77650209060252]\n",
      "[5, 4, 37, 21, 16] 35.2574232483\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for train, test in kf.split(X):\n",
    "    train_ids = list(train)\n",
    "    test_ids = list(test)\n",
    "    train_counts = dict()\n",
    "    for iid in train_ids:\n",
    "        train_counts[iid] = gt_counts[iid]\n",
    "    predicted_counts_mean = predict_counts_mean(test_ids, train_counts)\n",
    "    rmse = get_rmse(predicted_counts_mean, gt_counts)\n",
    "    rmses.append(rmse)\n",
    "    print(list(predicted_counts_mean.values())[0], rmse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.890334055197286"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(gt_counts, gt_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a submission with all train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_predicted_counts_mean = predict_counts_mean(real_test_ids, gt_counts)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495201291"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(datetime.timestamp(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_submission(real_predicted_counts_mean, \"../data/submissions/1495097083_mean_prediction_all_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id,adult_males,subadult_males,adult_females,juveniles,pups\r\n",
      "0,6,4,39,21,17\r\n",
      "1,6,4,39,21,17\r\n",
      "2,6,4,39,21,17\r\n",
      "3,6,4,39,21,17\r\n",
      "4,6,4,39,21,17\r\n",
      "5,6,4,39,21,17\r\n",
      "6,6,4,39,21,17\r\n",
      "7,6,4,39,21,17\r\n",
      "8,6,4,39,21,17\r\n"
     ]
    }
   ],
   "source": [
    "!head \"../data/submissions/1495097083_mean_prediction_all_train_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18637 ../data/submissions/1495097083_mean_prediction_all_train_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"../data/submissions/1495097083_mean_prediction_all_train_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = {0:[1, 2, 3, 4, 5], 1:[6, 7, 8, 9, 10], 2:[11, 12, 13, 14, 15]}\n",
    "gt = {0:[0, 0, 0, 0, 0], 1:[0, 0, 0, 0, 0], 2:[0, 0, 0, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.2571803523590805, 8.103497187428813, 8.981462390204987, 9.882644720249063, 10.801234497346433]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.0052038295176757"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse(pred, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rmse_row_wise(predicted_counts, groundtruth_counts):\n",
    "    N_SEALION_TYPES = 5\n",
    "    # Check if all predicted ids are also in validation ids\n",
    "    predicted_ids = set(predicted_counts.keys())\n",
    "    set_validation_ids  = set(groundtruth_counts.keys())\n",
    "    assert(predicted_ids.issubset(set_validation_ids))\n",
    "    \n",
    "    # Compute rmse for each type\n",
    "    rmses = []\n",
    "    for iid, pred_counts in predicted_counts.items():\n",
    "        true_counts = groundtruth_counts[iid]\n",
    "        row_rmse = 0\n",
    "        for sid in range(N_SEALION_TYPES):\n",
    "            dc = pred_counts[sid] - true_counts[sid]\n",
    "            row_rmse += dc * dc\n",
    "        row_rmse/=5\n",
    "        row_rmse = sqrt(row_rmse)\n",
    "        rmses.append(row_rmse)\n",
    "        \n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.1724533418711278"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rmse_row_wise(pred, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.57142857142858"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "69/0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30/0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mean_stratified_split(gt_counts, ratio=0.7):\n",
    "    available_ids = set(gt_counts.keys())\n",
    "    train_ids = set()\n",
    "    test_ids = set()\n",
    "    \n",
    "    train_sums = np.zeros((5, ), dtype=np.float32)\n",
    "    test_sums = np.zeros((5, ), dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        while available_ids and (len(train_ids)/ratio <= len(test_ids)/(1 - ratio) or len(train_ids) == 0): \n",
    "            # Add a randomly selected id to the train set\n",
    "            index = np.random.choice(len(available_ids), replace=False)\n",
    "            rid = list(available_ids)[index]\n",
    "            available_ids.remove(rid)\n",
    "            train_ids.add(rid)\n",
    "            train_sums += np.asarray(gt_counts[rid])\n",
    "        \n",
    "        train_means = train_sums/len(train_ids)\n",
    "        \n",
    "        # Select a id that minimize the mean difference\n",
    "        best_id = -1\n",
    "        best_error = 1e9\n",
    "        if not available_ids:\n",
    "            break\n",
    "        for tid in available_ids:\n",
    "            local_sums = test_sums + np.asarray(gt_counts[tid])\n",
    "            local_means = local_sums/(len(test_ids) + 1)\n",
    "            error = np.sum(np.square(local_means - train_means))\n",
    "            if error < best_error:\n",
    "                best_error = error\n",
    "                best_id = tid\n",
    "        test_ids.add(best_id)\n",
    "        test_sums += np.asarray(gt_counts[best_id])\n",
    "        available_ids.remove(best_id)\n",
    "        \n",
    "    final_error = np.sum(np.square(test_sums/len(test_ids) - train_sums/len(train_ids)))\n",
    "    print(\"Final error: \", final_error)\n",
    "    return train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error:  0.202523\n"
     ]
    }
   ],
   "source": [
    "train_ids, test_ids = random_mean_stratified_split(gt_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error:  0.67307\n",
      "[6.50802473604029, 5.571544244027673, 47.461304644905105, 30.260506367442616, 34.93517806834061]\n",
      "[6, 4, 39, 21, 17] 24.9473116122\n",
      "Final error:  0.208129\n",
      "[6.722572606981672, 5.3176303916741094, 49.86585513928273, 29.997836179274604, 37.01493297519117]\n",
      "[6, 4, 39, 21, 17] 25.7837654585\n",
      "Final error:  0.77703\n",
      "[7.060639601264702, 5.422500232543086, 50.93215301286915, 28.581615978279196, 37.34551806171988]\n",
      "[5, 4, 39, 21, 17] 25.8684853773\n",
      "Final error:  0.116361\n",
      "[6.865116500206207, 5.223429000792084, 47.68121480849702, 25.33370267505463, 35.64203117058443]\n",
      "[6, 4, 39, 21, 17] 24.149098831\n",
      "Final error:  0.914914\n",
      "[6.609668622423185, 5.387119140280726, 49.89975916687656, 26.461292485439937, 35.41275416985717]\n",
      "[6, 4, 39, 21, 17] 24.754118717\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "for i in range(5):\n",
    "    train_ids, test_ids = random_mean_stratified_split(gt_counts)\n",
    "    train_counts = dict()\n",
    "    for iid in train_ids:\n",
    "        train_counts[iid] = gt_counts[iid]\n",
    "    #predicted_counts_mean = predict_counts(test_ids)    \n",
    "    predicted_counts_mean = predict_counts_mean(test_ids, train_counts)\n",
    "    rmse = get_rmse(predicted_counts_mean, gt_counts)\n",
    "    rmses.append(rmse)\n",
    "    print(list(predicted_counts_mean.values())[0], rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.100555999193944"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
